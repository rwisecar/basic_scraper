
<!DOCTYPE html PUBLIC
  "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">

    
    
    
    
    


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
        <base href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts" /><!--[if lt IE 7]></base><![endif]-->
    

    
        <meta content="2011/04/01 - " name="DC.date.valid_range" />
<link rel="kss-base-url" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/" />

  
    <link rel="stylesheet" type="text/css" href="http://crisewing.com/portal_css/crisewing.com%20Theme/base-cachekey-6a4288b1f5ff58cb412d24a5d7699aed.css" />
        <!--[if lt IE 8]>    
    
    <link rel="stylesheet" type="text/css" media="screen" href="http://crisewing.com/portal_css/crisewing.com%20Theme/IEFixes-cachekey-9a1e4208c06a6186371efdfcf3c964e1.css" />
        <![endif]-->
    
    <style type="text/css" media="all">@import url(http://crisewing.com/portal_css/crisewing.com%20Theme/resourceContentWellPortlets.stylesContentWellPortlets-cachekey-ac0e6153e4d00db59895d2ab03124ca6.css);</style>
    <link rel="stylesheet" type="text/css" media="screen" href="http://crisewing.com/portal_css/crisewing.com%20Theme/resourcejquery-ui-themessunburstjqueryui-cachekey-a018f472896b20488a2ad02a2dca9359.css" />
    <style type="text/css">@import url(http://crisewing.com/portal_css/crisewing.com%20Theme/resourcecollective.flowplayer.cssflowplayer-cachekey-1f0ec8cd6776345992478af55d55d5e2.css);</style>
    <link rel="stylesheet" type="text/css" media="all" href="http://crisewing.com/portal_css/crisewing.com%20Theme/ploneCustom-cachekey-8ee8fc1cdd61211ec52a0f8181b78ed7.css" />

  
    <link rel="kinetic-stylesheet" type="text/css" href="http://crisewing.com/portal_kss/crisewing.com%20Theme/resourcetinymce.ksstinymce-cachekey-b6bfc5c09a03b431f201c86a1359995a.kss" />
    <link rel="kinetic-stylesheet" type="text/css" href="http://crisewing.com/portal_kss/crisewing.com%20Theme/at-cachekey-cc70007125bd046aa0c600b617cb1d7e.kss" />
  
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/jquery-cachekey-3d3aee2c96dd957234da67d45127b287.js"></script>
       <!--[if lt IE 8]>
     
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/iefixes-cachekey-42597b17d0273334e8607aa5425f69e4.js"></script>
       <![endif]-->
     
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/collective.js.jqueryui.custom.min-cachekey-47bebbba21dbd85bd82204b3588251c6.js"></script>


<title>Open Source Posts &mdash; CrisEwing.com</title>
        

    <link rel="shortcut icon" type="image/x-icon" href="http://crisewing.com/favicon.ico" />
    <link rel="apple-touch-icon" href="http://crisewing.com/touch_icon.png" />


<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/atom.xml" title="Atom 2005" type="application/atom+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/feed.rdf" title="RDF 1.0" type="application/rdf+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/feed11.rdf" title="RDF 1.1" type="application/rdf+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/rss.xml" title="RSS 1.0" type="application/rss+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/itunes.xml" title="RSS 2.0" type="application/rss+xml" />

<script type="text/javascript">
        jQuery(function($){
            $.datepicker.setDefaults(
                jQuery.extend($.datepicker.regional[''],
                {dateFormat: 'mm/dd/yy'}));
        });
        </script>

    <link rel="home" href="http://crisewing.com" title="Front page" />

    <link rel="contents" href="http://crisewing.com/sitemap" title="Site Map" />






    <link rel="search" href="http://crisewing.com/search_form" title="Search this site" />



        
        
        
        
        

        <meta name="viewport" content="width=device-width; initial-scale=0.6666; maximum-scale=1.0; minimum-scale=0.6666" />
        <meta name="generator" content="Plone - http://plone.org" />
    
</head>

<body class="template-full_feed portaltype-collage site-Plone section-cover" dir="ltr">

<div id="visual-portal-wrapper">

        <div id="portal-top" class="row">
<div class="cell width-full position-0">
            <div id="portal-header">
    <p class="hiddenStructure">
  <a accesskey="2" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed#content">Skip to content.</a> |

  <a accesskey="6" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed#portal-globalnav">Skip to navigation</a>
</p>

<div id="portal-personaltools-wrapper">

<h5 class="hiddenStructure">Personal tools</h5>



<dl class="actionMenu deactivated" id="portal-personaltools">
  <dt id="anon-personalbar">
    
        <a href="http://crisewing.com/login" id="personaltools-login">Log in</a>
    
  </dt>
</dl>

</div>



<div id="portal-searchbox">
    <form name="searchform" id="searchGadget_form" action="http://crisewing.com/search">

        <div class="LSBox">
        <label class="hiddenStructure" for="searchGadget">Search Site</label>

        <input name="SearchableText" type="text" size="18" title="Search Site" accesskey="4" class="searchField inputLabel" id="searchGadget" />

        <input class="searchButton" type="submit" value="Search" />

        <div class="searchSection">
            <input id="searchbox_currentfolder_only" class="noborder" type="checkbox" name="path" value="/Plone/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3" />
            <label for="searchbox_currentfolder_only" style="cursor: pointer">
                only in current section
            </label>
        </div>

        <div class="LSResult" id="LSResult" style=""><div class="LSShadow" id="LSShadow"></div></div>
        </div>
    </form>

    <div id="portal-advanced-search" class="hiddenStructure">
        <a href="http://crisewing.com/search_form" accesskey="5">
            Advanced Search&hellip;
        </a>
    </div>

</div>

<a id="portal-logo" title="CrisEwing.com" accesskey="1" href="http://crisewing.com">
    <img src="http://crisewing.com/logo.png" alt="CrisEwing.com" title="CrisEwing.com" height="63" width="238" /></a>


    <h5 class="hiddenStructure">Sections</h5>

    <ul id="portal-globalnav"><li id="portaltab-index_html" class="selected"><a href="http://crisewing.com" title="">Home</a></li><li id="portaltab-contact" class="plain"><a href="http://crisewing.com/contact" title="I'm looking forward to hearing from you">Contact Me</a></li><li id="portaltab-on-github" class="plain"><a href="https://github.com/cewing" title="">On Github</a></li></ul>

</div>


    <div id="portlets-in-header" class="row">
         
         
    </div>

    


</div>
        </div>
    <div id="portal-columns" class="row">

        <div id="portal-column-content" class="cell width-full position-0">

            <div id="viewlet-above-content"><div id="portal-breadcrumbs">

    <span id="breadcrumbs-you-are-here">You
are here:</span>
    <span id="breadcrumbs-home">
        <a href="http://crisewing.com">Home</a>
        
    </span>

</div>

<div id="portlets-above" class="row">
    
    
</div>

</div>

            
                <div class="">

                    

                    

    <dl class="portalMessage info" id="kssPortalMessage" style="display:none">
        <dt>Info</dt>
        <dd></dd>
    </dl>



                    
                        <div id="content">

                            

                            

    

    <h1 class="documentFirstHeading">Open Source Posts</h1>

    


    

    <div class="feedEntry">

        <a href="https://postgr.es/p/3IA" title="Magnus Hagander: Another couple of steps on my backup crusade">
            <h2>Magnus Hagander: Another couple of steps on my backup crusade</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 16, 2017</span>.
            
        </p>

        <p>For a while now, I've been annoyed with how difficult it is to set up <em>good</em> backups in PostgreSQL. The difficulty of doing this "right" has pushed people to use things like <em>pg_dump</em> for backups, which is not really a great option once your database reaches any non-toy size. And when visiting customers over the years I've seen a large number of home-written scripts to do PITR backups, most of them broken, and most of that breakage because the APIs provided were too difficult to use.</p>
<p>Over some time, I've worked on a number of ways to improve this situation, alone or with others. The bigger steps are:</p>
<ul>
<li>9.1 introduced <em>pg_basebackup</em>, making it easier to take base backups using the replication protocol</li>
<li>9.2 introduced transaction log streaming to <em>pg_basebackup</em></li>
<li>9.6 introduced a new version of the <em>pg_start_backup</em>/<em>pg_stop_backup</em> APIs that are needed to do more advanced base backups, in particular using third party backup tools.</li>
</ul>
<p>For 10.0, there are a couple of new things that have been done in the past couple of weeks:</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Iz" title="Kaarel Moppel: Two simple Postgres tips to kick-start year 2017">
            <h2>Kaarel Moppel: Two simple Postgres tips to kick-start year 2017</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 16, 2017</span>.
            
        </p>

        <p>While reviewing my notes on some handy Postgres tricks and nasty gotchas to conclude in on-site training course my “current me” again learned some tricks which an older version of “me” had luckily wrote down. So here are two simple tricks that hopefully even a lot of Postgres power-users find surprising. Disabling JOIN re-ordering by [&#8230;]</p>
<p>The post <a href="http://www.cybertec.at/two-simple-postgres-tips-to-kick-start-year-2017/" rel="nofollow">Two simple Postgres tips to kick-start year 2017</a> appeared first on <a href="http://www.cybertec.at" rel="nofollow">Cybertec - The PostgreSQL Database Company</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Iy" title="Michael Paquier: Postgres 10 highlight - Reload of SSL parameters">
            <h2>Michael Paquier: Postgres 10 highlight - Reload of SSL parameters</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 15, 2017</span>.
            
        </p>

        <p>Here are some news from the front of Postgres 10 development, with the
highlight of the following commit:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>commit: de41869b64d57160f58852eab20a27f248188135
author: Tom Lane &lt;tgl@sss.pgh.pa.us&gt;
date: Mon, 2 Jan 2017 21:37:12 -0500
Allow SSL configuration to be updated at SIGHUP.

It is no longer necessary to restart the server to enable, disable,
or reconfigure SSL.  Instead, we just create a new SSL_CTX struct
(by re-reading all relevant files) whenever we get SIGHUP.  Testing
shows that this is fast enough that it shouldn't be a problem.

In conjunction with that, downgrade the logic that complains about
pg_hba.conf "hostssl" lines when SSL isn't active: now that's just
a warning condition not an error.

An issue that still needs to be addressed is what shall we do with
passphrase-protected server keys?  As this stands, the server would
demand the passphrase again on every SIGHUP, which is certainly
impractical.  But the case was only barely supported before, so that
does not seem a sufficient reason to hold up committing this patch.

Andreas Karlsson, reviewed by Michael Banck and Michael Paquier

Discussion: https://postgr.es/m/556A6E8A.9030400@proxel.se
</code></pre>
</div>

<p>This has been wanted for a long time. In some environments where Postgres is
deployed, there could be CA and/or CLR files installed by default, and the user
may want to replace them with custom entries. Still, in most cases, the
problems to deal with is the replacement of expired keys. In each case, after
replacing something that needs a reload of the SSL context, a restart of the
instance is necessary to rebuild it properly. Note that while it may be fine
for some users to pay the cost of an instance restart, some users caring about
availability do not want to have to take down a server, so this new feature
is most helpful for many people.</p>

<p>All the SSL parameters are impacted by this upgrade, and they are the
following ones:</p>

<ul>
  <li>ssl</li>
  <li>ssl_ciphers</li>
  <li>ssl_prefer_server_ciphers</li>
  <li>ssl_ecdh_curve</li>
  <li>ssl_cert_file</li>
  <li>ssl_key_file</li>
  <li>ssl_ca_file</li>
  <li>ssl_crl_file</li>
</ul>

<p>Note however that there are a couple of things to be aware of:</p>

<ul>
  <li>On Windows (or builds with EXEC_BACKEND), the new parameters are read
  at each backend startup. Existing sessions do not have its context updated,
  and an error in loading the new parameters will cause the connection to
  fail.</li>
  <li>Entries of pg_hba.conf with hostssl are ignored are ignored if
  SSL is disabled and a warning is logged to mention that. In previous
  versions you would get an error if a hostssl entry was found at server
  start.</li>
  <li>Passphrase key prompt is enabled, but only at server startup, and
  disactivated at parameter reload to not stuck every backend reloading
  the SSL context. There could be improvements in this area by using a new
  GUC parameter that defines command allowing processes to get the passphrase
  instead of asking it in a tty. Patches are welcome if there is a use case
  for it. This behavior is described in the following
  <a href="http://git.postgresql.org/pg/commitdiff/6667d9a6d77b9a6eac89638ac363b6d03da253c1">commit</a>.
  As passphrase support has been rather limited for a long time, being able
  to reload SSL contexts even without it has a great value.</li>
</ul>

<p>This is really a nice feature, and I am happy to see this landing as I
have been struggling more than once with the downtime that a SSL update
induces.</p>
    </div>
    <div class="feedEntry">

        <a href="http://krzysztofzuraw.com/blog/2017/transcoding-aws-part-four.html" title="Transcoding with AWS- part four">
            <h2>Transcoding with AWS- part four</h2>
        </a>

        <p class="discreet">
            
                  By Krzysztof Żuraw Personal Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 15, 2017</span>.
            
        </p>

        <p><strong>As I have my transcoder up and running now it's time to let user know that their
uploaded files were transcoded. To this occasion I will use AWS SNS service which
allows me to send notification about completion of transcode job.</strong></p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#setting-up-aws-sns-to-work-with-aws-transcoder" id="id1">Setting up AWS SNS to work with AWS Transcoder</a></li>
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#receiving-notifications-from-sns-service-in-django" id="id2">Receiving notifications from SNS service in Django</a></li>
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#other-blog-posts-in-this-series" id="id3">Other blog posts in this series</a></li>
</ul>
</div>
<div class="section" id="setting-up-aws-sns-to-work-with-aws-transcoder">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id1">Setting up AWS SNS to work with AWS Transcoder</a></h2>
<p>After logging to AWS console and selecting SNS I have to create a topic:</p>
<img alt="SNS topic" src="https://www.djangoproject.com/images/aws_sns1.jpg" />
<p>Topic is endpoint for other application in AWS to send their notifications.
For my case I have to change it in AWS Transcoder pipeline settings:</p>
<img alt="Transcoder SNS subscription" src="https://www.djangoproject.com/images/aws_sns2.jpg" />
<p>Last thing I have to do was to create subscription for topic created above. They
are a lot of types of subscription that you can find in SNS settings but I will
be using HTTP request.</p>
</div>
<div class="section" id="receiving-notifications-from-sns-service-in-django">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id2">Receiving notifications from SNS service in Django</a></h2>
<p>The flow of application will look like this:</p>
<ol class="arabic simple">
<li>User upload a file</li>
<li>File is sent to S3</li>
<li>Transcode job is fired after uploading form view</li>
<li>After transcode completion AWS transcoder sends SNS notification</li>
<li>This notification is taken by SNS subscription and send to my endpoint</li>
<li>After validating notification endpoint inform user that his or her files are transcoded</li>
</ol>
<p>To receive HTTP notifications I have to create a endpoint in my Django application.
First I add url in <tt class="docutils literal">audio_transcoder/urls.py</tt>:</p>
<div class="highlight"><pre><span></span><span class="n">url</span><span class="p">(</span>
      <span class="n">regex</span><span class="o">=</span><span class="s1">r'^transcode-complete/$'</span><span class="p">,</span>
      <span class="n">view</span><span class="o">=</span><span class="n">views</span><span class="o">.</span><span class="n">transcode_complete</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">'transcode-complete'</span>
  <span class="p">)</span>
</pre></div>
<p>Code for this endpoint looks as follows (<tt class="docutils literal">audio_transcoder/views.py</tt>):</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">django.views.decorators.csrf</span> <span class="kn">import</span> <span class="n">csrf_exempt</span>
<span class="kn">from</span> <span class="nn">.utlis</span> <span class="kn">import</span> <span class="n">convert_sns_str_to_json</span>
<span class="kn">from</span> <span class="nn">django.http</span> <span class="kn">import</span> <span class="p">(</span>
  <span class="n">HttpResponse</span><span class="p">,</span>
  <span class="n">HttpResponseNotAllowed</span><span class="p">,</span>
  <span class="n">HttpResponseForbidden</span>
<span class="p">)</span>

<span class="nd">@csrf_exempt</span>
<span class="k">def</span> <span class="nf">transcode_complete</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">method</span> <span class="o">!=</span> <span class="s1">'POST'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">HttpResponseNotAllowed</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">META</span><span class="p">[</span><span class="s1">'HTTP_X_AMZ_SNS_TOPIC_ARN'</span><span class="p">]</span> <span class="o">!=</span> <span class="n">settings</span><span class="o">.</span><span class="n">SNS_TOPIC_ARN</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">HttpResponseForbidden</span><span class="p">(</span><span class="s1">'Not vaild SNS topic ARN'</span><span class="p">)</span>
    <span class="n">json_body</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">),</span> <span class="n">object_hook</span><span class="o">=</span><span class="n">convert_sns_str_to_json</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">json_body</span><span class="p">[</span><span class="s1">'Message'</span><span class="p">][</span><span class="s1">'state'</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'COMPLETED'</span><span class="p">:</span>
        <span class="c1"># do something</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="s1">'OK'</span><span class="p">)</span>
</pre></div>
<p>What is happening there? The first 2 ifs in <tt class="docutils literal">transcode_complete</tt> are for checking if user sends
POST request and as a <a class="reference external" href="http://docs.aws.amazon.com/sns/latest/dg/SendMessageToHttp.html">SNS documentation</a>
says I have to make sure that message received are valid as everyone can send request to this endpoint.</p>
<p>In line with <tt class="docutils literal">json_body</tt> I have to use helper that I pass to <tt class="docutils literal">object_hook</tt>:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>


<span class="k">def</span> <span class="nf">convert_sns_str_to_json</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'Message'</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">value</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
      <span class="n">obj</span><span class="p">[</span><span class="s1">'Message'</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">obj</span>
</pre></div>
<p>This small function is for converting nested strings received from SNS to
python dicts. I know that every notification will have <tt class="docutils literal">Message</tt> key so based on that
I can load string and convert it to python dictionary.</p>
<p>The last <tt class="docutils literal">if</tt> will be completed in next blog post.</p>
<p>Right now I have my endpoint up and running. But there is a problem - Amazon SNS
needs to have access to that endpoint and I'm developing this application on my localhost.
How to overcome such issue? I used <a class="reference external" href="https://ngrok.com/">ngrok</a> which allows me to
tunnel to my localhost from internet. How to use it? After downloading and unpacking
you first run:</p>
<div class="highlight"><pre><span></span>$ python transcoder/manage.py runserver 0.0.0.0:9000
</pre></div>
<p>And in other window:</p>
<div class="highlight"><pre><span></span>$ ./ngrok http 9000
</pre></div>
<p>Ngrok will start and you can use url shown in console - for me: <cite>http://fba8f218.ngrok.io/</cite>.</p>
<p>With this url I go to AWS SNS subscription tab and add new subscription:</p>
<img alt="Creating a SNS subscription" src="https://www.djangoproject.com/images/aws_sns3.jpg" />
<p>After setting this up you will receive SNS message with link that you need to paste in
browser to confirm subscription.</p>
<p>That's all for today! In the next blog post I will take care about how to inform user that
transcode job has completed. Feel free to comment - your feedback is always welcome.</p>
</div>
<div class="section" id="other-blog-posts-in-this-series">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id3">Other blog posts in this series</a></h2>
<ul class="simple">
<li><a class="reference external" href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-one.html">Transcoding with AWS- part one</a></li>
<li><a class="reference external" href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-two.html">Transcoding with AWS- part two</a></li>
<li><a class="reference external" href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-three.html">Transcoding with AWS- part three</a></li>
</ul>
<p>The code that I have made so far is available on
<a class="reference external" href="https://github.com/krzysztofzuraw/blog_transcoder_aws">github</a>. Stay
tuned for next blog post from this series.</p>
<p>Special thanks to Kasia for being an editor for this post. Thank you.</p>
<p>Cover image by <a class="reference external" href="http://www.flickr.com/people/25691430&#64;N04">Harald Hoyer</a> under <a class="reference external" href="http://creativecommons.org/licenses/by-sa/2.0">CC BY-SA 2.0</a>, via Wikimedia Commons</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ix" title="Shaun M. Thomas: PG Phriday: Why Postgres">
            <h2>Shaun M. Thomas: PG Phriday: Why Postgres</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 13, 2017</span>.
            
        </p>

        <p>There are a smorgasbord of database engines out there. From an outside perspective, Postgres is just another on a steadily growing pile of structured data storage mechanisms. Similarly to programming languages like Rust and Go, it&#8217;s the new and shiny database systems like MongoDB that tend to garner the most attention. On the other hand, more established engines like Oracle or MySQL have a vastly larger lead that seems insurmountable. In either case, enthusiasm and support is likely to be better represented in exciting or established installations.</p>

<p>So why? Why out of the myriad choices available, use Postgres? I tend to get asked this question by other DBAs or systems engineers that learn I strongly advocate Postgres. It&#8217;s actually a pretty fair inquiry, so why not make it the subject of the first PG Phriday for 2017? What distinguishes it from its brethren so strongly that I staked my entire career on it?</p>

<h3>Boring!</h3>

<p>Postgres isn&#8217;t new. It didn&#8217;t enjoy the popularity that practically made MySQL a household name as part of the <a href="https://en.wikipedia.org/wiki/LAMP_&#40;software_bundle&#41;">LAMP stack</a>. It didn&#8217;t infiltrate corporations several decades ago as the de facto standard for performance and security like Oracle. It isn&#8217;t part of a much larger supported data environment like SQL Server. It isn&#8217;t small and easy like SQLite. It&#8217;s not a distributed hulk like Hadoop, or enticingly sharded like MongoDB or Cassandra. It&#8217;s not in-memory hotness like VoltDB.</p>

<p>It&#8217;s just a regular, plain old <a href="https://en.wikipedia.org/wiki/ACID">ACID</a> <a href="https://en.wikipedia.org/wiki/Relational_database_management_system">RDBMS</a>.</p>

<p><img alt="You can&#039;t explain that!" class="aligncenter size-full wp-image-1332" height="500" src="http://bonesmoses.org/wp-content/uploads/2017/01/cantexplain.jpg" width="500" /></p>

<p>It does after all, have all of the basics many expect in an RDBMS:</p>

<ul>
<li>Tables, Views, Sequences, etc.</li>
<li>Subqueries</li>
<li>Functions in various languages</li>
<li>Triggers</li>
<li>Point In Time Recovery</li>
</ul>

<p>Certain&#8230; other database platforms weren&#8217;t so complete. As a consequence, Postgres was preferred by those who knew the difference and needed that extra functionality without breaking the bank. It&#8217;s not much, but it&#8217;s a great way to develop a niche. From there, things get more interesting.</p>

<h3>Durababble</h3>

<p>For the most part, being boring but reliable was a fact of life until the release of 9.0 when Postgres introduced streaming replication and hot standby. Postgres was still a very capable platform before that juncture, but built-in high-availability made it more viable in a business context. Now the secondary copy could be online and supply query results. Now the replica would lag behind the primary by a small handful of transactions instead of entire 16MB segments of transaction log files.</p>

<p>Postgres had finally joined the rest of the world in that regard. MySQL used a different mechanism, but that was one of its selling-points for years before Postgres. The primary distinction is that Postgres streams the changes at a binary level, meaning very little calculation is necessary to apply them. As a result, Postgres replicas are much less likely to fall behind the upstream primary.</p>

<p>The second I tested this feature in 2010, any lingering doubts about the future of Postgres vanished.</p>

<h3>Cult of Extensibility</h3>

<div class="wp-caption aligncenter" id="attachment_1333" style="width: 410px;"><img alt="A future version of Postgres. Probably." class="size-full wp-image-1333" height="305" src="http://bonesmoses.org/wp-content/uploads/2017/01/swiss_chainsaw.jpg" width="400" /><p class="wp-caption-text">A future version of Postgres. Probably.</p></div>

<p>The next huge&#8212;and arguably most important&#8212;advancement in Postgres accompanied the release of 9.1: extensions. The true implications here are hard to overstate. Not all of the internal API is exposed, but extensions make it possible for practically any inclined individual to just bolt functionality onto Postgres. When Postgres 9.2 added foreign data wrappers, even arbitrary alternative backends became a possibility.</p>

<p>Hijack the query planner to route data <a href="https://wiki.postgresql.org/wiki/PGStrom">through video card CPUs</a>? Got it. Add basic <a href="https://github.com/citusdata/citus">sharding and distributed query support</a>? No problem. Interact with <a href="https://github.com/jaiminpan/cassandra2_fdw">Cassandra</a>, <a href="https://github.com/tds-fdw/tds_fdw">SQL Server</a>, or even <em><a href="https://github.com/mrwilson/fb-psql">Facebook</a></em>? Easy peasy. Store data in analytic-friendly <a href="https://citusdata.github.io/cstore_fdw/">column structure</a>? Child&#8217;s play.</p>

<p>Perl has the dubious honor of being labeled the Swiss Army Chainsaw of languages because it enables a practitioner do <em>anything</em>. Extensions convey almost that same capability to Postgres. And while a badly written extension can crash your database, good ones can elevate it beyond the imaginations and time constraints of the core developers.</p>

<p>Extensions that provide enough added value have even inspired fully supported internal adaptations, as in the case of <a href="https://www.postgresql.org/docs/9.3/static/sql-creatematerializedview.html">materialized views</a> in Postgres 9.3. What other database does that?</p>

<p>Consider what happens when these features are combined.</p>

<ol>
<li>Create a materialized view that refers to a remote table.</li>
<li>Refresh the above view before using it in a report.</li>
<li>Alternatively, siphon updated rows from the view into a more permanent aggregate summary table.</li>
<li>Get local data processing performance in ad-hoc analytics over heterogeneous platforms.</li>
</ol>

<p>Now Postgres can be the central nexus for a constellation of various data environments and provide snapshot analysis for the live data. Without a convoluted <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">ETL</a> infrastructure. Technically the materialized views or intermediate aggregate tables aren&#8217;t strictly necessary, so Postgres wouldn&#8217;t even need to store actual data. Such a configuration would be hilariously slow, but now the ironic scenario exists where Postgres can power a database empty of actual contents.</p>

<p>The 9.2 release transformed Postgres into a <em>platform</em>, and one of the reasons I don&#8217;t use the SQL part of PostgreSQL anymore.</p>

<h3>Developers, Developers, Developers!</h3>

<p><img alt="Ballmer likes developers" class="aligncenter size-full wp-image-1334" height="387" src="http://bonesmoses.org/wp-content/uploads/2017/01/ballmer_developers.jpg" width="550" /></p>

<p>The folks hacking on the Postgres code are both insanely skilled and notoriously available. It&#8217;s almost a running joke to guess which of the core devs will answer a basic SQL question first. There&#8217;s practically a race to answer questions in the <a href="https://www.postgresql.org/list/">mailing lists</a> regardless of sophistication or perceived merit, and anyone subscribed to the list can participate.</p>

<p>Their <a href="http://bonesmoses.org/2014/05/27/pgcon-2014-unconference-a-community/">dedication</a> to <a href="http://bonesmoses.org/2015/06/23/pgcon-2015-unconference-a-community/">fostering</a> community interaction is unrelenting. While not quite as organized as the Linux kernel developers thanks to Linus&#8217; role as benevolent dictator, they&#8217;ve pushed Postgres forward every year. Due to their strict commit-fests and automated testing and code review, they&#8217;ve delivered a stable update roughly every year since 2008. Is there another database engine that can boast the same?</p>

<p>And every release has at least one headliner feature that makes upgrading worth the effort. Every. Last. Version.</p>

<ul>
<li>8.4: Window functions + CTEs</li>
<li>9.0: Streaming replication</li>
<li>9.1: Foreign tables, extensions</li>
<li>9.2: Cascading replication, JSON support</li>
<li>9.3: Materialized views, event triggers, data checksums</li>
<li>9.4: JSONB, background workers, logical WAL decoding</li>
<li>9.5: Upsert</li>
<li>9.6: Parallel execution</li>
<li>10.0?: Standby quorum, native table partitioning</li>
</ul>

<p>While it would be wrong to <em>demand</em> that kind of dedication and quality, appreciating it is quite a different story. The community pushes Postgres forward because the devs give it a voice. That&#8217;s rare in any project.</p>

<p>In the end, I consider it a privilege to even participate from the sidelines. Is it perfect? Of course not; I&#8217;ve pointed out serious flaws in Postgres performance that have yet to be successfully addressed. Yet given the alternatives, and what Postgres really delivers when it&#8217;s fully leveraged, I can&#8217;t even think of a better <em>commercial</em> RDBMS.</p>

<p>Why Postgres? Maybe the better question is: <em>why not</em>?</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Iw" title="Bruce Momjian: Creating an SSL Certificate">
            <h2>Bruce Momjian: Creating an SSL Certificate</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 12, 2017</span>.
            
        </p>

        <p>Having <a class="txt2html" href="http://momjian.us/main/blogs/pgblog/2017.html#January_9_2017" style="text-decoration: none;">covered</a> the choice of certificate authorities, I want to explain
the internals of creating server certificates in Postgres.  The
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/ssl-tcp.html#SSL-CERTIFICATE-CREATION" style="text-decoration: none;">instructions</a> are already in the Postgres
documentation.
</p>
<p>When using these instructions for creating a <a class="txt2html" href="https://en.wikipedia.org/wiki/Certificate_signing_request" style="text-decoration: none;">certificate signing request</a>
(CSR), two files are created:  
</p>
<ul>
  <li>certificate signing request file with extension <em>req</em>
  </li><li>key file, containing public and private server keys, with extension <em>pem</em>
</li></ul>
<p>(It is also possible to use an existing key file.)  You can view the contents of the CSR using
<a class="txt2html" href="https://en.wikipedia.org/wiki/OpenSSL" style="text-decoration: none;"><em>openssl,</em></a> e.g.:
</p>
<p><a href="http://momjian.us/main/blogs/pgblog/2017.html#January_12_2017">Continue Reading &raquo;</a></p>
    </div>
    <div class="feedEntry">

        <a href="https://www.caktusgroup.com/blog/2017/01/11/new-year-new-python-3-6/" title="New year, new Python: Python 3.6">
            <h2>New year, new Python: Python 3.6</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 11, 2017</span>.
            
        </p>

        <div class="document">
<p>Python 3.6 was released in the tail end of 2016. Read on for a few highlights from this release.
New module: secrets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Python 3.6 introduces a new module in the standard library called <tt class="docutils literal">secrets</tt>. While the <tt class="docutils literal">random</tt> module has long existed to provide us with pseudo-random numbers suitable for applications like modeling and simulation, these were not "cryptographically random" and not suitable for use in cryptography. <tt class="docutils literal">secrets</tt> fills this gap, providing a cryptographically strong method to, for instance, create a new, random password or a secure token.</p>
<div class="section" id="new-method-for-string-interpolation">
<h1>New method for string interpolation</h1>
<p>Python previously had several methods for string interpolation, but the most commonly used was <tt class="docutils literal">str.format()</tt>. Let’s look at how this used to be done. Assuming 2 existing variables, <tt class="docutils literal">name</tt> and <tt class="docutils literal">cookies_eaten, str.format()</tt> could look like this:</p>
<pre class="literal-block">"{0} ate {1} cookies".format(name, cookies_eaten)
</pre>
<p>Or this:</p>
<pre class="literal-block">"{name} ate {cookies_eaten} cookies".format(name=name, cookies_eaten=cookies_eaten)
</pre>
<p>Now, with the new f-strings, the variable names can be placed right into the string without the extra length of the format parameters:</p>
<pre class="literal-block">f"{name} ate {cookies_eaten} cookies"
</pre>
<p>This provides a much more pythonic way of formatting strings, making the resulting code both simpler and more readable.</p>
</div>
<div class="section" id="underscores-in-numerals">
<h1>Underscores in numerals</h1>
<p>While it doesn’t come up often, it has long been a pain point that long numbers could be difficult to read in the code, allowing bugs to creep in. For instance, suppose I need to multiply an input by 1 billion before I process the value. I might say:</p>
<pre class="literal-block">bill_val = input_val * 1000000000
</pre>
<p>Can you tell at a glance if that number has the right number of zeroes? I can’t. Python 3.6 allows us to make this clearer:</p>
<pre class="literal-block">bill_val = input_val * 1_000_000_000
</pre>
<p>It’s a small thing, but anything that reduces the chance I’ll introduce a new bug is great in my book!</p>
</div>
<div class="section" id="variable-type-annotations">
<h1>Variable type annotations</h1>
<p>One key characteristic of Python has always been its flexible variable typing, but that isn’t always a good thing. Sometimes, it can help you catch mistakes earlier if you know what type you are expecting to be passed as parameters, or returned as the results of a function. There have previously been ways to annotate types within comments, but the 3.6 release of Python is the first to bring these annotations into official Python syntax. This is a completely optional aspect of the language, since the annotations have no effect at runtime, but this feature makes it easier to inspect your code for variable type inconsistencies before finalizing it.</p>
</div>
<div class="section" id="and-much-more">
<h1>And much more…</h1>
<p>In addition to the changes mentioned above, there have been improvements made to several modules in the standard library, as well as to the CPython implementation. To read about all of the updates this new release includes, take a look at the <a class="reference external" href="https://docs.python.org/3/whatsnew/3.6.html">official notes</a>.</p>
</div>
</div>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Iv" title="Josh Berkus: Retiring from the Core Team">
            <h2>Josh Berkus: Retiring from the Core Team</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 11, 2017</span>.
            
        </p>

        Those of you in the PostgreSQL community will have noticed that I haven't been very active for the past year. &nbsp;My new work on Linux containers and Kubernetes has been even more absorbing than I anticipated, and I just haven't had a lot of time for PostgreSQL work.<br /><br />For that reason, as of today, I am stepping down from the PostgreSQL Core Team.<br /><br />I joined the PostgreSQL Core Team in 2003. &nbsp;I decided to take on project advocacy, with the goal of making PostgreSQL one of the top three databases in the world. &nbsp;Thanks to the many contributions by both advocacy volunteers and developers -- as well as the efforts by companies like EnterpriseDB and Heroku -- we've achieved that goal. &nbsp;Along the way, we proved that community ownership of an OSS project can compete with, and ultimately outlast, venture-funded startups.<br /><br />Now we need new leadership who can take PostgreSQL to the next phase of world domination. &nbsp;So I am joining Vadim, Jan, Thomas, and Marc in clearing the way for others.<br /><br />I'll still be around and still contributing to PostgreSQL in various ways, mostly around running the database in container clouds. &nbsp;It'll take a while for me to hand off all of my PR responsibilities for the project (assuming that I ever hand <i>all </i>of them off).<br /><br />It's been a long, fun ride, and I'm proud of the PostgreSQL we have today: both the database, and the community. &nbsp;Thank you for sharing it with me.
    </div>
    <div class="feedEntry">

        <a href="http://djangodeployment.com/2017/01/11/which-components-should-i-use-in-production/" title="Which components should I use in production?">
            <h2>Which components should I use in production?</h2>
        </a>

        <p class="discreet">
            
                  By Django deployment from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 11, 2017</span>.
            
        </p>

        <p>This is the last in a series of posts about whether you should choose Ubuntu or Windows, Gunicorn or uWSGI, MySQL or PostgreSQL, and Apache or nginx. I bring it altogether. The image illustrates the components I propose for a start.<br /></p> [&#8230;]<p>The post <a href="http://djangodeployment.com/2017/01/11/which-components-should-i-use-in-production/" rel="nofollow">Which components should I use in production?</a> appeared first on <a href="http://djangodeployment.com" rel="nofollow">Django deployment</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Iu" title="David Rader: How to: Pick a PostgreSQL Python driver">
            <h2>David Rader: How to: Pick a PostgreSQL Python driver</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 10, 2017</span>.
            
        </p>

        <p>Using Postgres with python is easy and provides first class database capabilities for applications and data processing. When starting a new project, you need to choose which PostgreSQL python driver to use. The best choice depends on your deployment, python version, and background. Here&#8217;s a quick guide to choosing between three popular python PostgreSQL drivers:</p>
<p><strong>Psycopg2</strong></p>
<p>This is the most common and widely supported Python PostgreSQL driver. It provides a DB-API compatible wrapper on top of the native libpq postgresql library. It supports automatic mapping of query results to python dictionaries as well as named tuples, and is commonly used by ORM&#8217;s and frameworks, including SQLAlchmey. Because psycopg2 uses libpq, it supports the same environment variables as libpq for connection properties (PGDATABASE, PGUSER, PGHOST, etc) as well as using a .pgpass file. And, supports <code>COPY</code> directly for bulk loading. If you use Postgres from multiple languages this driver will feel the most &#8220;native PG.&#8221;</p>
<p>But, the libpq dependency requires libpq-dev and python-dev packages on Linux or install packages on Windows and macOS for the shared objects/dll&#8217;s. Not an issue for a single developer machine or server, but hard to package for a cross-platform Python app (like our <a href="http://www.openscg.com/products/bigsql-devops/">BigSQl DevOps</a> management tool) or to use in a PyPy runtime.</p>
<p><strong>pg8000</strong></p>
<p>An actively maintained, pure python DB-API compatible driver that works across OS and in many different Python environments, such as PyPy and Jython. With no native dependencies, it is easy to package pg8000 for distribution with an application with Python 2 or Python 3. pg8000 tries to be focused on just PostgreSQL database access, ignoring some of the convenience functions in libpq. For example, pg800 does not directly support a .pgpass file or environment variables &#8211; but you can use the <a href="https://github.com/gmr/pgpasslib">pgpasslib</a> project in conjunction. pg8000 does not include the many Extras included with psycopg2 to retrieve dictionaries or named tuples but does support most data types.</p>
<p>pg8000 is a good choice for distributing with an application bundle or for environments where you can&#8217;t install native dependencies.</p>
<p><strong>asyncpg</strong></p>
<p>An exciting and new (in 2016) driver supporting Python/asyncio. Rather than using libpq and the text format protocol, asyncpg implements the Postgres binary protocol, which provides better type support and faster performance. asyncpg is designed (and tested) to be fast, able to achieve must higher retrieval speeds that either driver above. See the performance <a href="https://magic.io/blog/asyncpg-1m-rows-from-postgres-to-python/">benchmarking</a> provided by the authors. With the emphasis on speed, asyncpg does not support the DB-API so code <em>feels</em> different than other Python database access.</p>
<p>asyncpg is a C-extension, so only works with Cython and requires Python 3.5+; but has no dependencies, so a simple pip install (or app bundling) works and supports PostgreSQL 9.1+. asyncpg is definitely worth looking at if you&#8217;re using Python 3.5.</p>
<p>For more information, see the project pages for each driver discussed above:</p>
<ul>
<li><a href="http://initd.org/psycopg/">psycopg2</a></li>
<li><a href="https://github.com/mfenniak/pg8000">pg8000</a></li>
<li><a href="https://magicstack.github.io/asyncpg/current">asyncpg</a></li>
</ul>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3It" title="Hans-Juergen Schoenig: Checkpoint distance and amount of WAL">
            <h2>Hans-Juergen Schoenig: Checkpoint distance and amount of WAL</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 10, 2017</span>.
            
        </p>

        <p>Most people using PostgreSQL database systems are aware of the fact that the database engine has to send changes to the so called “Write Ahead Log” (= WAL) to ensure that in case of a crash the database will be able to recover to a consistent state safely and reliably. However, not everybody is aware [&#8230;]</p>
<p>The post <a href="http://www.cybertec.at/checkpoint-distance-and-amount-of-wal/" rel="nofollow">Checkpoint distance and amount of WAL</a> appeared first on <a href="http://www.cybertec.at" rel="nofollow">Cybertec - The PostgreSQL Database Company</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/how-to-implement-oauth2-using-django-rest-framework/" title="How to Implement OAuth2 using Django REST Framework">
            <h2>How to Implement OAuth2 using Django REST Framework</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 09, 2017</span>.
            
        </p>

        <p>Let’s paint a picture for you. You want to create a web and mobile application that allows your users to login more securely than [Token Authentication]. You know it’s possible, but you’re not sure how to implement something like this.</p>
<p>We can also use Facebook, Google, Twitter, Github, etc. to authenticate users. However, I’m just going to describe how to use OAuth to authenticate with <strong>JUST</strong> our application.</p>
<p>Maybe there is a package you can use? You’d be correct. There is a package you can use. OAuth Authentication implementation from scratch is complicated. Therefore, I recommend NOT re-inventing the wheel. I recommend using a package that already implements it. (I’ll write a post about how OAuth can be implemented yourself, if you’re interested in learning how this works).</p>
<p>I’m just going to pick a random OAuth package because it really doesn’t matter. The implementation of OAuth is the same no matter which package you choose. In this case, I’m going to use <code>django-rest-framework-social-oauth2</code>.</p>
<h2>Implementing OAuth2 using Django-REST-Framework-Social-OAuth2</h2>
<p>Let’s start by installing the package.</p>
<pre><code>$ pip install django-rest-framework-social-oauth2
</code></pre>
<p>Now, let’s add the package apps to our <code>INSTALLED_APPS</code>.</p>
<p><em>settings.py</em></p>
<pre><code>INSTALLED_APPS = (
    #...
    'oauth2_provider',
    'social_django',
    'rest_framework_social_oauth2,
)
</code></pre>
<p>Next, let’s include the URLs to our <code>urls.py</code>.</p>
<p><em>urls.py</em></p>
<pre><code>urlpatterns = patterns(
    # ...
    url(r'^auth/', include('rest_framework_social_oauth2.urls')),
)
</code></pre>
<p>Now, we need to set up the packages <code>CONTEXT_PROCESSORS</code>. If you are using Django 1.8+ you’ll add the <code>CONTEXT_PROCESSORS</code> in the <code>TEMPLATES</code> setting.</p>
<p><em>settings.py</em></p>
<pre><code>TEMPLATES = [
    {
        # ...
        'OPTIONS': {
            'context_processors': [
                # ...
                'social_django.context_processors.backends',
                'social_django.context_processors.login_redirect',
            ],
        },
    }
]
</code></pre>
<p>However, if you are using anything <em>BEFORE</em> Django 1.8, you’ll need to add the context processors like so…</p>
<p><em>settings.py</em></p>
<pre><code>TEMPLATE_CONTEXT_PROCESSORS = (
    # ...
    'social_django.context_processors.backends',
    'social_django.context_processors.login_redirect',
)
</code></pre>
<p>Now, we need some Authentication Backends so that Django and REST knows how to authenticate users. So, let’s add the backends to both settings.</p>
<p><em>settings.py</em></p>
<pre><code># DJANGO REST FRAMEWORK SETTINGS
REST_FRAMEWORK = {
    # ...
    'DEFAULT_AUTHENTICATION_CLASSES': (
        # ...
        'oauth2_provider.ext.rest_framework.OAuth2Authentication',
        'rest_framework_social_oauth2.authentication.SocialAuthentication',
    ),
}

# DJANGO SETTINGS 
AUTHENTICATION_BACKENDS = (
    # ...
    'rest_framework_social_oauth2.backends.DjangoOAuth2',
    'django.contrib.auth.backends.ModelBackend',
)
</code></pre>
<h3>Set up Web Application</h3>
<p>We have successfully setup our application to use OAuth2 in our Web Application. Just like every time you add a new app to your list of <code>INSTALLED_APPS</code>, you always need to run:</p>
<pre><code>$ python manage.py migrate
</code></pre>
<p>This command will build our database backend with the new models from the OAuth2 package.</p>
<p>Let’s run the application!</p>
<pre><code>$ python manage.py runserver
</code></pre>
<p>If the application starts correctly, we’ll go to <a href="http://localhost:8000/admin/">http://localhost:8000/admin/</a> and login with:</p>
<pre><code>username: adminadmin 
password: adminadmin
</code></pre>
<p>When you login successfully, you’ll see a list of different options: <code>Django OAuth Toolkit</code> and <code>Social_Django</code>.</p>
<p>Underneath <code>Django OAuth Toolkit</code>, near <code>Applications</code>, click <code>Add</code>.</p>
<p>Your application should be filled out to be the following:</p>
<pre><code>Client Id: **Do not change**
User: **click the hourglass and select the superuser**
Redirect URIs: **leave blank**
Client Type: “Confidential”
Authorization grant type: “Resource owner password-based”
Client secret: **Do not change**
Name: **Anything you want — maybe “Test Example”**
</code></pre>
<p>Next, click save to save that application.</p>
<h3>Test the Application</h3>
<p>Use either CURL (command line) or use [Postman] to create a POST request to your web application (<a href="http://localhost:8000/auth/token">http://localhost:8000/auth/token</a> using the following information:</p>
<pre><code>username=adminadmin
password=adminadmin
client_id=QKaPafSal2lYYfIYIDSKCC3hoj0TRPLFnZYJNE0h
client_secret=bvQDk9bIwVS28VSNZFP5ehgsrnQroWP5xHccdradOvqxonWSqC1soy7HzaiIiRzCQi73o0pPKyWp7dEoS8DgrZWLoiwJf7iZ8kymv1rb1s3Hx3XSTGQgDmVBqveOQT5H
grant_type=password
</code></pre>
<p>If you are using CURL, you can run the following command:</p>
<pre><code>$ curl -X POST -d "client_id=QKaPafSal2lYYfIYIDSKCC3hoj0TRPLFnZYJNE0h&amp;client_secret=bvQDk9bIwVS28VSNZFP5ehgsrnQroWP5xHccdradOvqxonWSqC1soy7HzaiIiRzCQi73o0pPKyWp7dEoS8DgrZWLoiwJf7iZ8kymv1rb1s3Hx3XSTGQgDmVBqveOQT5H&amp;grant_type=password&amp;username=adminadmin&amp;password=adminadmin" http://localhost:8000/auth/token
</code></pre>
<p>If you are using Postman, your interface should look like this:</p>
<p><img alt="" class="alignnone size-large wp-image-198" height="458" src="http://www.chrisbartos.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-09-at-1.34.20-PM-1024x750.png" width="625" /></p>
<p>This will retrieve a secret token for use for authentication by our user.</p>
<p>Now, we need to use the access token that we received and create an <code>Authorization</code> header in the form:</p>
<pre><code>Authorization: Bearer [access_token]
</code></pre>
<p>The access token that I received happens to look like this: <code>71AVaiCidnYcD2ct3Mqgat9j4jo6Xl</code>.</p>
<p>So, if I want to access <a href="http://localhost:8000/polls/api/questions/1">http://localhost:8000/polls/api/questions/1</a> I have to create a header using my access token in order to access that question.</p>
<p>In CURL, I would do something like this:</p>
<pre><code>$ curl -H "Authorization: Bearer 71AVaiCidnYcD2ct3Mqgat9j4jo6Xl" -X GET http://localhost:8000/polls/api/questions/1
</code></pre>
<p>In Postman I do something like this:</p>
<p><img alt="" class="alignnone size-large wp-image-199" height="435" src="http://www.chrisbartos.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-09-at-1.54.58-PM-1024x713.png" width="625" /></p>
<p>Just to test it out to make sure that I’m doing this right, I will remove the Header from the request and see if Django will let me access the data. Not surprisingly, it doesn’t let me in!</p>
<p><a href="http://www.chrisbartos.com/wp-content/uploads/2017/01/django_polls_oauth.zip">Click here for my Sample Code — remember to install the package using pip</a></p>
<h3>Homework (because this helps you apply what you learned)</h3>
<ol>
<li>Setup a new Django REST Framework web application</li>
<li>Add an endpoint, a serializer and make sure only authenticated users can access the data.</li>
<li>Follow the steps above and try OAuth2 out for yourself. Get it to work.</li>
<li>If you have questions <a href="mailto:me@chrisbartos.com">email me</a></li>
</ol>
<p>Now, you know how to implement OAuth2 in your own application. You can use the similar steps to get this setup for Facebook, Google, Twitter, Github, etc. so you can allow users to sign in to your application using accounts that they already have and use!</p>
<p>Try this out, see if you can get it work for yourself!</p>
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/GoDjango/~3/kzL8vrCJ_SA/" title="5 Reasons I don't think you shold use the django admin">
            <h2>5 Reasons I don't think you shold use the django admin</h2>
        </a>

        <p class="discreet">
            
                  By GoDjango - Django Screencasts from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 09, 2017</span>.
            
        </p>

        <p>Have you ever needed to quickly modify data or look it up. But while the task is simple the entire process of changing one value frustrates you?</p>
<p>Well, this is very common to me, bad UX is annoying. I quite often have to either lookup, or edit, two disparate, yet related pieces of data, and sometimes it is an exercise in frustration.</p>
<p>An all to common occurrence is I just needed to check the edit history of a "Company" our database. This is a simple process, go to the admin find the Company model, do a search and you have your answer.</p>
<p>Except, it isn't that easy in reality. Lets run through what really happened.</p>
<p>I went to "<a href="http://superawesomesite.com/admin/">http://superawesomesite.com/admin/</a>" and logged in.</p>
<p>I then looked at how my model options extended well below the fold of my browser so I had to scroll. No problem I'll just hit "ctrl+f" and search for it. WTF!!! where is my company model?</p>
<p>I then proceed to scroll down and finally find it only to remember it was pluralized. If I had searched for "Companies" I would have been good to go, grrrrr.</p>
<p>I click into and see the list of companies available to me. I see that there is a search feature at the top so I do a search for the relevant information. Unfortunately, I don't know the company name that is what I am trying to find out.</p>
<p>Except, we aren't filtering our search in the admin based on that field. So no results show up.</p>
<p>No problem I can do a list filter on the side. So I set the correct filters and still no luck because someone didn't set all the metadata that was supposed to be set for the company. Again grrrrr.</p>
<p>Finally, I abandoned the admin and opened up the django/python shell and did a query with the model, and in about 30 seconds had the record I needed. Took the id and plugged that into the django admin and I was good to go.</p>
<p>This was an exercise in frustration because the 30 seconds that was taken during development to decide which fields should be filtered didn't let that person imagine the field I needed. Also the fact that whomever added the company didn't add all the correct information, made it almost impossible to find the data. In the end I had to go outside this system that is hailed as one of the greatest tools for django to get the information I needed.</p>
<p>I propose we as a community reduce our reliance on the django admin, especially in production.</p>
<p>I also created a Video on the 5 reasons we shouldn't use the django admin. </p>
<img alt="" height="1" src="http://feeds.feedburner.com/~r/GoDjango/~4/kzL8vrCJ_SA" width="1" />
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Il" title="Bruce Momjian: SSL Certificates and Certificate Authorities">
            <h2>Bruce Momjian: SSL Certificates and Certificate Authorities</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 09, 2017</span>.
            
        </p>

        <p>When setting up <a class="txt2html" href="https://en.wikipedia.org/wiki/Transport_Layer_Security" style="text-decoration: none;">SSL</a> in Postgres, you can't just enable
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/runtime-config-connection.html#RUNTIME-CONFIG-CONNECTION-SECURITY" style="text-decoration: none;">SSL</a>. You must
also <a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/ssl-tcp.html" style="text-decoration: none;">install</a> a signed certificate on the server.
</p>
<p>The first step is to create a <a class="txt2html" href="https://en.wikipedia.org/wiki/Certificate_signing_request" style="text-decoration: none;">certificate signing request</a> (CSR)
file that contains the host name of the database server.  Once created, there are three ways to sign a CSR to create a
certificate:
</p>
<ul>
  <li>Self-signed
  </li><li>Signed by a local certificate authority
  </li><li>Signed by a public <a class="txt2html" href="https://en.wikipedia.org/wiki/Certificate_authority" style="text-decoration: none;">certificate authority</a>
</li></ul>
<p>If the certificate is to be self-signed, use the key created by the certificate signing request to
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/ssl-tcp.html#SSL-CERTIFICATE-CREATION" style="text-decoration: none;">create</a> a certificate.  If using a local certificate
authority, sign the CSR file with the local certificate authority's key.
</p>
<p><a href="http://momjian.us/main/blogs/pgblog/2017.html#January_9_2017">Continue Reading &raquo;</a></p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ij" title="Jobin Augustine: pg_repack in Postgres by BigSQL">
            <h2>Jobin Augustine: pg_repack in Postgres by BigSQL</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 09, 2017</span>.
            
        </p>

        <p>Many DBAs agree that one of the most useful extension in their arsenal is pg_repack. Pg_repack addresses a serious shortcoming in Postgres: doing VACUUM FULL online. Due to the way Postgres handles the MVCC, tables and indexes become bloated. Dead tuples are addressed by AUTOVACUUM and space will be marked free. In many situations a VACUUM FULL becomes unavoidable because AUTOVACUUM just leaves scattered and fragmented free space in the table as it is. DBA may have to do VACUMM FULL to release such free space back to disk.</p>
<p>Unfortunately VACUUM FULL requires an exclusive lock on the table during an operation. This can’t be performed while the table is being used. This is where pg_repack comes to the rescue of the DBA &#8212; to perform a VACUUM FULL almost fully online (there could be a momentary lock).</p>
<p>The popularity of this extension among DBAs led the Postgres by BigSQL project to add pg_repack as a ready to install package.</p>
<h2>Installation</h2>
<p>Installing pg_repack is quite easy with the pgcli command line.</p>
<p><code>$ ./pgc list</code> Displays all installable versions of extensions. Let&#8217;s install repack13-pg96 (the package version depends on the postgres version we have installed). Installing this is pretty straightforward:</p>
<p><code>$ ./pgc install repack13-pg96</code></p>
<p>Installation of pg_repack doesn’t require either a restart or reload. As is commonly known, the pg_repack installation has 2 components: the actual extension and a client tool to invoke the pg_repack functionality. We can create the extension in the desired database as follows from the psql command interface:</p>
<p><code>postgres=# \c db1<br />
postgres=# CREATE EXTENSION pg_repack;<br />
CREATE EXTENSION</code></p>
<h2>Test Environment</h2>
<p>To create a test environment, run pgbench from the command line:</p>
<p><code>pgbench -U postgres -i -s 10 db1</code></p>
<p>This produced a pgbench_accounts table of 128 MB. To create a bloat, I ran the update twice.</p>
<p><code>db1=# update pgbench_accounts set abalance=abalance;</code></p>
<p>This caused the table to grow up to 384 MB. In a couple of minutes, AUTOVACUUM kicked in and cleans up all dead tuples as expected.</p>
<p><code>db1=# select n_live_tup,n_dead_tup from pg_stat_user_tables where relname='pgbench_accounts';<br />
 n_live_tup | n_dead_tup<br />
------------+------------<br />
     997705 |          0</code></p>
<p>However the tablesize remained at 384 MB</p>
<p><code>db1=# \dt+<br />
                          List of relations<br />
 Schema |       Name       | Type  |  Owner   |  Size   | Description<br />
--------+------------------+-------+----------+---------+-------------<br />
 public | pgbench_accounts | table | postgres | 384 MB  |</code></p>
<h2>VACUUM FULL using pg_repack</h2>
<p>pg_repack is invoked using the included command line utility. We can repack every table in a database like so:</p>
<p><code>$ pg_repack db1<br />
INFO: repacking table "pgbench_tellers"<br />
INFO: repacking table "pgbench_accounts"<br />
INFO: repacking table "pgbench_branches"</code></p>
<p>Where db1 is the name of the database.</p>
<p>Or we can repack individual tables:</p>
<p><code>$ pg_repack --no-order --table pgbench_accounts --table pgbench_branches db1<br />
INFO: repacking table "pgbench_accounts"<br />
INFO: repacking table "pgbench_branches"</code></p>
<p>After running pg_repack, the space consumption is back to 128MB</p>
<p><code>db1=# \dt+<br />
                            List of relations<br />
 Schema |       Name       | Type  |  Owner   |    Size    | Description<br />
--------+------------------+-------+----------+------------+-------------<br />
 public | pgbench_accounts | table | postgres | 128 MB     |</code></p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ik" title="Giulio Calacoci: Barman 2.1 and the new –archive option">
            <h2>Giulio Calacoci: Barman 2.1 and the new –archive option</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 09, 2017</span>.
            
        </p>

        <h2>Barman 2.1</h2>
<p>Version 2.1 of <a href="http://www.pgbarman.org/">Barman, backup and recovery manager for PostgreSQL</a>, was released Thursday, Jan. 5.</p>
<p>The new release, along with several bugfixes, introduces preliminary support for the upcoming PostgreSQL 10, and adds the &#8211;archive option to the switch-xlog command.</p>
<h2>switch-xlog &#8211;archive</h2>
<p>The new &#8211;archive option is especially useful when setting up a new server.</p>
<p>Until now, the switch-xlog command used to force the PostgreSQL server to switch to a different transaction log file. Now, Barman also gives the &#8211;archive option, which triggers WAL archiving after the xlog switch, and forces Barman to wait for the archival of the closed WAL file.</p>
<p>By default Barman expects to receive the WAL in 30 seconds, the amount of seconds to wait can be changed using the &#8211;archive-timeout option.<br />
If the switch-xlog command returns an error, it means no WAL file has been archived, and the Barman server is not able to receive WALs from PostgreSQL.</p>
<p>This option allows the users to test the entire WAL archiving process, identifying configuration issues.</p>
<h2>Conclusions</h2>
<p>The Barman dev team is very happy about this small release. Containing primarily bug fixes, it increases the robustness of Barman thanks to the feedback received through the Barman mailing list and the GitHub issue tracker.</p>
<p>If you are interested in helping us by sponsoring the development, even partially, drop us a line (info@pgbarman.org).</p>
<h2>Links</h2>
<p><a href="http://www.pgbarman.org/">Website</a><br />
<a href="https://sourceforge.net/projects/pgbarman/files/2.1/">Download</a><br />
<a href="http://docs.pgbarman.org/release/2.1/">Online Documentation</a><br />
<a href="http://docs.pgbarman.org/release/2.1/barman.1.html">Man page, section 1</a><br />
<a href="http://docs.pgbarman.org/release/2.1/barman.5.html">Man page, section 5</a><br />
<a href="http://www.pgbarman.org/support/">Support</a></p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ii" title="Craig Kerstiens: Simple but handy Postgres features">
            <h2>Craig Kerstiens: Simple but handy Postgres features</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 08, 2017</span>.
            
        </p>

        <p>It seems each week when I&rsquo;m reviewing data with someone a feature comes up that they had no idea existed within Postgres. In an effort to continue documenting many of the features and functionality that are useful, here&rsquo;s a list of just a few that you may find handy the next time you&rsquo;re working with your data.</p>

<h3>Psql, and \e</h3>

<p>This one I&rsquo;ve <a href="http://www.craigkerstiens.com/2013/02/13/How-I-Work-With-Postgres/">covered before</a>, but it&rsquo;s worth restating. Psql is a great editor that already comes with Postgres. If you&rsquo;re comfortable on the CLI you should consider giving it a try. You can even setup you&rsquo;re own <code>.psqlrc</code> for it so that it&rsquo;s well customized to your liking. In particular turning <code>\timing</code> on is especially useful. But even with all sorts of customization if you&rsquo;re not aware that you can use your preferred editor by using <code>\e</code> then you&rsquo;re missing out. This will allow you to open up the last run query, edit it, save–and then it&rsquo;ll run for you. Vim, Emacs, even Sublime text works just take your pick by setting your <code>$EDITOR</code> variable.</p>

<!--more-->


<h3>Watch</h3>

<p>Ever sit at a terminal running a query over and over to see if something on your system changed? If you&rsquo;re debugging something whether locally or even live in production, watching data change can be key to figuring out. Instead of re-running your query you could simply use the <code>\watch</code> command in Postgres, this will re-run your query automatically every few seconds.</p>

<p>```sql
SELECT now() &ndash;</p>

<pre><code>   query_start, 
   state, query 
</code></pre>

<p>FROM pg_stat_activity
\watch
```</p>

<h3>JSONB pretty print</h3>

<p>I love <a href="https://www.citusdata.com/blog/2016/07/14/choosing-nosql-hstore-json-jsonb/">JSONB</a> as a datatype. Yes, in cases it won&rsquo;t be the <a href="http://blog.heapanalytics.com/when-to-avoid-jsonb-in-a-postgresql-schema/">optimal</a> for performance (though at times it can be perfectly fine). If I&rsquo;m hitting some API that returns a ton of data, I&rsquo;m usually not using all of it right away. But, you never know when you&rsquo;ll want to use the rest of it. I use Clearbit this way today, and for safety sake I save all the JSON result instead of de-normalizing it. Unfortunately, when you query this in Postgres you get one giant compressed text of JSON. Yes, you could pipe out to something like jq, or you could simply use Postgres built in function to make it legible:</p>

<p>```sql
SELECT jsonb_pretty(clearbit_response)
FROM lookup_data;</p>

<pre><code>                            jsonb_pretty
</code></pre>

<hr />

<p> {</p>

<pre><code> "person": { 
     "id": "063f6192-935b-4f31-af6b-b24f63287a60", 
     "bio": null, 
     "geo": { 
         "lat": 37.7749295, 
         "lng": -122.4194155,                                              
         "city": "San Francisco", 
         "state": "California", 
         "country": "United States", 
         "stateCode": "CA", 
         "countryCode": "US" 
     }, 
     "name": { 
     ...
</code></pre>

<p>```</p>

<h3>Importing my data into Google</h3>

<p>This one isn&rsquo;t Postgres specific, but I use it on a weekly basis and it&rsquo;s key for us at Citus. If you use something like Heroku Postgres, dataclips is an extremely handy feature that lets you have a real-time view of a query and the results of it, including an anonymous URL you can it for it. At Citus much like we did at Heroku Postgres we have a dashboard in google sheets which pulls in this data in real-time. To do this simple select a cell then put in: <code>=importdata("pathtoyourdataclip.csv")</code>. Google will import any data using this as long as it&rsquo;s in CSV form. It&rsquo;s a great lightweight way to build out a dashboard for your business without rolling your own complicated dashboarding or building out a complex ETL pipeline.</p>

<p>I&rsquo;m sure I&rsquo;m missing a ton of the smaller features that you use on a daily basis. Let me know <a href="https://www.twitter.com/craigkerstiens">@craigkerstiens</a> the ones I forgot that you feel should be listed.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ih" title="gabrielle roth: PDXPUG – January meeting">
            <h2>gabrielle roth: PDXPUG – January meeting</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 07, 2017</span>.
            
        </p>

        <p><strong>When</strong>: 6-8pm Thursday Jan 19, 2017<br />
<strong>Where</strong>: iovation<br />
<strong>Who</strong>: Mark Wong<br />
<strong>What</strong>: pglogical</p>
<p>Mark Wong will give an overview of pglogical, the latest replication option for Postgres. It&#8217;s a lower-impact option than trigger-based replication, and features include the ability to replicate only the databases and tables you choose from a cluster. Part of the talk will cover use cases and future development plans.</p>
<p>Find out more here: <a href="https://2ndquadrant.com/en/resources/pglogical/" rel="nofollow">https://2ndquadrant.com/en/resources/pglogical/</a></p>
<p>Mark leads the 2ndQuadrant performance practice as a Performance Consultant for English Speaking Territories, based out of Oregon in the<br />
USA.</p>
<p>&#8212;<br />
If you have a job posting or event you would like me to announce at the meeting, please send it along. The deadline for inclusion is 5pm the day before the meeting.<br />
&#8212;</p>
<p>Our meeting will be held at iovation, on the 32nd floor of the US Bancorp Tower at 111 SW 5th (5th &amp; Oak). It&#8217;s right on the Green &amp; Yellow Max lines. Underground bike parking is available in the parking garage; outdoors all around the block in the usual spots. No bikes in the office, sorry!</p>
<p>iovation provides us a light dinner (usually sandwiches or pizza).</p>
<p>Elevators open at 5:45 and building security closes access to the floor at 6:30.</p>
<p>See you there!</p><br />  <a href="http://feeds.wordpress.com/1.0/gocomments/pdxpug.wordpress.com/516/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/pdxpug.wordpress.com/516/" /></a> <img alt="" border="0" height="1" src="https://pixel.wp.com/b.gif?host=pdxpug.wordpress.com&#038;blog=30930172&#038;post=516&#038;subd=pdxpug&#038;ref=&#038;feed=1" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/how-to-implement-custom-authentication-with-django-rest-framework/" title="How to Implement Custom Authentication with Django REST Framework">
            <h2>How to Implement Custom Authentication with Django REST Framework</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 06, 2017</span>.
            
        </p>

        <h2>Introduction to Custom Authentication</h2>
<p>Custom Authentication in Django REST Framework is the way you would create any time of authentication you would want. In fact, inside of the internals of DRF, you will find every other authentication scheme that I’ve talked about using CustomAuthentication. So, let’s look at an example of how you would implement something like this.</p>
<h2>How to Implement Custom Authentication</h2>
<p><strong>WARNING</strong>: The example I’m about to show you is VERY VERY bad for security so DON’T use it in production. <img alt="🙂" class="wp-smiley" src="https://s.w.org/images/core/emoji/2.2.1/72x72/1f642.png" style="height: 1em;" /></p>
<p>First, you will need to override the <code>BaseAuthentication</code> class. It looks like this:</p>
<p><em>my_proj/accounts/auth.py</em> from django.contrib.auth.models import User from rest_framework.authentication import BaseAuthentication from rest_framework import exceptions</p>
<pre><code>class MyCustomAuthentication(BaseAuthentication):
    def authenticate(self, request):
        username = request.GET.get("username")

        if not username: # no username passed in request headers
            return None # authentication did not succeed

        try:
            user = User.objects.get(username=username) # get the user
        except User.DoesNotExist:
            raise exceptions.AuthenticationFailed('No such user') # raise exception if user does not exist

        return (user, None) # authentication successful
</code></pre>
<p>I called the new class <code>MyCustomAuthentication</code>. If you look at what this does, it retrieves a <code>username</code> as a <code>GET</code> request and will try to find a user with that <code>username</code>. (You should now understand why this is a stupid example).</p>
<p>Next, in <code>settings.py</code> you’ll want to update the <code>DEFAULT_AUTHENICATION</code> setting.</p>
<p><em>settings.py</em> REST_FRAMEWORK = { &#8216;DEFAULT_AUTHENTICATION_CLASSES&#8217;: ( &#8216;accounts.auth.MyCustomAuthentication&#8217;, ), &#8216;DEFAULT_PERMISSION_CLASSES&#8217;: ( &#8216;rest_framework.permissions.IsAuthenticated&#8217;, ) }</p>
<p>And that is LITERALLY all you need to do to create a new authentication scheme. Download the custom code below and try going to the following URL:</p>
<p><a href="http://localhost:8000/polls/api/questions/1/?username=chris">http://localhost:8000/polls/api/questions/1/?username=chris</a></p>
<p>You should be able to see the data. Also, if you go to:</p>
<p><a href="http://localhost:8000/polls/api/questions/1/">http://localhost:8000/polls/api/questions/1/</a></p>
<p>The authentication scheme should deny you from getting any data at all.</p>
<p><a href="http://www.chrisbartos.com/wp-content/uploads/2017/01/django_polls_custom.zip">Click Here to Download the Sample Code</a></p>
<h2>Homework</h2>
<ol>
<li>Run the sample code and go to the two URLs above.</li>
<li>Try to implement your own Session Authentication scheme WITHOUT enforcing CSRF tokens using Custom Authentication. <a href="https://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/authentication.py#L110">You can see how Session Authentication is implemented here</a></li>
</ol>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ig" title="Bruce Momjian: Use Kill -9 Only in an Emergency">
            <h2>Bruce Momjian: Use Kill -9 Only in an Emergency</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 06, 2017</span>.
            
        </p>

        <p>During normal server shutdown, sessions are disconnected, dirty
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/runtime-config-resource.html#RUNTIME-CONFIG-RESOURCE-MEMORY" style="text-decoration: none;"><em>shared buffers</em></a> and pending
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/wal-intro.html" style="text-decoration: none;">write-ahead log</a> (WAL) records are flushed to durable storage, and
a clean shutdown record is written to <a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/wal-internals.html" style="text-decoration: none;"><em>pg_control</em></a>.  During the next
server start, <em>pg_control</em> is checked, and if the previous shutdown was clean, startup can ignore the WAL and start immediately.
</p>
<p>Unfortunately, a clean shutdown can take some time, and impatient database administrators might get into the habit of using <em>kill -9</em> or
<em>pg_ctl -m immediate</em> to quicken the shutdown.  While this does have the intended effect, and you will not lose any committed
transactions, it greatly slows down the next database startup because all WAL generated since the last completed checkpoint must
be replayed.  You can identify an unclean shutdown by looking at the server logs for these two ominous lines:
</p>
<p><blockquote>
</p><pre class="quote_explicit">
LOG:  database system was interrupted; last known up at 2016-10-25 12:17:28 EDT
LOG:  database system was not properly shut down; automatic recovery in progress
</pre>
<p><a href="http://momjian.us/main/blogs/pgblog/2017.html#January_6_2017">Continue Reading &raquo;</a></p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3If" title="Andrew Dunstan: Managed Database Services – pros and cons">
            <h2>Andrew Dunstan: Managed Database Services – pros and cons</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 06, 2017</span>.
            
        </p>

        <p>Using a managed service is a very attractive proposition. You are offloading a heck of a lot of worry, especially when it comes to something as complicated and, let&#8217;s face it, specialized as a database. Someone else will set it up for you, and back it up, and keep it running, without you having to worry overmuch about it. However, there are downsides. You can only get what the manager is offering. Often that&#8217;s good enough. But needs change, and I have often seen people start with managed services, only to find that they want more than they can get that way.</p>
<p>Just yesterday I received a complaint that the Redis Foreign Data Wrapper, which I have done a lot of work on, is not available on Amazon RDS. And that&#8217;s completely understandable. Amazon only provide a limited number of extensions, and this isn&#8217;t one of them. At least one other managed service, Heroku, does offer this extension, but there are others it doesn&#8217;t offer.</p>
<p>So the lesson is: choose your managed service, or even whether to use a managed service at all, very carefully, taking into account both your current needs and your likely future needs.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ie" title="Michael Paquier: Postgres 10 highlight - Quorum set of synchronous standbys">
            <h2>Michael Paquier: Postgres 10 highlight - Quorum set of synchronous standbys</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 06, 2017</span>.
            
        </p>

        <p>Today’s post, the first one of 2017, is about the following feature of the
upcoming Postgres 10:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>commit: 3901fd70cc7ccacef1b0549a6835bb7d8dcaae43
author: Fujii Masao &lt;fujii@postgresql.org&gt;
date: Mon, 19 Dec 2016 21:15:30 +0900
Support quorum-based synchronous replication.

This feature is also known as "quorum commit" especially in discussion
on pgsql-hackers.

This commit adds the following new syntaxes into synchronous_standby_names
GUC. By using FIRST and ANY keywords, users can specify the method to
choose synchronous standbys from the listed servers.

FIRST num_sync (standby_name [, ...])
ANY num_sync (standby_name [, ...])

The keyword FIRST specifies a priority-based synchronous replication
which was available also in 9.6 or before. This method makes transaction
commits wait until their WAL records are replicated to num_sync
synchronous standbys chosen based on their priorities.

The keyword ANY specifies a quorum-based synchronous replication
and makes transaction commits wait until their WAL records are
replicated to *at least* num_sync listed standbys. In this method,
the values of sync_state.pg_stat_replication for the listed standbys
are reported as "quorum". The priority is still assigned to each standby,
but not used in this method.

The existing syntaxes having neither FIRST nor ANY keyword are still
supported. They are the same as new syntax with FIRST keyword, i.e.,
a priority-based synchronous replication.

Author: Masahiko Sawada
Reviewed-By: Michael Paquier, Amit Kapila and me
Discussion: &lt;CAD21AoAACi9NeC_ecm+Vahm+MMA6nYh=Kqs3KB3np+MBOS_gZg@mail.gmail.com&gt;

Many thanks to the various individuals who were involved in
discussing and developing this feature.
</code></pre>
</div>

<p>9.6 has introduced the possibility to specify multiple synchronous standbys
by extending the syntax of
<a href="https://www.postgresql.org/docs/devel/static/runtime-config-replication.html#runtime-config-replication-master">synchronous_standby_names</a>.
For example values like ‘N (standby_1,standby_2, … ,standby_M)’ allow
a primary server to wait for commit confirmations from N standbys among the
set of M nodes defined in the list given by user, depending on the availability
of the standbys at the moment of the transaction commit, and their reported
WAL positions for write, apply or flush. In this case, though, the standbys
from which a confirmation needs to be waited for are chosen depending on their
order in the list of the parameter.</p>

<p>Being able to define quorum sets of synchronous standbys provides more
flexibility in some availability scenarios. In short, it is possible to
validate a commit after receiving a confirmation from N standbys, those
standbys being <em>any</em> node listed in the M nodes of synchronous_standby_names.
So this facility is actually useful for example in the case of deployments
where there is a primary with two or more standbys to bring more flexibility
in the way synchronous standbys are chosen. Be careful though that it is
better to have a low latency between each node, but there is nothing new
here…</p>

<p>In order to support this new feature, and as mentioned in the commit message,
the grammar of synchronous_standby_names has been extended with a set of
keywords.</p>

<ul>
  <li>ANY maps to the quorum behavior, meaning that any node in the set can be
  used to confirm a commit.</li>
  <li>FIRST maps to the 9.6 behavior, giving priority to the nodes listed
  first (higher priority number defined).</li>
</ul>

<p>Those can be used as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code># Quorum set of two nodes
any 2(node_1,node_2)
# Priority set of two nodes, with three standbys
first 1(node_1,node_2,node_3)
</code></pre>
</div>

<p>Note as well that not using any keyword means ‘first’ for
backward-compatibility. And that those keywords are case insensitive.</p>

<p>One last thing to know is that pg_stat_replication marks the standbys
in a quorum set with… ‘quorum’. For example let’s take a primary with
two standbys node_1 and node_2.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>=# ALTER SYSTEM SET synchronous_standby_names = 'ANY 2(node_1,node_2)';
ALTER SYSTEM
=# SELECT pg_reload_conf();
 pg_reload_conf
----------------
 t
(1 row)
</code></pre>
</div>

<p>And here is how they show up to the user:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>=# SELECT application_name, sync_priority, sync_state FROM pg_stat_replication;
 application_name | sync_priority | sync_state
------------------+---------------+------------
 node_1           |             1 | quorum
 node_2           |             2 | quorum
(2 rows)
</code></pre>
</div>

<p>Note that the priority number does not have much meaning for a quorum set,
though it is useful to see them if user is willing to switch from ‘ANY’
to ‘FIRST’ to understand what would be the standbys that would be considered
as synchronous after the switch (this is still subject to discussions on
community side, and may change by the release of Postgres 10).</p>
    </div>
    <div class="feedEntry">

        <a href="https://yoongkang.com/blog/event-sourcing-in-django/" title="Event sourcing in Django">
            <h2>Event sourcing in Django</h2>
        </a>

        <p class="discreet">
            
                  By Yoong Kang Lim from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 05, 2017</span>.
            
        </p>

        <p>Django comes with "batteries included" to make CRUD (create, read, update, delete) operations easy. It's nice that the CR part (create and read) of CRUD is so easy, but have you ever paused to think about the UD part (update and delete)?</p>
<p>Let's look at delete. All you need to do is this:</p>
<div class="highlight"><pre><span></span><span class="n">ReallyImportantModel</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>  <span class="c1"># gone from the database forever</span>
</pre></div>


<p>Just one line, and your data is gone forever. It can be done accidentally. Or you can be do it deliberately, only to later realise that your old data is valuable too.</p>
<p>Now what about updating? </p>
<p><em>Updating is deleting in disguise</em>. </p>
<p>When you update, you're deleting the old data and replacing it with something new. <em>It's still deletion</em>.</p>
<div class="highlight"><pre><span></span><span class="n">important</span> <span class="o">=</span> <span class="n">ReallyImportantModel</span><span class="o">.</span><span class="n">object</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">important</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'new_data'</span><span class="p">:</span> <span class="s1">'This is new data'</span><span class="p">})</span>  <span class="c1"># OLD DATA GONE FOREVER</span>
</pre></div>


<p>Okay, but why do we care?</p>
<p>Let's say we want to know the state of <code>ReallyImportantModel</code> 6 months ago. Oh that's right, you've deleted it, so you can't get it back. </p>
<p>Well, that's not exactly true -- you can recreate your data from backups (if you don't backup your database, <strong>stop reading right now and fix that immediately</strong>). But that's clumsy.</p>
<p>So by only storing the current state of the object, you lose all the contextual information on how the object arrived at this current state. Not only that, you make it difficult to make projections about the future.</p>
<p>Event sourcing <sup id="fnref-1"><a class="footnote-ref" href="https://www.djangoproject.com/rss/community/blogs/#fn-1">1</a></sup> can help with that.</p>
<h2>Event sourcing</h2>
<p>The basic concept of event sourcing is this:</p>
<ul>
<li>Instead of just storing the current state, we also store the <em>events</em> that lead up to the current state</li>
<li>Events are replayable. We can travel back in time to any point by replaying every event up to that point in time</li>
<li>That also means we can recover the current state just by replaying every event, even if the current state was accidentally deleted</li>
<li>Events are <em>append-only</em>. </li>
</ul>
<p>To gain an intuition, let's look at an event sourcing system you're familiar with: your bank account.</p>
<p>Your "state" is your account balance, while your "events" are your transactions (deposit, withdrawal, etc.). </p>
<p>Can you imagine a bank account that only shows you the current balance? </p>
<p>That is clearly unacceptable ("Why do I only have $50? Where did my money go? If only I could see the the history."). So we always store the history of transfers as the source of truth.</p>
<h2>Implementing event sourcing in Django</h2>
<p>Let's look at a few ways to do this in Django.</p>
<h3>Ad-hoc models</h3>
<p>If you have a one or two important models, you probably don't need a generalizable event sourcing solution that applies to all models. </p>
<p>You could do it on an ad-hoc basis like this, if you can have a relationship that makes sense:</p>
<div class="highlight"><pre><span></span><span class="c1"># in an app called 'account'</span>
<span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">django.conf</span> <span class="kn">import</span> <span class="n">settings</span>


<span class="k">class</span> <span class="nc">Account</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bank account&quot;&quot;&quot;</span>
    <span class="n">balance</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">AUTH_USER_MODEL</span><span class="p">,</span> <span class="n">related_name</span><span class="o">=</span><span class="s1">'account'</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Transfer</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a transfer in or out of an account. A positive amount indicates</span>
<span class="sd">    that it is a transfer into the account, whereas a negative amount indicates</span>
<span class="sd">    that it is a transfer out of the account.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">account</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="s1">'account.Account'</span><span class="p">,</span> <span class="n">on_delete</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">PROTECT</span><span class="p">,</span> 
                                <span class="n">related_name</span><span class="o">=</span><span class="s1">'transfers'</span><span class="p">)</span>
    <span class="n">amount</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DateTimeField</span><span class="p">()</span>
</pre></div>


<p>In this case your "state" is in your <code>Account</code> model, whereas your <code>Transfer</code> model contains the "events".</p>
<p>Having <code>Transfer</code> objects makes it trivial to recreate any account.</p>
<h3>Using an Event Store</h3>
<p>You could also use a single <code>Event</code> model to store every possible event in any model. A nice way to do this is to encode the changes in a JSON field. </p>
<p>This example uses Postgres:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">django.contrib.contenttypes.fields</span> <span class="kn">import</span> <span class="n">GenericForeignKey</span>
<span class="kn">from</span> <span class="nn">django.contrib.contenttypes.models</span> <span class="kn">import</span> <span class="n">ContentType</span>
<span class="kn">from</span> <span class="nn">django.contrib.postgres.fields</span> <span class="kn">import</span> <span class="n">JSONField</span>
<span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>


<span class="k">class</span> <span class="nc">Event</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Event table that stores all model changes&quot;&quot;&quot;</span>
    <span class="n">content_type</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">ContentType</span><span class="p">,</span> <span class="n">on_delete</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">PROTECT</span><span class="p">)</span>
    <span class="n">object_id</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">PositiveIntegerField</span><span class="p">()</span>
    <span class="n">time_created</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DateTimeField</span><span class="p">()</span>
    <span class="n">content_object</span> <span class="o">=</span> <span class="n">GenericForeignKey</span><span class="p">(</span><span class="s1">'content_type'</span><span class="p">,</span> <span class="s1">'object_id'</span><span class="p">)</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">JSONField</span><span class="p">()</span>
</pre></div>


<p>You can then add methods to any model that mutates the state:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Account</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">balance</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">AUTH_USER_MODEL</span><span class="p">,</span> <span class="n">related_name</span><span class="o">=</span><span class="s1">'account'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_deposit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">amount</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Deposit money into account&quot;&quot;&quot;</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'made_deposit'</span><span class="p">,</span>
                <span class="s1">'amount'</span><span class="p">:</span> <span class="n">amount</span><span class="p">,</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">balance</span> <span class="o">+=</span> <span class="n">amount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">make_withdrawal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">amount</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Withdraw money from account&quot;&quot;&quot;</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'made_withdrawal'</span><span class="p">,</span>
                <span class="s1">'amount'</span><span class="p">:</span> <span class="o">-</span><span class="n">amount</span><span class="p">,</span>  <span class="c1"># withdraw = negative amount</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">balance</span> <span class="o">-=</span> <span class="n">amount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create_account</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">owner</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create an account&quot;&quot;&quot;</span>
        <span class="n">account</span> <span class="o">=</span> <span class="n">cls</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="n">owner</span><span class="p">,</span> <span class="n">balance</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="n">account</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'created_account'</span><span class="p">,</span>
                <span class="s1">'id'</span><span class="p">:</span> <span class="n">account</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s1">'owner_id'</span><span class="p">:</span> <span class="n">owner</span><span class="o">.</span><span class="n">id</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">account</span>
</pre></div>


<p>So now you can do this:</p>
<div class="highlight"><pre><span></span><span class="n">account</span> <span class="o">=</span> <span class="n">Account</span><span class="o">.</span><span class="n">create_account</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">first</span><span class="p">())</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_deposit</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">50.0</span><span class="p">))</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_deposit</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">125.0</span><span class="p">))</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_withdrawal</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">75.0</span><span class="p">))</span>

<span class="n">events</span> <span class="o">=</span> <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
    <span class="n">content_type</span><span class="o">=</span><span class="n">ContentType</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get_for_model</span><span class="p">(</span><span class="n">account</span><span class="p">),</span> 
    <span class="n">object_id</span><span class="o">=</span><span class="n">account</span><span class="o">.</span><span class="n">id</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">events</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">event</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>


<p>Which should give you this:</p>
<div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;created_account&quot;</span><span class="p">,</span> <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="nt">&quot;owner_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mf">50.0</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">150</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_withdrawal&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">-75</span><span class="p">}</span>
</pre></div>


<p>Again, this makes it trivial to write any utility methods to recreate any instance of <code>Account</code>, even if you accidentally dropped the whole accounts table.</p>
<h2>Snapshotting</h2>
<p>There will come a time when you have too many events to efficiently replay the entire history. In this case, a good optimisation step would be <em>snapshots</em> taken at various points in history. For example, in our accounting example one could save snapshots of the account in an <code>AccountBalance</code> model, which is a snapshot of the account's state at a point in time.</p>
<p>You could do this via a scheduled task. Celery <sup id="fnref-2"><a class="footnote-ref" href="https://www.djangoproject.com/rss/community/blogs/#fn-2">2</a></sup> is a good option.</p>
<h2>Summary</h2>
<p>Use event sourcing to maintain an append-only list of events for your critical data. This effectively allows you to travel in time to any point in history to see the state of your data at that time. </p>
<div class="footnote">
<hr />
<ol>
<li id="fn-1">
<p>Martin Fowler wrote a detailed description of event sourcing in his website here: <a href="http://martinfowler.com/eaaDev/EventSourcing.html">http://martinfowler.com/eaaDev/EventSourcing.html</a>&#160;<a class="footnote-backref" href="https://www.djangoproject.com/rss/community/blogs/#fnref-1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn-2">
<p>Celery project. http://www.celeryproject.org/&#160;<a class="footnote-backref" href="https://www.djangoproject.com/rss/community/blogs/#fnref-2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Id" title="Christophe Pettus: Estimates “stuck” at 200 rows?">
            <h2>Christophe Pettus: Estimates “stuck” at 200 rows?</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 04, 2017</span>.
            
        </p>

        <p>So, what&#8217;s weird about this plan, from a query on a partitioned table?  (PostgreSQL 9.3, in this case.)</p>

<pre><code>test=&gt; explain select distinct id from orders where order_timestamp &gt; '2016-05-01';
                                                                  QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=347341.56..347343.56 rows=200 width=10)
   Group Key: orders.id
   -&gt;  Append  (cost=0.00..337096.10 rows=4098183 width=10)
         -&gt;  Seq Scan on orders  (cost=0.00..0.00 rows=1 width=178)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Index Scan using orders_20160425_order_timestamp_idx on orders_20160425  (cost=0.43..10612.30 rows=120838 width=10)
               Index Cond: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Seq Scan on orders_20160502  (cost=0.00..80539.89 rows=979431 width=10)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Seq Scan on orders_20160509  (cost=0.00..74780.41 rows=909873 width=10)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Seq Scan on orders_20160516  (cost=0.00..68982.25 rows=845620 width=10)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Seq Scan on orders_20160523  (cost=0.00..65777.68 rows=796054 width=10)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
         -&gt;  Seq Scan on orders_20160530  (cost=0.00..36403.57 rows=446366 width=10)
               Filter: (order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone)
(17 rows)
</code></pre>

<p>That estimate on the HashAggregate certainly looks wonky, doesn&#8217;t it?  Just 200 rows even with a huge number of rows below it?</p>

<p>What if we cut down the number of partitions being hit?</p>

<pre><code>test=&gt; explain select distinct id from orders where order_timestamp &gt; '2016-05-01' and order_timestamp &lt; '2016-05-15';
                                                                                    QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=169701.02..169703.02 rows=200 width=10)
   Group Key: orders.id
   -&gt;  Append  (cost=0.00..165026.92 rows=1869642 width=10)
         -&gt;  Seq Scan on orders  (cost=0.00..0.00 rows=1 width=178)
               Filter: ((order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
         -&gt;  Index Scan using orders_20160425_order_timestamp_idx on orders_20160425  (cost=0.43..10914.39 rows=120838 width=10)
               Index Cond: ((order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
         -&gt;  Seq Scan on orders_20160502  (cost=0.00..82988.46 rows=979431 width=10)
               Filter: ((order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
         -&gt;  Index Scan using orders_20160509_order_timestamp_idx on orders_20160509  (cost=0.42..71124.06 rows=769372 width=10)
               Index Cond: ((order_timestamp &gt; '2016-05-01 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
(11 rows)
</code></pre>

<p>Still 200 exactly.  OK, that&#8217;s bizarre.  Let&#8217;s select exactly one partition:</p>

<pre><code>test=&gt; explain select distinct id from orders where order_timestamp &gt; '2016-05-14' and order_timestamp &lt; '2016-05-15';
                                                                                    QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=14669.26..14671.26 rows=200 width=10)
   Group Key: orders.id
   -&gt;  Append  (cost=0.00..14283.05 rows=154481 width=10)
         -&gt;  Seq Scan on orders  (cost=0.00..0.00 rows=1 width=178)
               Filter: ((order_timestamp &gt; '2016-05-14 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
         -&gt;  Index Scan using orders_20160509_order_timestamp_idx on orders_20160509  (cost=0.42..14283.05 rows=154480 width=10)
               Index Cond: ((order_timestamp &gt; '2016-05-14 00:00:00'::timestamp without time zone) AND (order_timestamp &lt; '2016-05-15 00:00:00'::timestamp without time zone))
(7 rows)
</code></pre>

<p>Still 200 exactly.  What happens if we select from the child directly?</p>

<pre><code>test=&gt; explain select distinct id from orders_20160509;
                                     QUERY PLAN
-------------------------------------------------------------------------------------
 HashAggregate  (cost=74780.41..75059.51 rows=27910 width=10)
   Group Key: id
   -&gt;  Seq Scan on orders_20160509  (cost=0.00..72505.73 rows=909873 width=10)
(3 rows)
</code></pre>

<p>A much more reasonable estimate. So, what&#8217;s going on?</p>

<p>That 200 should be something of a flag, as that&#8217;s a compiled-in constant that PostgreSQL uses when it doesn&#8217;t have ndistinct information for a particular table, usually because there are no statistics collected on a table.</p>

<p>In this case, the issue was that an ANALYZE had never been done on the parent table. This isn&#8217;t surprising: Autovacuum would never hit that table, since (like most parent tables in a partition set), it has no rows and is never updated or inserted to. That lack-of-information gets passed up through the Append node, and the HashAggregate just uses the default 200.</p>

<p>Sure enough, when the parent table was ANALYZE&#8217;d, the estimates became much more reasonable.</p>

<p>So: It can pay to do an initial ANALYZE on a newly created partitioned table so that the planner gets statistics for the parent table, even if those statistics are &#8220;no rows here.&#8221;</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ic" title="David Rader: Thank you PostgreSQL for Secure Defaults">
            <h2>David Rader: Thank you PostgreSQL for Secure Defaults</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 04, 2017</span>.
            
        </p>

        <p>One of the most common questions from new PostgreSQL users is &#8220;how do I connect to the database server?&#8221; The nuances of pg_hba.conf and how to correctly enable your Python web app to connect to your db server without opening up connections to all users and all servers is not <em>simple</em> for someone new to Postgres. And architecting a secure multi-tenant SaaS system requires knowledge of how roles, schemas, databases, and search paths interact. That&#8217;s one reason we wrote a <a href="http://www.openscg.com/whitepapers/postgresql-security-guidelines-case-study-whitepaper/">Security Whitepaper</a> a while back.</p>
<p>But, after seeing thousands of <a href="http://www.csoonline.com/article/3154190/security/exposed-mongodb-installs-being-erased-held-for-ransom.html">MongoDB instances taken hostage by ransomware</a> the &#8220;no authorization required&#8221; default for MongoDB is looking like a very dumb idea. Just imagine what executives whose developers picked MongoDB are saying today:</p>
<blockquote>
<p>&#8220;You mean we store our client list in a database without security?</p>
<p>&#8220;Anyone can just delete our NoSQL database from the internet?&#8221;</p>
<p>&#8220;Were we hacked last year when you said we lost data in MongoDB?&#8221;</p>
</blockquote>
<p>So, a quick <strong>&#8220;Thank You&#8221;</strong> to PostgreSQL for making sure that your data is Secure By Default.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ib" title="Simon Riggs: PostgreSQL’s Popularity Goes Up Again">
            <h2>Simon Riggs: PostgreSQL’s Popularity Goes Up Again</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 04, 2017</span>.
            
        </p>

        <p>Mirror mirror on the wall,<br />
Who is the fairest Database of all?</p>
<p>A frequently asked question, certainly.</p>
<p>DB-Engines recently announced it&#8217;s DBMS of the Year. Maybe the cool thing is that PostgreSQL is in 3rd Place. Yee-ha, an open source project is up there!</p>
<p>Let&#8217;s look closely about what this means.</p>
<p>PostgreSQL.org&#8217;s agreed response was this&#8230;</p>
<blockquote><p>&#8220;It&#8217;s great to see the continued success of PostgreSQL being reflected in DB-Engines rankings. It&#8217;s clear that the strength of the following for the World&#8217;s Most Advanced Open Source Database is enough to outweigh the largest software companies as people continue to choose to move away from commercial databases.&#8221;</p></blockquote>
<p>though because of commercial sensitivity this was changed down to this</p>
<blockquote><p>&#8220;It&#8217;s great to see the continued success of PostgreSQL being reflected in DB-Engines rankings. It&#8217;s clear that the strength of the following for the World&#8217;s Most Advanced Open Source Database is enough to draw people away from commercial databases.&#8221;
</p></blockquote>
<p>What were the commercial sensitivities? (What about &#8220;open source sensitivies&#8221;? Well, blame me, cos I agreed the change.)</p>
<p>Well, the title of the post is that a Microsoft product is actually DBMS of the Year, even though it&#8217;s not ranked #1 on the main list, that&#8217;s still Oracle. And Postgres is #3 on DBMS of the Year, even though we moved through to #5 again, competing with MongoDB for position 4 (although mostly level).</p>
<p>My guess is that Microsoft would like to highlight how it gets more press than PostgreSQL, a point I would concede in an instant. Whether that means it is more popular or has better features is a different thing entirely. People are simply leaving commercial databases in droves to come to PostgreSQL, which is clearly reflected in the very public decline of Oracle licencing revenues over the last 10 quarters and I&#8217;m sure its just the same for Microsoft revenue.</p>
<p>The purpose of the announcement from PostgreSQL.org was to highlight that &#8220;the strength of the following for the World&#8217;s Most Advanced Open Source Database is enough to outweigh the largest software companies&#8221;, though my conclusion is that we are not YET in a position to do that. Larger marketing budget does still give a larger audience. Real world usage does still show PostgreSQL usage increasing at an amazing rate. And our technology continues to set the pace of feature development that other databases would like to achieve.</p>
<p>Number 3 means we&#8217;re on the list. We can discuss exactly place we&#8217;re at, but its enough to put us on the short list for every major technology decision, worldwide. And when people see the feature list, price and responsive support, the effect is compelling.</p>
<p>Anyway, ain&#8217;t no such thing as bad publicity, so we&#8217;re all happy.</p>
<p>Thanks very much to DBEngines for mentioning PostgreSQL in this post&#8230;<br />
<a href="http://db-engines.com/en/blog_post/67" title="DB-Engines announcement">http://db-engines.com/en/blog_post/67</a></p>
<p>Anyway, I do thank Microsoft for continuing to support PostgreSQL in its framework and driver.</p>
<p>.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3Ia" title="Bruce Momjian: Controlling Autovacuum">
            <h2>Bruce Momjian: Controlling Autovacuum</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 03, 2017</span>.
            
        </p>

        <p>Unlike other database systems, Postgres makes the cleanup process visible and tunable to users. 
<a class="major" href="https://www.postgresql.org/docs/9.6/static/routine-vacuuming.html#AUTOVACUUM" style="text-decoration: underline;">Autovacuum</a> performs recycling of old rows and updates
optimizer statistics.  It appears in <a class="txt2html" href="http://www.linfo.org/ps.html" style="text-decoration: none;"><em>ps</em></a> command output, the
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/monitoring-stats.html#MONITORING-STATS-VIEWS" style="text-decoration: none;"><em>pg_stat_activity</em></a> system view,  and
optionally in the server logs via
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/runtime-config-autovacuum.html" style="text-decoration: none;"><em>log_autovacuum_min_duration.</em></a>
</p>
<p>Postgres also allows fine-grained <a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/runtime-config-autovacuum.html" style="text-decoration: none;">control</a> over the
autovacuum cleanup process.  Occasionally users find that cleanup is slowing the system down, and rather than modifying the behavior of
autovacuum, they decide to turn it off via the
<a class="txt2html" href="https://www.postgresql.org/docs/9.6/static/runtime-config-autovacuum.html" style="text-decoration: none;"><em>autovacuum</em></a> setting.  
</p>
<p>However, turning off autovacuum can cause problems.  Initially the system will run faster since there is no cleanup overhead, but after a
while old rows will clog up user tables and indexes, leading to increasing slowness.  Once that happens, you can turn on autovacuum again,
and it will recycle the old rows and free up space, but there will be much unused space that can't be reused quickly, or perhaps ever.
</p>
<p><a href="http://momjian.us/main/blogs/pgblog/2017.html#January_3_2017">Continue Reading &raquo;</a></p>
    </div>
    <div class="feedEntry">

        <a href="https://yoongkang.com/blog/event-sourcing-in-django/" title="Event sourcing in Django">
            <h2>Event sourcing in Django</h2>
        </a>

        <p class="discreet">
            
                  By Yoong Kang Lim from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 02, 2017</span>.
            
        </p>

        <p>Django comes with "batteries included" to make CRUD (create, read, update, delete) operations easy. It's nice that the CR part (create and read) of CRUD is so easy, but have you ever paused to think about the UD part (update and delete)?</p>
<p>Let's look at delete. All you need to do is this:</p>
<div class="highlight"><pre><span></span><span class="n">ReallyImportantModel</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>  <span class="c1"># gone from the database forever</span>
</pre></div>


<p>Just one line, and your data is gone forever. It can be done accidentally. Or you can be do it deliberately, only to later realise that your old data is valuable too.</p>
<p>Now what about updating? </p>
<p><em>Updating is deleting in disguise</em>. </p>
<p>When you update, you're deleting the old data and replacing it with something new. <em>It's still deletion</em>.</p>
<div class="highlight"><pre><span></span><span class="n">important</span> <span class="o">=</span> <span class="n">ReallyImportantModel</span><span class="o">.</span><span class="n">object</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">important</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'new_data'</span><span class="p">:</span> <span class="s1">'This is new data'</span><span class="p">})</span>  <span class="c1"># OLD DATA GONE FOREVER</span>
</pre></div>


<p>Okay, but why do we care?</p>
<p>Let's say we want to know the state of <code>ReallyImportantModel</code> 6 months ago. Oh that's right, you've deleted it, so you can't get it back. </p>
<p>Well, that's not exactly true -- you can recreate your data from backups (if you don't backup your database, <strong>stop reading right now and fix that immediately</strong>). But that's clumsy.</p>
<p>So by only storing the current state of the object, you lose all the contextual information on how the object arrived at this current state. Not only that, you make it difficult to make projections about the future.</p>
<p>Event sourcing <sup id="fnref-1"><a class="footnote-ref" href="https://www.djangoproject.com/rss/community/blogs/#fn-1">1</a></sup> can help with that.</p>
<h2>Event sourcing</h2>
<p>The basic concept of event sourcing is this:</p>
<ul>
<li>Instead of just storing the current state, we also store the <em>events</em> that lead up to the current state</li>
<li>Events are replayable. We can travel back in time to any point by replaying every event up to that point in time</li>
<li>That also means we can recover the current state just by replaying every event, even if the current state was accidentally deleted</li>
<li>Events are <em>append-only</em>. </li>
</ul>
<p>To gain an intuition, let's look at an event sourcing system you're familiar with: your bank account.</p>
<p>Your "state" is your account balance, while your "events" are your transactions (deposit, withdrawal, etc.). </p>
<p>Can you imagine a bank account that only shows you the current balance? </p>
<p>That is clearly unacceptable ("Why do I only have $50? Where did my money go? If only I could see the the history."). So we always store the history of transfers as the source of truth.</p>
<h2>Implementing event sourcing in Django</h2>
<p>Let's look at a few ways to do this in Django.</p>
<h3>Ad-hoc models</h3>
<p>If you have a one or two important models, you probably don't need a generalizable event sourcing solution that applies to all models. </p>
<p>You could do it on an ad-hoc basis like this, if you can have a relationship that makes sense:</p>
<div class="highlight"><pre><span></span><span class="c1"># in an app called 'account'</span>
<span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">django.conf</span> <span class="kn">import</span> <span class="n">settings</span>


<span class="k">class</span> <span class="nc">Account</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bank account&quot;&quot;&quot;</span>
    <span class="n">balance</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">AUTH_USER_MODEL</span><span class="p">,</span> <span class="n">related_name</span><span class="o">=</span><span class="s1">'account'</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Transfer</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a transfer in or out of an account. A positive amount indicates</span>
<span class="sd">    that it is a transfer into the account, whereas a negative amount indicates</span>
<span class="sd">    that it is a transfer out of the account.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">account</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="s1">'account.Account'</span><span class="p">,</span> <span class="n">on_delete</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">PROTECT</span><span class="p">,</span> 
                                <span class="n">related_name</span><span class="o">=</span><span class="s1">'transfers'</span><span class="p">)</span>
    <span class="n">amount</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DateTimeField</span><span class="p">()</span>
</pre></div>


<p>In this case your "state" is in your <code>Account</code> model, whereas your <code>Transfer</code> model contains the "events".</p>
<p>Having <code>Transfer</code> objects makes it trivial to recreate any account.</p>
<h3>Using an Event Store</h3>
<p>You could also use a single <code>Event</code> model to store every possible event in any model. A nice way to do this is to encode the changes in a JSON field. </p>
<p>This example uses Postgres:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">django.contrib.contenttypes.fields</span> <span class="kn">import</span> <span class="n">GenericForeignKey</span>
<span class="kn">from</span> <span class="nn">django.contrib.contenttypes.models</span> <span class="kn">import</span> <span class="n">ContentType</span>
<span class="kn">from</span> <span class="nn">django.contrib.postgres.fields</span> <span class="kn">import</span> <span class="n">JSONField</span>
<span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>


<span class="k">class</span> <span class="nc">Event</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Event table that stores all model changes&quot;&quot;&quot;</span>
    <span class="n">content_type</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">ContentType</span><span class="p">,</span> <span class="n">on_delete</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">PROTECT</span><span class="p">)</span>
    <span class="n">object_id</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">PositiveIntegerField</span><span class="p">()</span>
    <span class="n">time_created</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DateTimeField</span><span class="p">()</span>
    <span class="n">content_object</span> <span class="o">=</span> <span class="n">GenericForeignKey</span><span class="p">(</span><span class="s1">'content_type'</span><span class="p">,</span> <span class="s1">'object_id'</span><span class="p">)</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">JSONField</span><span class="p">()</span>
</pre></div>


<p>You can then add methods to any model that mutates the state:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Account</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">balance</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">DecimalField</span><span class="p">(</span><span class="n">max_digits</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">decimal_places</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">AUTH_USER_MODEL</span><span class="p">,</span> <span class="n">related_name</span><span class="o">=</span><span class="s1">'account'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_deposit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">amount</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Deposit money into account&quot;&quot;&quot;</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'made_deposit'</span><span class="p">,</span>
                <span class="s1">'amount'</span><span class="p">:</span> <span class="n">amount</span><span class="p">,</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">balance</span> <span class="o">+=</span> <span class="n">amount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">make_withdrawal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">amount</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Withdraw money from account&quot;&quot;&quot;</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'made_withdrawal'</span><span class="p">,</span>
                <span class="s1">'amount'</span><span class="p">:</span> <span class="o">-</span><span class="n">amount</span><span class="p">,</span>  <span class="c1"># withdraw = negative amount</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">balance</span> <span class="o">-=</span> <span class="n">amount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create_account</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">owner</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create an account&quot;&quot;&quot;</span>
        <span class="n">account</span> <span class="o">=</span> <span class="n">cls</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="n">owner</span><span class="p">,</span> <span class="n">balance</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">content_object</span><span class="o">=</span><span class="n">account</span><span class="p">,</span>
            <span class="n">time_created</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s1">'type'</span><span class="p">:</span> <span class="s1">'created_account'</span><span class="p">,</span>
                <span class="s1">'id'</span><span class="p">:</span> <span class="n">account</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s1">'owner_id'</span><span class="p">:</span> <span class="n">owner</span><span class="o">.</span><span class="n">id</span>
            <span class="p">})</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">account</span>
</pre></div>


<p>So now you can do this:</p>
<div class="highlight"><pre><span></span><span class="n">account</span> <span class="o">=</span> <span class="n">Account</span><span class="o">.</span><span class="n">create_account</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">first</span><span class="p">())</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_deposit</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">50.0</span><span class="p">))</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_deposit</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">125.0</span><span class="p">))</span>
<span class="n">account</span><span class="o">.</span><span class="n">make_withdrawal</span><span class="p">(</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="mf">75.0</span><span class="p">))</span>

<span class="n">events</span> <span class="o">=</span> <span class="n">Event</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
    <span class="n">content_type</span><span class="o">=</span><span class="n">ContentType</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get_for_model</span><span class="p">(</span><span class="n">account</span><span class="p">),</span> 
    <span class="n">object_id</span><span class="o">=</span><span class="n">account</span><span class="o">.</span><span class="n">id</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">events</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">event</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>


<p>Which should give you this:</p>
<div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;created_account&quot;</span><span class="p">,</span> <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="nt">&quot;owner_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mf">50.0</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">150</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_deposit&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;made_withdrawal&quot;</span><span class="p">,</span> <span class="nt">&quot;amount&quot;</span><span class="p">:</span> <span class="mi">-75</span><span class="p">}</span>
</pre></div>


<p>Again, this makes it trivial to write any utility methods to recreate any instance of <code>Account</code>, even if you accidentally dropped the whole accounts table.</p>
<h2>Snapshotting</h2>
<p>There will come a time when you have too many events to efficiently replay the entire history. In this case, a good optimisation step would be <em>snapshots</em> taken at various points in history. For example, in our accounting example one could save snapshots of the account in an <code>AccountBalance</code> model, which is a snapshot of the account's state at a point in time.</p>
<p>You could do this via a scheduled task. Celery <sup id="fnref-2"><a class="footnote-ref" href="https://www.djangoproject.com/rss/community/blogs/#fn-2">2</a></sup> is a good option.</p>
<h2>Summary</h2>
<p>Use event sourcing to maintain an append-only list of events for your critical data. This effectively allows you to travel in time to any point in history to see the state of your data at that time. </p>
<div class="footnote">
<hr />
<ol>
<li id="fn-1">
<p>Martin Fowler wrote a detailed description of event sourcing in his website here: <a href="http://martinfowler.com/eaaDev/EventSourcing.html">http://martinfowler.com/eaaDev/EventSourcing.html</a>&#160;<a class="footnote-backref" href="https://www.djangoproject.com/rss/community/blogs/#fnref-1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn-2">
<p>Celery project. http://www.celeryproject.org/&#160;<a class="footnote-backref" href="https://www.djangoproject.com/rss/community/blogs/#fnref-2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I9" title="Magnus Hagander: Financial updates in PostgreSQL Europe">
            <h2>Magnus Hagander: Financial updates in PostgreSQL Europe</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 02, 2017</span>.
            
        </p>

        <p>As we say welcome to a new year, we have a couple of updates to the finances and payment handling in PostgreSQL Europe, that will affect our members and attendees of our events.</p>
<p>First of all, PostgreSQL Europe has unfortunately been forced to VAT register. This means that most of our invoices (details below) will now include VAT.</p>
<p>Second, we have enabled a new payment provider for those of you that can't or prefer not to use credit cards but that still allows for fast payments.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I8" title="Magnus Hagander: Mail agents in the PostgreSQL community">
            <h2>Magnus Hagander: Mail agents in the PostgreSQL community</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Jan 01, 2017</span>.
            
        </p>

        <p>A few weeks back, I noticed the following tweet from Michael Paquier:</p>
<p><img alt="tweet" src="https://photos.smugmug.com/photos/i-8qDK7XB/0/O/i-8qDK7XB.png" /></p>
<p>And my first thought was "that can't be right" (spoiler: Turns out it wasn't. But almost.)</p>
<p>The second thought was "hmm, I wonder how that has actually changed over time". And of course, with today being a day off and generally "slow pace" (ahem), what better way than to analyze the data that we have. The <a href="https://www.postgresql.org/list/">PostgreSQL mailinglist archives</a> are all stored in a PostgreSQL database of course, so running the analytics is a quick job.</p>
    </div>
    <div class="feedEntry">

        <a href="https://micropyramid.com/blog/django-database-access-optimization/" title="Django - Database access optimization">
            <h2>Django - Database access optimization</h2>
        </a>

        <p class="discreet">
            
                  By Micropyramid django from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 30, 2016</span>.
            
        </p>

        <p style="font-style: italic;"><a href="https://micropyramid.com/django-development-services/">Django</a> Queryset is generally lazy in nature. It will not hit the database until it &nbsp;evaluates the query results.</p>

<p>Example:</p>

<pre class="prettyprint">
queryset = User.objects.all() # It won't hit the database
print (queryset) &nbsp;# Now, ORM turns the query into raw sql &nbsp;and fetches results from the database</pre>

<h2>1.Caching and QuerySets</h2>

<p>Generally Django stores the query results in the catche when it fetches the results for the first time.</p>

<p>Example:&nbsp;<span style="line-height: 1.6;">Get all users first names list &nbsp;and emails list from the database.</span></p>

<pre class="prettyprint">
first_names_list = [ user.first_name for user in User.objects.all()]
emails_list =&nbsp;[ user.email for user in User.objects.all()]</pre>

<p>above code hits the database twice. To avoid the extra request to the database we can use the Django's database cache in the following way.</p>

<pre class="prettyprint">
users_list =&nbsp;User.objects.all() &nbsp; &nbsp;# No database activity
first_names_list =&nbsp;&nbsp;[user.first_name for user in users_list] &nbsp; &nbsp;# Hits the database and stores the results in the cache
emails_list =&nbsp;[user.email for user in&nbsp;users_list] &nbsp; &nbsp;# uses the results from the cache.</pre>

<p>other way is&nbsp;</p>

<pre class="prettyprint">
users_list =&nbsp;User.objects.all()
db = dict(users_list.values_list(&quot;first_name&quot;, &quot;email&quot;))
first_names_list,&nbsp;emails_list = db.keys(), db.values()</pre>

<p><span style="line-height: 1.6;"><em>Note: Querysets are not cached if query is not evaluated.</em><br />
Eaxmple: If you want to take a subset/part of the query results</span></p>

<pre class="prettyprint">
queryset = Users.objects.all()
first_five =&nbsp;queryset[:5] &nbsp; &nbsp;# Hits the database
first_ten =&nbsp;queryset[:10] &nbsp; &nbsp;# Hits the database</pre>

<p>If you want to use the cache in the above situation you can do it in the following way</p>

<pre class="prettyprint">
queryset = Users.objects.all()
bool(queryset) &nbsp;# queryset is evaluated &nbsp;and results are cached
first_five =&nbsp;queryset[:5] &nbsp; &nbsp;# &nbsp;uses the cache
first_ten =&nbsp;queryset[:10] &nbsp; &nbsp;# uses the cache</pre>

<h2>2. Complex Database Queries with &quot;Q&quot; objects</h2>

<p><span style="line-height: 1.6;">Django Queries uses &quot;AND&quot; caluse to fetch results when using filter.<br />
Example:</span></p>

<pre class="prettyprint">
User.objects.filter(email__contains=&quot;adam&quot;, first_name=&quot;Adam&quot;)
# equivalent SQL Qurery is
SELECT * FROM user_table WHERE email LIKE '%adam%' &nbsp;AND first_name=Adam;</pre>

<p><span style="line-height: 1.6;">If you want to filter the users &nbsp;email starts with &quot;an&quot; or &quot;sa&quot;<br />
Simple Example:</span></p>

<pre class="prettyprint">
users_list = User.objects.all()
filtered_users = []
for user in users_list:
&nbsp; &nbsp; if user.email.startswith(&quot;an&quot;) &nbsp;or &nbsp;user.email.startswith(&quot;sa&quot;):
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;filtered_users.append(user)</pre>

<p><span style="line-height: 1.6;">In above example it gets all the records from the table. Insted, we can fetch the records that we required by using the &quot;Q&quot; object.</span><br />
Example:</p>

<pre class="prettyprint">
from django.db.models import Q
users_list = User.objects.filter(Q(email__startswith=&quot;an&quot;) | Q(email__startswith=&quot;sa&quot;))
#&nbsp;equivalent SQL Qurery is
SELECT * FROM user_table WHERE email LIKE 'an%' OR email LIKE 'sa%'</pre>

<p><span style="line-height: 1.6;">Q object usuage:</span></p>

<pre class="prettyprint">
~Q(email__startswith=&quot;an&quot;) &nbsp;# email don't starts with &quot;an&quot;&nbsp;
# SQL &nbsp;equivalent
| &nbsp;= OR
&amp; = AND
~ = NOT

</pre>

<p>We can use parenthesis with &quot;Q&quot; object<br />
Example:</p>

<pre class="prettyprint">
Model.objects.filter((Q(key1=&quot;value1&quot;) &amp; ~Q(key2=&quot;value2&quot;)) |&nbsp;(~Q(key3=&quot;value&quot;))</pre>

<h2>3. Create Multiple Objects at once with Bulk Create</h2>

<p>Simple Example: To create 4 users</p>

<pre class="prettyprint">
users_details = [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;(&quot;Dinesh&quot;, &quot;dinesh@micropyramid.com&quot;),
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;(&quot;Ravi&quot;, &quot;ravi@micropyramid.com&quot;),
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;(&quot;Santharao&quot;, &quot;santharao@micropyramid.com&quot;),
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;(&quot;Shera&quot;, &quot;shera@micropyramid.com&quot;)
]
for first_name, email in users_details:
&nbsp;&nbsp; &nbsp; User.objects.create(first_name=first_name, email=email)</pre>

<p>Above example hits/request the database 4 times to create 4 users, but we can create 4 users with single database hit/request.<br />
Example:</p>

<pre class="prettyprint">
instance_list = [User(first_name=first_name, email=email) for first_name, email in users_details]
User.objects.bulk_create(instance_list)</pre>

<h2>4. Update Multiple Objects or a filtered Queryset at once with update</h2>

<p>Let us consider Employee model as</p>

<pre class="prettyprint">
from django.db import models

DESIGNATIONS =&nbsp;((&quot;Designer&quot;, &quot;Designer&quot;),
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (&quot;Developer&quot;, &quot;Developer&quot;),
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (&quot;HR&quot;, &quot;HR&quot;))

class Employee(models.Model):
&nbsp; &nbsp; name = models.CharField(max_length=30)
&nbsp;&nbsp; &nbsp;email = models.EmailField(max_length=30)
&nbsp;&nbsp; &nbsp;designation =&nbsp;models.CharField(max_length=30, choices=DESIGNATIONS)
&nbsp;&nbsp; &nbsp;salary = models.DecimalField(default=20000)
&nbsp;</pre>

<p>After one year manager wants to increase the salary for Developers at an amount of 5000</p>

<p>SimpleExample:</p>

<pre class="prettyprint">
developers =&nbsp;Employee.objects.filter(designation=&quot;Developer&quot;)
for developer in developers:
&nbsp;&nbsp; &nbsp;developer.salary =&nbsp;developer.salary + 5000
&nbsp;&nbsp; &nbsp;develope
r.save()

</pre>

<p>Above example hits the database for several times[i.e number of developers]. we can do this with a single database hit/request.</p>

<p>Example:</p>

<pre class="prettyprint">
from django.db.models import F

amount = 5000
developers =&nbsp;Employee.objects.filter(designation=&quot;Developer&quot;)
developers.update(salary=F(&quot;salary&quot;)+amount)</pre>

<h2>5. Select only required fields in the query from the database to decrease querying time&nbsp;</h2>

<p>We use this when we need only the data[ie. fields values] &nbsp;we dont get access to the model functions and relational objects. We can do this by using&nbsp;QuerySet.values() and <strong><span style="line-height: 20.8px;">QuerySet.</span>values_list()</strong></p>

<p><strong style="line-height: 20.8px;">QuerySet.values()</strong><span style="line-height: 20.8px;">&nbsp;</span>&nbsp;returns the list of dictionaries. Each dictionary represents an instance of object.<br />
<strong style="line-height: 20.8px;"><span style="line-height: 20.8px;">QuerySet.</span>values_list()&nbsp;</strong><span style="line-height: 20.8px;">returns the list of&nbsp;</span>tuples. Each tutple&nbsp;<span style="line-height: 20.8px;">represents an instance of object. order of values in the tuple is id followed by the fields in the model.</span></p>

<pre class="prettyprint">
from .models import&nbsp;Employee
# create 2 objects
Employee.objects.create(name=&quot;Ravi&quot;, email=&quot;ravi@micropramid.com&quot;, designation=&quot;Developer&quot;, salary=30000)
Employee.objects.create(name=&quot;Santharao&quot;, email=&quot;santharao@micropramid.com&quot;, designation=&quot;Designer&quot;, salary=40000)

queryset =&nbsp;Employee.objects.all() &nbsp; &nbsp;# you can also use filter&nbsp;
# Example for &nbsp;QuerySet.values()
users_dict_list =&nbsp;queryset.values()
# above line is equivalent to
users_dict_list = [
&nbsp; &nbsp; {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&quot;id&quot;: 1,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;name&quot;: &quot;Ravi&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;email&quot;: &quot;ravi@micropramid.com&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;designation&quot;: &quot;Developer&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;salary&quot;: 30000
&nbsp;&nbsp; &nbsp; },
&nbsp; &nbsp; {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&quot;id&quot;: 2,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;name&quot;: &quot;Santharao&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;email&quot;: &quot;santharao@micropramid.com&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;designation&quot;: &quot;Designer&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;salary&quot;:&nbsp;40000
&nbsp;&nbsp; &nbsp; },
]
<em># To &nbsp;get only required fields data ie. &nbsp;&quot;name&quot;, &quot;salary&quot;</em>
users_dict_list =&nbsp;queryset.values(&quot;name&quot;, &quot;salary&quot;)
# above line is equivalent to
users_dict_list = [
&nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;name&quot;: &quot;Ravi&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;salary&quot;: 30000
&nbsp;&nbsp; &nbsp; },
&nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;name&quot;: &quot;Santharao&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;salary&quot;:&nbsp;40000
&nbsp;&nbsp; &nbsp; },
]
# Example for &nbsp;QuerySet.values_list()
users_tuple_list =&nbsp;queryset.values_list()
# above line is equivalent to
users_tuple_list = [
&nbsp; &nbsp; &nbsp;(1, &quot;Ravi&quot;, &quot;ravi@micropramid.com&quot;,&nbsp;&quot;Developer&quot;,&nbsp;30000),
&nbsp; &nbsp; &nbsp;(2, &quot;Santharao&quot;,&nbsp;&quot;santharao@micropramid.com&quot;,&nbsp;&quot;Designer&quot;, 40000),
]
<em style="line-height: 20.8px;"># To &nbsp;get only required fields data ie. &nbsp;&quot;name&quot;, &quot;salary&quot;</em>
users_tuple_list =&nbsp;queryset.values_list(&quot;name&quot;, &quot;salary&quot;)
# above line is equivalent to
users_tuple_list = [
&nbsp; &nbsp; &nbsp;(&quot;Ravi&quot;, 30000),
&nbsp; &nbsp; &nbsp;(&quot;Santharao&quot;, 40000),
]
<em style="line-height: 20.8px;"># We can also get list of values of a single field in the model by setting&nbsp;<ins>&quot;flat=True&quot;</ins></em>
users_names_list =&nbsp;queryset.values_list(&quot;name&quot;, flat=True) &nbsp; &nbsp; # it works only for single field
# above line is equivalent to
users_names_list = [&quot;Ravi&quot;, &quot;Santharao&quot;]
&nbsp;

</pre>
5. Dont hit/request the database for related objects. Fetch all related objects in a single query using&nbsp;select_related&nbsp;and&nbsp;prefetch_related Let us consider the following models

<pre class="prettyprint">
from django.db import models

class Address(models.Model):
&nbsp;&nbsp; &nbsp; &nbsp; city = models.CharField(max_length=100)
&nbsp;&nbsp; &nbsp; &nbsp; state = &nbsp;models.CharField(max_length=100)
&nbsp; &nbsp; &nbsp; &nbsp;pin = &nbsp;models.CharField(max_length=100)

class Person(models.Model):
&nbsp; &nbsp; &nbsp; &nbsp;name = models.CharField(max_length=100)
&nbsp;&nbsp; &nbsp; &nbsp; email = models.EmailField(max_length=100)
&nbsp; &nbsp; &nbsp; &nbsp;present_address = models.ForeignKey(Address)
&nbsp; &nbsp; &nbsp; &nbsp;previous_address = models.ForeignKey(Address)

class Book(models.Model):
&nbsp; &nbsp; &nbsp; &nbsp;name = models.CharField(max_length=100)
&nbsp; &nbsp; &nbsp; &nbsp;author = models.ForeignKey(Person)
&nbsp; &nbsp; &nbsp; &nbsp;publishers = models.ManyToManyField(Person)

</pre>

<h3>usuage of select_related</h3>

<pre class="prettyprint">
# without select related
person = Person.objects.get(id=1)
present_address = person.present_address &nbsp;#&nbsp;Hits the database.
previous_address&nbsp;= person.previous_address&nbsp; #&nbsp;Hits the database.
# total database hits = 3
# with select related
person = Person.objects.select_related().get(id=1)
present_address&nbsp;= person.present_address #&nbsp;<em>Doesn't hit the database.</em>
previous_address&nbsp;= person.previous_address&nbsp;#&nbsp;<em>Doesn't hit the database.
# total database hits = 1</em>
# you can also select the specific related objects
person = Person.objects.select_related(&quot;present_address&quot;).get(id=1)
present_address&nbsp;= person.present_address #&nbsp;<em style="line-height: 20.8px;">Doesn't hit the database.</em>
previous_address&nbsp;= person.previous_address #&nbsp;Hits the database.

</pre>

<h3>Limitaions of&nbsp;select_related</h3>

<p>select_related works by creating an SQL join and including the fields of the related object in the SELECT statement. For this reason, select_related gets the related objects in the same database query. However, to avoid the much larger result set that would result from joining across a &lsquo;many&rsquo; relationship, select_related is <strong>limited</strong> <strong>to</strong> single-valued relationships - <strong>foreign key</strong> and <strong>one-to-one</strong>.<br />
<br />
Usuage of&nbsp;prefetch_related</p>

<div>
<pre class="prettyprint">
# without prefetch related
book = Book.objects.get(id=1)
author&nbsp;= book.author<span style="line-height: 20.8px;">&nbsp;#&nbsp;</span>Hits the database.
publishers<span style="line-height: 20.8px;">&nbsp;= book</span><span span="" style="line-height: 20.8px;"><span style="line-height: 20.8px;">&nbsp;#&nbsp;Hits the database.
# total database hits = 3</span>
# with prefetch related
book =&nbsp;</span>Book.objects.prefetch_related().get(id=1)
author&nbsp;=&nbsp;book.author<span style="line-height: 20.8px;">&nbsp; #&nbsp;</span><em>Doesn't hit the database.</em>
publishers<span style="line-height: 20.8px;">&nbsp;=&nbsp;book</span><span style="line-height: 20.8px;">.publishers.all()</span><span style="line-height: 20.8px;">&nbsp;#&nbsp;</span><em>Doesn't hit the database.
<span style="line-height: 20.8px;"># total database hits = 1</span></em>
# you can also select the specific related objects
book =&nbsp;Book.objects.prefetch_related(&quot;publishers&quot;).get(id=1)
author&nbsp;=&nbsp;book.author<span style="line-height: 20.8px;">&nbsp; #&nbsp;</span><em style="line-height: 20.8px;">Doesn't hit the database.</em>
publishers<span style="line-height: 20.8px;">&nbsp;=&nbsp;book</span><span style="line-height: 20.8px;">.publishers.all() </span><span style="line-height: 20.8px;">#&nbsp;</span>Hits the database.

</pre>
</div>

<h3>Advantage over&nbsp;select_related</h3>

<p><em><strong style="line-height: 20.8px;">prefetch_related</strong><strong style="line-height: 20.8px;">&nbsp;</strong></em>does a separate lookup for each relationship, and does the &lsquo;joining&rsquo; in Python. <em style="line-height: 20.8px;"><strong style="line-height: 20.8px;">prefetch_related</strong></em> allows it to prefetch <strong>many-to-many</strong> and <strong>many-to-one</strong> objects, which cannot be done using select_related, in addition to the foreign key and one-to-one relationships that are supported by select_related. It also supports prefetching of <strong>GenericRelation</strong> and <strong>GenericForeignKey</strong></p>

<h3>Limitaions of&nbsp;prefetch_related</h3>

<p><em><strong>prefetching</strong></em> of related objects referenced by a <em><strong>GenericForeignKey</strong></em> is only supported if the query is restricted to <strong>one ContentType.</strong></p>

<h2><span style="line-height: 1.2;">6. use queryset.count() if you require only count but not queryset objects</span></h2>

<pre class="prettyprint">
count = Book.objects.filter(author_id=5).count() &nbsp; # It returns the count(number of objects/records) only. So, operation is very fast.</pre>

<h2>7. use queryset.exists() if you want to know whether objects exists or not only</h2>

<pre class="prettyprint">
is_exists = Book.objects.filter(author_id=5).exists() &nbsp; # It returns the boolean value(True/False) only. So, operation is very fast.</pre>

<h2>8. Provide index to fields in database models &amp; provide default ordering</h2>

<p>If one of the models accessed very freequently use the indexes to the database tables.</p>

<pre class="prettyprint">
class Book(models.Model):
&nbsp; &nbsp; &nbsp; &nbsp;name = models.CharField(max_length=100, db_index=True)
&nbsp; &nbsp; &nbsp; &nbsp;author = models.ForeignKey(Person)
&nbsp;&nbsp; &nbsp; &nbsp; published_on = &nbsp;models.DateField()
&nbsp; &nbsp; &nbsp; &nbsp;publishers = models.ManyToManyField(Person)

&nbsp;&nbsp; &nbsp; &nbsp;class Meta:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; index_together = [&quot;author&quot;, &quot;published_on&quot;]
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;ordering = ['-published_on']
</pre>
<span>Reference: </span><a href="http://https://docs.djangoproject.com/en/1.9/topics/db/optimization/">&nbsp;https://docs.djangoproject.com/en/1.9/topics/db/optimization/</a>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I7" title="Christophe Pettus: The Multi-Column Index of the Mysteries">
            <h2>Christophe Pettus: The Multi-Column Index of the Mysteries</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 30, 2016</span>.
            
        </p>

        <p>The one thing that everyone knows about compositive indexes is: If you have an index on (A, B, C), it can&#8217;t be used for queries on (B) or (B, C) or (C), just (A), (A, B) or (A, B, C), right? I&#8217;ve said that multiple times in talks. It&#8217;s clearly true, right?</p>

<p>Well, no, it&#8217;s not. It&#8217;s one of those things that is not technically true, but it is still good advice.</p>

<p>The <a href="https://www.postgresql.org/docs/9.6/static/indexes-multicolumn.html">documentation on multi-column indexes</a> is pretty clear:</p>

<blockquote>
  <p>A multicolumn B-tree index can be used with query conditions that involve any subset of the index&#8217;s columns, but the index is most efficient when there are constraints on the leading (leftmost) columns. The exact rule is that equality constraints on leading columns, plus any inequality constraints on the first column that does not have an equality constraint, will be used to limit the portion of the index that is scanned. </p>
</blockquote>

<p>Let&#8217;s try this out!</p>

<p>First, create a table and index:</p>

<pre><code>xof=# CREATE TABLE x ( 
xof(#     i integer,
xof(#     f float,
xof(#     g float
xof(# );
CREATE TABLE
xof=# CREATE INDEX ON x(i, f, g);
CREATE INDEX
</code></pre>

<p>And fill it with some test data:</p>

<pre><code>xof=# INSERT INTO x SELECT 1, random(), random() FROM generate_series(1, 10000000);
INSERT 0 10000000
xof=# INSERT INTO x SELECT 2, random(), random() FROM generate_series(1, 10000000);
INSERT 0 10000000
xof=# INSERT INTO x SELECT 3, random(), random() FROM generate_series(1, 10000000);
INSERT 0 10000000
xof=# ANALYZE x;
ANALYZE
</code></pre>

<p>And away we go!</p>

<pre><code>xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                                   QUERY PLAN                                                                   
------------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=599859.50..599859.51 rows=1 width=8) (actual time=91876.057..91876.057 rows=1 loops=1)
   -&gt;  Index Only Scan using x_i_f_g_idx on x  (cost=0.56..599097.71 rows=304716 width=8) (actual time=1820.699..91652.409 rows=300183 loops=1)
         Index Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
         Heap Fetches: 300183
 Planning time: 3.384 ms
 Execution time: 91876.165 ms
(6 rows)
</code></pre>

<p>And sure enough, it uses the index, even though we didn&#8217;t include column <code>i</code> in the query. In this case, the planner thinks that this will be more efficient than just doing a sequential scan on the whole table, even though it has to walk the whole index.</p>

<p>Is it right? Let&#8217;s turn off index scans and find out.</p>

<pre><code>xof=# SET enable_indexonlyscan = 'off';
SET
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=599859.50..599859.51 rows=1 width=8) (actual time=39691.081..39691.081 rows=1 loops=1)
   -&gt;  Index Scan using x_i_f_g_idx on x  (cost=0.56..599097.71 rows=304716 width=8) (actual time=1820.676..39624.144 rows=300183 loops=1)
         Index Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
 Planning time: 0.181 ms
 Execution time: 39691.128 ms
(5 rows)
</code></pre>

<p>PostgreSQL, you&#8217;re not helping!</p>

<pre><code>xof=# SET enable_indexscan = 'off';
SET
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                                   QUERY PLAN                                                                    
-------------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=689299.60..689299.61 rows=1 width=8) (actual time=40593.427..40593.428 rows=1 loops=1)
   -&gt;  Bitmap Heap Scan on x  (cost=513444.70..688537.81 rows=304716 width=8) (actual time=37901.773..40542.900 rows=300183 loops=1)
         Recheck Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
         Rows Removed by Index Recheck: 8269763
         Heap Blocks: exact=98341 lossy=53355
         -&gt;  Bitmap Index Scan on x_i_f_g_idx  (cost=0.00..513368.52 rows=304716 width=0) (actual time=37860.366..37860.366 rows=300183 loops=1)
               Index Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
 Planning time: 0.160 ms
 Execution time: 40593.764 ms
(9 rows)
</code></pre>

<p>Ugh, <em>fine</em>!</p>

<pre><code>xof=# SET enable_bitmapscan='off';
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                     QUERY PLAN                                                     
--------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=641836.33..641836.34 rows=1 width=8) (actual time=27270.666..27270.666 rows=1 loops=1)
   -&gt;  Seq Scan on x  (cost=0.00..641074.54 rows=304716 width=8) (actual time=0.081..27195.552 rows=300183 loops=1)
         Filter: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
         Rows Removed by Filter: 29699817
 Planning time: 0.157 ms
 Execution time: 27270.726 ms
(6 rows)
</code></pre>

<p>It turns out the seq scan is faster, which isn&#8217;t that much of a surprise.  Of course, what&#8217;s <em>really</em> fast is using the index properly:</p>

<pre><code>xof=# // reset all query planner settings
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE i IN (1, 2, 3) AND f BETWEEN 0.11 AND 0.12;
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=92459.82..92459.83 rows=1 width=8) (actual time=6283.162..6283.162 rows=1 loops=1)
   -&gt;  Index Only Scan using x_i_f_g_idx on x  (cost=0.56..91698.03 rows=304716 width=8) (actual time=1.295..6198.409 rows=300183 loops=1)
         Index Cond: ((i = ANY ('{1,2,3}'::integer[])) AND (f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
         Heap Fetches: 300183
 Planning time: 1.264 ms
 Execution time: 6283.567 ms
(6 rows)
</code></pre>

<p>And, of course, a dedicated index for that particular operation is the fastest of all:</p>

<pre><code>xof=# CREATE INDEX ON x(f);
CREATE INDEX
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                              QUERY PLAN                                                               
---------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=188492.00..188492.01 rows=1 width=8) (actual time=5536.940..5536.940 rows=1 loops=1)
   -&gt;  Bitmap Heap Scan on x  (cost=4404.99..187662.16 rows=331934 width=8) (actual time=209.854..5466.633 rows=300183 loops=1)
         Recheck Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
         Rows Removed by Index Recheck: 8258716
         Heap Blocks: exact=98337 lossy=53359
         -&gt;  Bitmap Index Scan on x_f_idx  (cost=0.00..4322.00 rows=331934 width=0) (actual time=163.402..163.402 rows=300183 loops=1)
               Index Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
 Planning time: 5.586 ms
 Execution time: 5537.235 ms
(9 rows)
</code></pre>

<p>Although, interestingly enough, PostgreSQL doesn&#8217;t quite get it right here:</p>

<pre><code>xof=# SET enable_bitmapscan='off';
SET
xof=# EXPLAIN ANALYZE SELECT SUM(g) FROM x WHERE f BETWEEN 0.11 AND 0.12;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=203875.29..203875.30 rows=1 width=8) (actual time=2178.215..2178.216 rows=1 loops=1)
   -&gt;  Index Scan using x_f_idx on x  (cost=0.56..203045.45 rows=331934 width=8) (actual time=0.161..2110.903 rows=300183 loops=1)
         Index Cond: ((f &gt;= '0.11'::double precision) AND (f &lt;= '0.12'::double precision))
 Planning time: 0.170 ms
 Execution time: 2178.279 ms
(5 rows)
</code></pre>

<p>So, we conclude:</p>

<ul>
<li>Yes, PostgreSQL will sometimes use the second and further columns of a multi-column index, even if the first column isn&#8217;t used in the query.</li>
<li>This is rarely optimal, so it should not be relied on as an optimization path.</li>
<li>So, while the advice was not correct in the absolute statement, it was still valid as advice.</li>
</ul>

<p>And there we are.</p>

<pre><code>xof=# DROP TABLE x;
DROP TABLE
</code></pre>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I6" title="Ernst-Georg Schmid: One-time passwords with Google Authenticator PAM (and friends)">
            <h2>Ernst-Georg Schmid: One-time passwords with Google Authenticator PAM (and friends)</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 30, 2016</span>.
            
        </p>

        PostgreSQL allows for <a href="https://www.postgresql.org/docs/9.6/static/auth-methods.html">more</a> than plain password authentication in <i><a href="https://www.postgresql.org/docs/9.6/static/auth-pg-hba-conf.html">pg_hba.conf</a></i>. One of the most flexible is authenticating against a <a href="https://en.wikipedia.org/wiki/Pluggable_authentication_module">PAM</a>.<br /><br />Let's see how this works with one-time passwords from&nbsp; <a href="https://github.com/google/google-authenticator">Google Authenticator</a>.<br /><br />1.) Install Google Authenticator on your Android or iOS device.<br /><br />2.) Install the Google Authenticator PAM on the machine where your PostgreSQL server lives, like in Step 1 - 4 of this <a href="https://www.blackmoreops.com/2014/06/26/securing-ssh-two-factor-authentication-using-google-authenticator/#Step_2_Download_Google_Authenticator_Module">guide</a>.<br /><br />3.) Connect your device with the account on that machine.<br /><br />4.) Configure a PAM service for PostgreSQL. E.g. create a file named <i>postgresql</i> where your PAM configs live, on Ubuntu this is <i>/etc/pam.d/</i>. The file should look like this:<br /><br /><pre><span>auth         sufficient     <code>pam_google_authenticator.so</code></span></pre><br />5.) Configure PostgreSQL to use the PAM. E.g. a line in <i>pg_hba.conf</i> could look like this:<br /><br /><span>hostssl&nbsp;&nbsp;&nbsp; all&nbsp;&nbsp;&nbsp; all&nbsp;&nbsp;&nbsp; 127.0.0.1/32&nbsp;&nbsp; pam&nbsp;&nbsp;&nbsp; pamservice=postgresql</span><br /><br />And that's basically it. Now, next time you login, PostgreSQL will ask you for a password that is generated individually on your device.<br /><br />Of course you can use all kinds of PAM with PostgreSQL like this.<br /><br />Unfortunately, I also found a few caveats along the way. :-(<br /><br />First, PostgreSQL clients will ask only for one password, regardless if you chain <i>n</i> PAM's for n-factor authentication.<br /><br />So if you e.g. chain a PAM against LDAP with Google Authenticator as the second factor, this won't work. This seems to be a shortcoming of the PAM implementation in PostgreSQL, not expecting multiple password prompts. It is still possible to enable n-factor authentication though, but only one PAM can prompt for a password. If the other factors are hardware devices like a fingerprint scanner that does not prompt for a password, you are fine.<br /><br />Alternatively, you can provide your own PAM that takes all passwords in one prompt and handles them internally. <br /><br />Second, PAM requires PostgreSQL clients to send the password in plaintext. So <b>now</b> is the time to <a href="https://www.postgresql.org/docs/9.6/static/ssl-tcp.html">switch on TLS</a> and make it mandatory (Noticed the <i>hostssl</i> switch above?).<br /><br />Third, some clients like pgAdmin3 break with one-time passwords, because they apparently open new connections without prompting for a password again, but re-use the initial one instead until you disconnect. This obviously does not work with passwords which are valid only for one login attempt.<br /><br />Fourth, if your PAM requires a physical account on the machine, but you want to map it to a different PostgreSQL user,<i> <a href="https://www.postgresql.org/docs/9.6/static/auth-username-maps.html">pg_ident.conf</a></i> is your friend.
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I5" title="Christophe Pettus: A Cheap and Cheerful Replication Check">
            <h2>Christophe Pettus: A Cheap and Cheerful Replication Check</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 28, 2016</span>.
            
        </p>

        <p>On a PostgreSQL primary / secondary pair, it&#8217;s very important to monitor replication lag. Increasing replication lag is often the first sign of trouble, such as a network issue, the secondary disconnecting for some reason (or for no reason at all, which does happen rarely), disk space issues, etc.</p>

<p>You can find all kinds of complex scripts that do math on the various WAL positions that are available from the secondary and from pg<em>stat</em>replication on the primary.</p>

<p>Or you can do this. It&#8217;s very cheap and cheerful, and for many installations, it gets the job done.</p>

<p>First, on the primary (and thus on the secondary), we create a one-column table:</p>

<pre><code>CREATE TABLE replication_monitor (
   last_timestamp TIMESTAMPTZ
);
</code></pre>

<p>Then, we insert a singel row into the table (you can probably already see where this is going):</p>

<pre><code>INSERT INTO replication_monitor VALUES(now());
</code></pre>

<p>Having that, we can start a cron job that runs every minute, updating that value:</p>

<pre><code>* * * * * /usr/bin/psql -U postgres -c "update replication_monitor set last_update=now()" postgres &gt; /dev/null
</code></pre>

<p>On the secondary (which is kept in sync with the primary via NTP, so make sure ntpd is running on both!), we have a script, also run from cron, that complains if the value in has fallen more than a certain amount behind <code>now()</code>. Here&#8217;s a (pretty basic) Python 2 version:</p>

<pre><code>#!/usr/bin/python

import sys

import psycopg2

conn = psycopg2.connect("dbname=postgres user=postgres")

cur = conn.cursor()

cur.execute("select (now()-last_update)&gt;'5 minutes'::interval from replication_monitor")

problem = cur.fetchone()[0]

if problem:
    print &gt;&gt;sys.stderr, "cat1r replication lag over 5 minutes."
</code></pre>

<p>We make sure we get the output from <code>stderr</code> for cron jobs on the secondary, set it up to run every so often, and we&#8217;re done!</p>

<p>Of course, this has its limitations:</p>

<ul>
<li><p>It only has &#xb1;2 minutes of resolution, based on how often cron runs. For a basic &#8220;is replication working?&#8221; check, this is probably fine.</p></li>
<li><p>It creates traffic in the replication stream and WAL, but if you are really worried about a TIMESTAMPTZ&#8217;s worth of update once a minute, you probably have other things to worry about.</p></li>
</ul>

<p>It has the advantage that it works even if the server is otherwise not taking traffic, since it creates traffic all by itself.</p>

<p>As a final note, <a href="https://bucardo.org/wiki/Check_postgres">check_postgres</a> has this check integrated as one of the (many, many) checks it can do, as the <code>replicate_row</code> check. If you are using check_postgres, by all means use that one!</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/how-to-implement-token-authentication-with-django-rest-framework/" title="How to Implement Token Authentication with Django REST Framework">
            <h2>How to Implement Token Authentication with Django REST Framework</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 27, 2016</span>.
            
        </p>

        <p>Token Authentication seems to be an Authentication Scheme that gives people the most trouble. The reason appears to be a misunderstanding not of so much how to implement it, but how to actually use it.</p>
<p>For example, the Django REST Framework documentation says that for every request, you have to add an <code>Authorization</code> Header to your requests. But, how do you create that <code>Authorization</code> header?</p>
<p>Also…</p>
<p>How do I use Token Authentication to authorize external clients? These are serious questions that I’ve seen from people just like you. But, the difference is that after reading this post, you’ll understand how that works. I’ll show you how to implement Token Authentication using Django REST Framework. Then, I’ll give you a sample application that uses Token Authentication to authenticate users <strong>within</strong> a Django Application. Best of all, you can take what you learn from my sample code to use in external clients (Javascript clients) to authenticate / authorize users with your RESTful API.</p>
<blockquote>
<p><strong>WARNING</strong>: NEVER, EVER use Token Authentication without using Secure HTTP (HTTPS). If you want to run my sample code or play around with your own code locally it is <strong>OKAY</strong> to use Unsecure HTTP (HTTP). However, NEVER do it in production. You’ve been warned.</p>
</blockquote>
<h2>Introduction to Token Authentication</h2>
<p>Token Authentication is a way to authorize users by using an <em>API Key</em> or <em>Auth Token</em>. The way Django REST Framework implements Token Authentication requires you to add a header for each request. This header will be in the following format:</p>
<pre><code>Authorization: Token 93138ba960dfb4ef2eef6b907718ae04400f606a
</code></pre>
<p><code>Authorization</code> is the header key and <code>Token 93138ba960dfb4ef2eef6b907718ae04400f606a</code> is the header value. Note, there is a space between <code>Token</code> and the token itself.</p>
<p>The server where your API lives will read off the user’s token and determine if there is a user assigned to that particular token.</p>
<p>This is Token Authentication in a nutshell. It really doesn’t get anymore complicated than that. The difficulty is implementing it for each of the clients that will use the API (Javascript apps, Desktop apps, Commandline, etc.)</p>
<h2>How to Implement Token Authentication</h2>
<p>The implementation is a bit more complicated than other Authentication Schemes so take this slow, digest each piece of the puzzle and make sure to download my sample code so you can see what I’m doing each step of the way.</p>
<h3>Preliminary Configuration</h3>
<p>As with all Django REST Framework Authentication schemes, you must configure the authentication scheme that you will use in your <code>settings.py</code> file.</p>
<p><em>myproject/settings.py</em></p>
<pre><code>REST_FRAMEWORK = { 
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework.authentication.TokenAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': (
        'rest_framework.permissions.IsAuthenticated',
    )
}
</code></pre>
<p>This is where it’s a little different than other Authentication schemes. You will also need to add an app to your <code>INSTALLED_APPS</code> array. The reason for this is because Token Authentication requires a special model called <code>Token</code> which is used to store your user authentication tokens.</p>
<p>In my sample application, my <code>INSTALLED_APPS</code> tuple looks like this:</p>
<p><em>myproject/settings.py</em></p>
<pre><code>INSTALLED_APPS = ( 
    'django.contrib.admin', 
    'django.contrib.auth', 
    'django.contrib.contenttypes', 
    'django.contrib.sessions', 
    'django.contrib.messages', 
    'django.contrib.staticfiles',
    'polls',
    'accounts',
    'rest_framework',
    'rest_framework.authtoken',
)
</code></pre>
<p>Now, in order to install the app and update the database with the new <code>Token</code> model, it is imperative that we run <code>python manage.py migrate</code>.</p>
<p>Now, you should be ready to create tokens for your users, create a <code>post_save</code> method on your <code>User</code> model so that whenever a new user is added to your database it will automatically create a token for them.</p>
<h3>Create Tokens for your Users</h3>
<p>Go to your project shell by typing this command at a terminal: <code>python manage.py shell</code>. You should be presented with a prompt that looks like this: <code>&gt;&gt;&gt;</code>.</p>
<p>Now, you’re going to type in the following code:</p>
<pre><code>from django.contrib.auth.models import User
from rest_framework.authtoken.models import Token

users = User.objects.all()
for user in users:
    token, created = Token.objects.get_or_create(user=user)
    print user.username, token.key
</code></pre>
<p>This code will retrieve all the users that currently exist in your database. It loops through each of them, generates a unique token for each of them and prints our their username and their token. It’s nice to print out their username and the token so you can see that it in fact worked correctly.</p>
<p>Now, you don’t want to manually create tokens for your users whenever a new user registers for your web app so you’ll have to create a special function that will automatically create a token for each new user:</p>
<p><em>myproject/accounts/models.py</em></p>
<pre><code>from django.conf import settings
from django.db.models.signals import post_save
from django.dispatch import receiver
from rest_framework.authtoken.models import Token 

@receiver(post_save, sender=settings.AUTH_USER_MODEL)
def create_auth_token(sender, instance=None, created=False, **kwargs):
    if created:
        Token.objects.create(user=instance)
</code></pre>
<p>Now, every time a new user is saved in your database, this function will run and a new Token will be created for that user.</p>
<h3>Create a Route for Retrieving a Token for Successfully logged in users</h3>
<p>Django REST Framework provides a view that simply returns the user’s token when they provide a correct username / password combo.</p>
<p>Let’s add this now:</p>
<p><em>myproject/accounts/urls.py</em></p>
<pre><code>from django.conf.urls import url
from django.conf import settings
from django.conf.urls.static import static

from . import views as local_view
from rest_framework.authtoken import views as rest_framework_views

urlpatterns = [ 
    # Session Login
    url(r'^login/$', local_views.get_auth_token, name='login'),
    url(r'^logout/$', local_views.logout_user, name='logout'),
    url(r'^auth/$', local_views.login_form, name='login_form'),
    url(r'^get_auth_token/$', rest_framework_views.obtain_auth_token, name='get_auth_token'),
] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)
</code></pre>
<p>The bottom route is what you should notice:</p>
<pre><code>url(r'^get_auth_token/$', rest_framework_views.obtain_auth_token, name='get_auth_token'),
</code></pre>
<p>Now, when POST’ing to <code>http://localhost:8000/accounts/get_auth_token/</code> with the following data (assuming this username / password exists): <code>{ 'username': 'admin', 'password': 'admin' }</code> you’ll receive something that looks like the following: <code>{ 'token': '93138ba960dfb4ef2eef6b907718ae04400f606a' }</code></p>
<p>You’re done implementing Token Authentication. So, what can you do with this Authentication Scheme? Whatever you want. Let’s look at some sample code to see how this works.</p>
<p><a href="http://www.chrisbartos.com/wp-content/uploads/2016/12/django_polls_token_auth.zip">Click Here to Download the Sample Code</a></p>
<h2>How to use the Sample Code</h2>
<ol>
<li>Unzip the code repository</li>
<li>Change directory to the unzipped code repository</li>
<li>Run the command <code>python manage.py runserver</code></li>
<li>Go to <a href="http://localhost:8000/polls/">http://localhost:8000/polls/</a> to run the code.</li>
<li>You’ll be redirected to a very crude login form</li>
<li>Type <code>admin</code> for the username and <code>admin</code> for the password</li>
<li>You’ll be redirected to the polls app and application should work.</li>
<li>Go to <a href="http://localhost:8000/accounts/logout">http://localhost:8000/accounts/logout</a> to invalidate the cookie that holds the Authentication Token.</li>
<li>Download <strong>Postman</strong> from <a href="https://www.getpostman.com/">https://www.getpostman.com/</a></li>
<li>Open Postman. Make sure the dropdown says, “GET”.</li>
<li>Type in: <a href="http://localhost:8000/polls/api/questions/1">http://localhost:8000/polls/api/questions/1</a> into the address bar.</li>
<li>Make sure under <em>Authorization</em> “No Auth” is selected.</li>
<li>Under “Headers” add the Header key: Content-Type. Make the Header value: application/json</li>
<li>Click “Send” and you should retrieve <code>"Authentication credentials were not provided."</code></li>
<li>Now, under “Headers” underneath “Content-Type” add the Header key: Authorization and add the Header value: “Token 93138ba960dfb4ef2eef6b907718ae04400f606a” (without the quotes).</li>
<li>Click “Send” again and you should be getting the correct data.</li>
</ol>
<h2>Homework (If you’d like…)</h2>
<ol>
<li>Look at <strong>ALL</strong> of my sample code.
<ul>
<li>Underneath the admin form in <code>login.html</code> there is some Javascript that creates a call to <code>http://localhost:8000/accounts/get_auth_token/</code> with my username and password. When I retrieve the token, I put it into a cookie called “token” and I redirect to the ‘/polls/‘ app.</li>
<li>In the <code>app.js</code> file (where my AngularJS code lives), [I created an “Interceptor”]. The purpose of it is to intercept requests and automatically add a Header with your token so that the Polls Application works correctly. If a request fails, it assumes the user isn’t authorized and redirects to the login form. </li>
</ul>
</li>
<li>Play around with Postman. As long as you keep the Authorization header you can run through the API endpoints and see what you get.</li>
<li>Play with [Python <em>Requests</em>]. Keep the Django Application running and see if you can write a program using Python Requests that will allow you to login and retrieve some information. </li>
</ol>
<p>The homework is to help you understand why you would want to use Token Authentication. You can create cool applications external to the Django Application that interface with your API. Give it a go and see what you come up with!</p>
<p>Until next time, Chris</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/3-things-you-need-to-authenticate-users-in-django/" title="3 Things You Need to Authenticate Users in Django">
            <h2>3 Things You Need to Authenticate Users in Django</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 27, 2016</span>.
            
        </p>

        <p>You want to authenticate users but you’re unsure how. The documentation isn’t the most helpful thing in the world. You think, “wow… this documentation assumes I know all this other stuff…”</p>
<p>What are the things you need to authenticate users? There are 3 things you need and I’m going to show you what each looks like.</p>
<h2>First: You need some routes</h2>
<p>You need authentication routes. I think it makes the most sense to create a separate app for this purpose. (Separate all your login logic from all your other logic)</p>
<p>Let’s look at some login routes:</p>
<p>_loginapp/urls.py</p>
<pre><code>from django.conf.urls import url
from django.conf import settings
from django.conf.urls.static import static

from . import views

urlpatterns = [
    # Session Login
    url(r'^login/$', views.login_user, name='login'),
    url(r'^logout/$', views.logout_user, name='logout'),
    url(r'^auth/$',  views.login_form, name='login_form'),
]
</code></pre>
<h2>Second: You’ll need some templates</h2>
<p>Templates are important. Templates are the HTML representation of your application. For example, at the bare minimum, you’ll need a way to let your users login. How do you do it? It doesn’t have to be pretty because this is <strong>JUST</strong> HTML.</p>
<p><em>loginapp/templates/loginapp/login.html</em></p>
<pre><code>&lt;form method='post' action="{%  url 'loginapp:login' %}"&gt;
    &lt;label for="username"&gt;Username:&lt;/label&gt;
    &lt;input type="text" name="username" /&gt;
    &lt;br&gt;
    &lt;label for="password"&gt;Password:&lt;/label&gt;
    &lt;input type="password" name="password" /&gt;
    &lt;br&gt;
    &lt;input type="submit" value="Login" /&gt;
&lt;/form&gt;
</code></pre>
<h2>Third: You’ll need some views</h2>
<p>The views you’ll need for login will be:<br />
1. The login form view (shows the login form)<br />
2. The POST view that will authenticate a user that is active / exists<br />
3. A view that will log the user out</p>
<p>Let’s start with the login form view (loginapp/auth):</p>
<pre><code>def login_form(request):
    return render(request, 'accounts/login.html', {})
</code></pre>
<p>This view simply renders our <code>login.html</code> template that we created above. It’s also possible to make only <strong>2</strong> routes (1 that will detect a POST request and 1 that will detect a GET request) however, I (personally) really like have separate views for each request method.</p>
<p>Here is an example of a view that will detect a username and password and use those credentials to authenticate a user and login the user thus creating a session specifically for that user.</p>
<pre><code>def login_user(request):
    username = request.POST.get('username')
    password = request.POST.get('password')
    user = authenticate(username=username, password=password)
    if user is not None:
        # the password verified for the user
        if user.is_active:
            login(request, user)
            return redirect('/polls/')
    return redirect(settings.LOGIN_URL, request)
</code></pre>
<p>This method will get the <code>username</code> and <code>password</code> from the POST request data. Then, we will use the <code>username</code> and <code>password</code> to try to authenticate a user that exists in our database.</p>
<p>If a user exists, we will try to login our user and redirect to our <code>polls</code> application. If the user does not exist we will redirect back to the login form.</p>
<p>How do you logout an authenticated user?</p>
<pre><code>def logout_user(request):
    logout(request)
    return redirect('/polls/')
</code></pre>
<p>This method will take the request object and user it to logout the logged in user. Once the user logs out, the application will redirect the user to our <code>polls</code> application.</p>
<p>This is the 3 things that you need to authenticate users in your Django application. (If you want to use Session Authentication with Django REST Framework) this is how you would accomplish this.</p>
<p>I hope that helps you when need to authenticate users in your future web application.</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I3" title="Michael Paquier: Postgres 10 highlight - Checkpoint skip logic">
            <h2>Michael Paquier: Postgres 10 highlight - Checkpoint skip logic</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 26, 2016</span>.
            
        </p>

        <p>It is too late for stories about Christmas, so here is a Postgres story
about the following commit of Postgres 10:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>commit: 6ef2eba3f57f17960b7cd4958e18aa79e357de2f
author: Andres Freund &lt;andres@anarazel.de&gt;
date: Thu, 22 Dec 2016 11:31:50 -0800
Skip checkpoints, archiving on idle systems.

Some background activity (like checkpoints, archive timeout, standby
snapshots) is not supposed to happen on an idle system. Unfortunately
so far it was not easy to determine when a system is idle, which
defeated some of the attempts to avoid redundant activity on an idle
system.

To make that easier, allow to make individual WAL insertions as not
being "important". By checking whether any important activity happened
since the last time an activity was performed, it now is easy to check
whether some action needs to be repeated.

Use the new facility for checkpoints, archive timeout and standby
snapshots.

The lack of a facility causes some issues in older releases, but in my
opinion the consequences (superflous checkpoints / archived segments)
aren't grave enough to warrant backpatching.

Author: Michael Paquier, editorialized by Andres Freund
Reviewed-By: Andres Freund, David Steele, Amit Kapila, Kyotaro HORIGUCHI
Bug: #13685
Discussion:
https://www.postgresql.org/message-id/20151016203031.3019.72930@wrigleys.postgresql.org
https://www.postgresql.org/message-id/CAB7nPqQcPqxEM3S735Bd2RzApNqSNJVietAC=6kfkYv_45dKwA@mail.gmail.com
Backpatch: 
</code></pre>
</div>

<p>Postgres 9.0 has been the first release to introduce the parameter
<a href="https://www.postgresql.org/docs/devel/static/runtime-config-wal.html#runtime-config-wal-settings">wal_level</a>,
with three different values:</p>

<ul>
  <li>“minimal”, to get enough information WAL-logged to recover from a crash.</li>
  <li>“archive”, to be able to recover from a base backup and archives.</li>
  <li>“hot_standby”, to be able to have a standby node work, resulting in
  information about exclusive locks and currently running transactions
  to be WAL-logged, called standby snapshots.</li>
  <li>“logical”, introduced in 9.4, to work with logical decoding.</li>
</ul>

<p>In 9.6, “archive” and “hot_standby” have been merged into “replica” as
both levels have no difference in terms of performance. Another thing to
know is that standby snapshots are generated more often since 9.3 via the
bgwriter process, every 15 seconds to be exact.</p>

<p>So what is the commit above about? The fact that since “hot_standby” has
been introduced the logic that was present in xlog.c to decide if checkpoints
should be skipped or not was simply broken. As “hot_standby” has become a
standard in terms of configuration, many installations have been producing
useless checkpoints, or even useless WAL segments if archive_timeout was
being set. This is actually no big deal for most installations, as there
should always be some activity on a system, by that is meant activity that
produces new WAL records, hence a checkpoints or a WAL segment switch after
a timeout (if archive_timeout is set), would still have resulted in an
operation to happen.</p>

<p>The main issue here are embedded systems, where Postgres runs for ages
without intervention. For example an instance managing some internal
facility of a company very likely faces a downspike of activity on weekends,
because nobody is a robot and bodies need rest. Useless checkpoints being
generated actually can result in more WAL segments created. And while storing
those segments is not really a problem if they are compressed as the remaining
empty part is filled with zeros, installations that do not compress them
need some extra time to recover those segments in case of a crash, and that’s
even more painful for developments that have a spiky WAL activity.</p>

<p>This has resulted in a couple of bug reports and misunderstandings over
the last couple of years on the community mailing lists like
<a href="https://www.postgresql.org/message-id/20151016203031.3019.72930@wrigleys.postgresql.org">this thread</a>.</p>

<p>So in order to fix this problem has been designed a system allowing
to mark a WAL record as “important” or not regarding the activity it
creates. There has been much debate about the wording of this concept,
named at some point as well “progress”, debate going on for perhaps more
than a hundred of emails across many threads. There is also a set of
routines that can be used to fetch the last important WAL position that
can be used for more checks and do more fancy decision-making.</p>

<p>With this facility in place, records related to archive_timeout, understand
here WAL segment switch, and standby snapshots (WAL-logging of exclusive locks
and running transactions for hot standby nodes) are considered as
unimportant WAL activity to decide if a checkpoint should be executed or not.
Once those records are marked as such, deciding if a checkpoint should be
skipped or not is just a matter of comparing the WAL position of the last
checkpoint record with the last important WAL position. If they match, no
checkpoint need to happen. And then embedded systems are happy.</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/how-do-i-implement-session-authentication-in-django-rest-framework/" title="How do I Implement Session Authentication in Django REST Framework?">
            <h2>How do I Implement Session Authentication in Django REST Framework?</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 23, 2016</span>.
            
        </p>

        <h2>Introduction to Session Authentication</h2>
<p>Session Authentication when used with Django REST Framework allows you to authenticate users very similar to the way Django authenticates users without Django REST Framework.</p>
<p>This will make it extremely easy to introduce a REST API to your web app without having to completely overhaul your authentication system.</p>
<p>The best part of this Authentication Scheme is you literally only have to change <strong>ONE</strong> line of your Django Application.</p>
<h2>Implementation Details (all the little bits…)</h2>
<p>In your <code>settings.py</code> file, just add <code>'rest_framework.authentication.SessionAuthentication',</code> to your <code>DEFAULT_AUTHENTICATION_CLASSES</code> setting.</p>
<p><em>myproject/settings.py</em></p>
<pre><code>REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework.authentication.SessionAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': (
        'rest_framework.permissions.IsAuthenticated',
    )
}
</code></pre>
<p>Now, you will be able to login using the login form that you learned how to create when you took the <a href="https://docs.djangoproject.com/en/1.10/intro/tutorial01/">Polls Django Tutorial</a>.</p>
<p>If you’d like an example of how this is accomplished, I’ve updated the Django Application I used to show you how to implement Basic Authentication using Django REST Framework. Now, it works using Session Authentication.</p>
<p><a href="http://www.chrisbartos.com/wp-content/uploads/2016/12/django_polls_session_auth.zip">Click Here to Download the Sample Code</a></p>
<h2>How to use this Sample Code</h2>
<ol>
<li>Unzip the code repository</li>
<li>Change directory to the unzipped code repository</li>
<li>Run the command <code>python manage.py runserver</code></li>
<li>Go to <a href="http://localhost:8000/polls/">http://localhost:8000/polls/</a> to run the code.</li>
<li>You’ll be redirected to a very crude login form</li>
<li>Type <code>admin</code> for the username and <code>admin</code> for the password</li>
<li>You’ll be redirected to the polls app and application should work.</li>
<li>Go to <a href="http://localhost:8000/accounts/logout">http://localhost:8000/accounts/logout</a> to logout of your session.</li>
<li>Go to <a href="http://localhost:8000/polls/api/questions/1">http://localhost:8000/polls/api/questions/1</a> to checkout the API (it should tell you that you’re not authenticated to look at the data).</li>
<li>Go to <a href="http://localhost:8000/accounts/login">http://localhost:8000/accounts/login</a> and login with <code>admin</code> for the username and <code>admin</code> for the password.</li>
<li>Go back to <a href="http://localhost:8000/polls/api/questions/1">http://localhost:8000/polls/api/questions/1</a> and you should be able to see the data now that you are signed in.</li>
</ol>
<p>That is the Session Authentication Scheme in a nutshell. I hope you realize how simple it is to implement. Now… for some homework!</p>
<h2>Homework (If you’d like…)</h2>
<ol>
<li>Use the sample application and change the static login form into an AJAX style form. (So, when you put in <code>admin</code> for the username and password and click <code>login</code> there should be an AJAX POST request with the username, password and CSRF Token that will attempt to login the user and either send a success message or a failure message. Then, redirect the user back to the <code>/polls/</code>. If you’re unsure how to add a CSRF Token to all AJAX requests, sign up for my FREE Django REST Framework email course below.)</li>
</ol>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I2" title="Pavel Stehule: OpenERP configuration">
            <h2>Pavel Stehule: OpenERP configuration</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 23, 2016</span>.
            
        </p>

        I had a customer with strange issues of OpenERP - the main problem was long life of OpenERP/PostgreSQL sessions. The fix was not hard - using pgBouncer in transaction mode with short server life time (ten minutes).
    </div>
    <div class="feedEntry">

        <a href="http://www.chrisbartos.com/articles/list-of-authentication-schemes-available-for-django-rest-framework/" title="List of Authentication Schemes available for Django REST Framework">
            <h2>List of Authentication Schemes available for Django REST Framework</h2>
        </a>

        <p class="discreet">
            
                  By Chris Bartos from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 22, 2016</span>.
            
        </p>

        <h2>Do you know what your options are?</h2>
<p>You learned a little bit of how authentication works with Django REST Framework from my short, FREE mini email course. What you might <strong>NOT</strong> know is that <em>Basic Authentication</em> isn’t the only type of authentication available do you.</p>
<p>You can use the following authentication schemes in Django REST framework and keep checking your inbox for implementation details for each of these authentication schemes.</p>
<h2>The list of Authentication types in Django REST Framework</h2>
<ol>
<li>Basic Authentication — you learned how to implement this while following my free email course. If you haven’t signed up for the email course yet, put your email address in the form at the end of this post.</li>
<li>Session Authentication — this is similar to the authentication that Django uses to authenticate users.</li>
<li>Token Authentication — Token Auth is how most APIs authenticate users. You might have played around some APIs that require an “API Key”. This is how you would implement that for <strong>your</strong> users.</li>
<li>Custom Authentication — If for some reason, the other authentication schemes don’t do what you want, you can override the BaseAuthentication class and create your own authentication scheme in Django REST Framework.</li>
<li>OAuth2 Authentication — OAuth authentication is a way to allow your users to authenticate using things like Social Media. I’m sure you’ve logged into certain web apps that allowed you to authenticate using Google or Facebook. This allows you to do that!</li>
</ol>
<h2>Which Authentication scheme is best for me?</h2>
<p>That will depend on your specific use case. If you know how to implement each of them, you’ll be better off in the long run. Come back to this post periodically. Each of the authentication schemes above will eventually link to a post that will show you <strong>EXACTLY</strong> how to implement each one.</p>
<p>If you’d rather not come back for each post, simply put your email in the box below and you’ll get every new post sent directly to your inbox!</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I1" title="Scott Mead: PostgreSQL Schema Visualization">
            <h2>Scott Mead: PostgreSQL Schema Visualization</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 22, 2016</span>.
            
        </p>

        <p>I spend a lot of time trying to learn what&#8217;s already been implemented, as DBA&#8217;s, we tend to live in that world.  It&#8217;s important that you have tools that allow you to quickly get the visual so you can get on with your job.  One of the biggest &#8216;reverse engineering&#8217; tasks that DBA&#8217;s have to do is in the area of data modeling.  There&#8217;s a lot of tools that do this, but my favorite of late is SchemaSpy (schemapy.sf.net).  I&#8217;ve found that the output is complete and the ERD&#8217;s are easy to read.</p>
<p><code>java -jar schemaSpy_5.0.0.jar -t pgsql -host localhost:5432 -db postgres \<br />
     -dp ~/software/pg/drivers/jdbc/postgresql-9.4.1208.jre6.jar \<br />
     -o ERD -u postgres -s myschema</code></p>
<p>SchemaSpy is nice because it can talk to many different types of databases&#8230; a side effect of this is a fairly complex set of commandline switches.</p>
<p>-t specifies the type, -t pgsql specifies postgres<br />
-o specifies a directory to create the output in</p>
<p>All you need in order to run this is the SchemaSpy jar and a postgresql jdbc driver.  In the output directory &#8216;ERD&#8217;.  Pulling up ERD/index.html gives you a nice page with a table list and some basics.</p>
<p><img alt="SchemaSpyDash" class="alignnone size-medium wp-image-6784" height="272" src="http://wwwres.openscg.com/wp-content/uploads/2016/12/22221455/Screen-Shot-2016-12-22-at-5.02.24-PM-300x272.png" width="300" /></p>
<p>As a DBA, I really love the &#8216;Insertion Order&#8217; and &#8216;Deletion Order&#8217; links here.  SchemaSpy reverse engineers the referential integrity chain for me!  Clicking either one gives me a simple page, top to bottom with the right order!</p>
<p><img alt="InsertionOrder" class="alignnone size-medium wp-image-6785" height="255" src="http://wwwres.openscg.com/wp-content/uploads/2016/12/22221457/Screen-Shot-2016-12-22-at-5.08.17-PM-300x255.png" width="300" /></p>
<p>Now for the real reason that I super-love SchemaSpy.  The &#8216;Relationships&#8217; tab.  I&#8217;ve loaded up a pgbench schema.  pgbench doesn&#8217;t actually create any real keys, but column names are consistent.  SchemaSpy notices this and &#8216;infers&#8217; relationships for me!  This is huge, even without explicity keys, I can begin to infer what the developer intended (the estimated rowcount is helpful too <img alt="🙂" class="wp-smiley" src="https://s.w.org/images/core/emoji/2/72x72/1f642.png" style="height: 1em;" /></p>
<p><img alt="Relationships" class="alignnone size-medium wp-image-6786" height="270" src="http://wwwres.openscg.com/wp-content/uploads/2016/12/22221500/Screen-Shot-2016-12-22-at-5.09.09-PM-300x270.png" width="300" /></p>
<p>I won&#8217;t force you to follow me through all of the tabs.  If you&#8217;re looking for a schema visualization tool, give SchemaSpy a try.</p>
<p>Happy PostgreSQL-ing!</p>
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3I0" title="Jeff McCormick: Easy PostgreSQL Cluster Recipe Using Docker 1.12 and Swarm">
            <h2>Jeff McCormick: Easy PostgreSQL Cluster Recipe Using Docker 1.12 and Swarm</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 22, 2016</span>.
            
        </p>

        <div class="hs-featured-image-wrapper"> 
 <a class="hs-featured-image-link" href="http://info.crunchydata.com/blog/easy-postgresql-cluster-recipe-using-docker-1.12" title=""> <img alt="DockerNPostgresLogos.png" class="hs-featured-image" src="http://info.crunchydata.com/hubfs/DockerNPostgresLogos.png?t=1482428535246" style="width: auto !important; float: left; margin: 0 15px 15px 0;" /> </a> 
</div>    
<p>In this blog I’ll show you how to deploy a PostgreSQL cluster using the latest Docker 1.12 technology. Updates to Docker in their 1.12 release greatly simplify deploying a PostgreSQL cluster. IP addresses and hostnames used in this blog are just examples and not mandated.</p>    
<img alt="" height="1" src="http://track.hubspot.com/__ptq.gif?a=2283855&amp;k=14&amp;r=http%3A%2F%2Finfo.crunchydata.com%2Fblog%2Feasy-postgresql-cluster-recipe-using-docker-1.12&amp;bu=http%253A%252F%252Finfo.crunchydata.com%252Fblog&amp;bvt=rss" style="width: 1px!important;" width="1" />
    </div>
    <div class="feedEntry">

        <a href="https://postgr.es/p/3H_" title="Marco Slot: Scaling out relational data models, and SQL, through co-location">
            <h2>Marco Slot: Scaling out relational data models, and SQL, through co-location</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Dec 22, 2016</span>.
            
        </p>

        <p>Relational databases are the first choice of data store for many applications due to their enormous flexibility and reliability. Historically the one knock against relational databases is that they can only run on a single machine, which creates inherent limitations when data storage needs outpace server improvements. The solution to rapidly scaling databases is to distribute them, but this creates a performance problem of its own: relational operations such as joins then need to cross the network boundary. Co-location is the practice of dividing data tactically, where one keeps related information on the same machines to enable efficient relational operations, but takes advantage of the horizontal scalability for the whole dataset.</p>

<p>The principle of data co-location is that all tables in the database have a common distribution column and are sharded across machines in the same way such that rows with the same distribution column value are always on the same machine, even across different tables. As long as the distribution column provides a meaningful grouping of data, relational operations can be performed within the groups. </p>

<p>In a <a href="https://www.citusdata.com/blog/2016/10/03/designing-your-saas-database-for-high-scalability/">previous article</a> we described how to shard a multi-tenant application with co-location as the underlying technique. In this article, we zoom into how data co-location works in Citus and the benefits it provides.</p>

<h3>Data co-location in Citus for hash-distributed tables</h3>

<p>The Citus extension for PostgreSQL is unique in being able to form a distributed database of databases. Every node in a Citus cluster is a fully functional PostgreSQL database and Citus adds the experience of a single homogenous database on top. While it does not provide the full functionality of PostgreSQL in a distributed way, in many cases it can take full advantage of features offered by PostgreSQL on a single machine through co-location, including full SQL support, transactions and foreign keys. </p>

<p>In Citus a row is stored in a shard if the hash of the value in the distribution column falls within the shard’s hash range. To ensure co-location, shards with the same hash range are always placed on the same node even after rebalance operations, such that equal distribution column values are always on the same node across tables.</p>

<p><img alt="hash ranges" src="https://d3vv6lp55qjaqc.cloudfront.net/items/0P422j29173t2r0t2F22/hash-ranges.png?X-CloudApp-Visitor-Id=e4475d145dcf11ebcffabf840edcc11f&amp;v=a62a5b08" /></p>

<p>A distribution column that we’ve found to work well in practice is tenant ID in <a href="https://www.citusdata.com/blog/2016/08/10/sharding-for-a-multi-tenant-app-with-postgres/">multi-tenant applications</a>. For example, SaaS applications typically have many tenants, but every query they make is specific to a particular tenant. While providing a database or schema for every tenant is one option, it is often <a href="https://influitive.io/our-multi-tenancy-journey-with-postgres-schemas-and-apartment-6ecda151a21f">costly and impractical</a> as there can be many operations that span across users (data loading, migrations, aggregations, analytics, schema changes, backups, etc.) that becomes harder to manage as the number of tenants grows.</p>

<h3>A practical example of co-location</h3>

<p>Consider the following tables, that might be part of a multi-tenant web analytics SaaS:</p>
<pre class="highlight sql"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">event</span> <span class="p">(</span>
    <span class="n">event_id</span> <span class="n">bigint</span><span class="p">,</span>
    <span class="n">tenant_id</span> <span class="n">int</span><span class="p">,</span>
    <span class="n">page_id</span> <span class="n">int</span><span class="p">,</span>
    <span class="n">payload</span> <span class="n">jsonb</span><span class="p">,</span> 
    <span class="k">primary</span> <span class="k">key</span> <span class="p">(</span><span class="n">tenant_id</span><span class="p">,</span> <span class="n">event_id</span><span class="p">)</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">page</span> <span class="p">(</span>
    <span class="n">page_id</span> <span class="n">int</span><span class="p">,</span>
    <span class="n">tenant_id</span> <span class="n">int</span><span class="p">,</span>
    <span class="n">path</span> <span class="n">text</span><span class="p">,</span> 
    <span class="k">primary</span> <span class="k">key</span> <span class="p">(</span><span class="n">tenant_id</span><span class="p">,</span> <span class="n">page_id</span><span class="p">)</span>
<span class="p">);</span>
</code></pre>
<p>Now we want to answer queries that may be issued by a customer-facing dashboard, such as:</p>

<p>“Return the number of visits in the past week for all pages starting with ‘/blog’ for tenant 6”</p>

<h3>Using Regular PostgreSQL Tables</h3>

<p>If our data was in a single PostgreSQL node, we could easily express our query using the rich set of relational operations offered by SQL:</p>
<pre class="highlight sql"><code><span class="k">SELECT</span> <span class="n">page_id</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="n">event_id</span><span class="p">)</span>
<span class="k">FROM</span>
  <span class="n">page</span> 
<span class="k">LEFT</span> <span class="k">JOIN</span>  <span class="p">(</span>
  <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">event</span>
  <span class="k">WHERE</span> <span class="p">(</span><span class="n">payload</span><span class="o">-&gt;&gt;</span><span class="s1">'time'</span><span class="p">)::</span><span class="n">timestamptz</span> <span class="o">&gt;=</span> <span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">interval</span> <span class="s1">'1 week'</span>
<span class="p">)</span> <span class="n">recent</span> 
<span class="k">USING</span> <span class="p">(</span><span class="n">tenant_id</span><span class="p">,</span> <span class="n">page_id</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">tenant_id</span> <span class="o">=</span> <span class="mi">6</span> <span class="k">AND</span> <span class="n">path</span> <span class="k">LIKE</span> <span class="s1">'/blog%'</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">page_id</span><span class="p">;</span>
</code></pre>
<p>As long the <a href="https://en.wikipedia.org/wiki/Working_set">working set</a> for this query fits in memory, this is an appropriate solution for many application since it offers maximum flexibility. However, even if you don’t need to scale yet, it can be useful to consider the implications of scaling out on your data model.</p>

<h3>Distributing tables by ID</h3>

<p>As the number of tenants and the data stored for each tenant grows, query times will typically go up as the working set no longer fits in memory or CPU becomes a bottleneck. In this case, we can shard the data across many nodes using Citus. The first and most important choice we need to make when sharding is the distribution column. Let’s start with a naive choice of using <code>event_id</code> for the <code>event</code> table and <code>page_id</code> for the <code>page</code> table:</p>
<pre class="highlight sql"><code><span class="c1">-- create Citus tables, naively use event_id and page_id as distribution columns</span>
<span class="k">SELECT</span> <span class="n">create_distributed_table</span><span class="p">(</span><span class="s1">'event'</span><span class="p">,</span> <span class="s1">'event_id'</span><span class="p">);</span>
<span class="k">SELECT</span> <span class="n">create_distributed_table</span><span class="p">(</span><span class="s1">'page'</span><span class="p">,</span> <span class="s1">'page_id'</span><span class="p">);</span>
</code></pre>
<p>Given that the data is dispersed across different workers, we cannot simply perform a join as we would on a single PostgreSQL node. Instead, we will need to answer this query in two steps:</p>

<p>Across all shards of the page table (Q1):</p>
<pre class="highlight sql"><code><span class="k">SELECT</span> <span class="n">page_id</span> <span class="k">FROM</span> <span class="n">page</span> <span class="k">WHERE</span> <span class="n">path</span> <span class="k">LIKE</span> <span class="s1">'/blog%'</span> <span class="k">AND</span> <span class="n">tenant_id</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
</code></pre>
<p>Across all shards of the event table (Q2):</p>
<pre class="highlight sql"><code><span class="k">SELECT</span> <span class="n">page_id</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">AS</span> <span class="k">count</span>
<span class="k">FROM</span> <span class="n">events</span>
<span class="k">WHERE</span> <span class="n">page_id</span> <span class="k">IN</span> <span class="p">(</span><span class="n">ARRAY</span><span class="p">[...</span><span class="n">page</span> <span class="n">IDs</span> <span class="k">from</span> <span class="k">first</span> <span class="n">query</span><span class="p">...])</span> <span class="k">AND</span> 
      <span class="n">tenant_id</span> <span class="o">=</span> <span class="mi">6</span> <span class="k">AND</span> 
      <span class="n">payload</span><span class="o">-&gt;&gt;</span><span class="s1">'time'</span> <span class="o">&gt;=</span> <span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">interval</span> <span class="s1">'1 week'</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">page_id</span> <span class="k">ORDER</span> <span class="k">BY</span> <span class="k">count</span> <span class="k">DESC</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>
</code></pre>
<p>Afterwards, the results from the two steps need to be combined by the application.</p>

<p>The data required to answer the query is scattered across the shards on the different nodes and each of those shards will need to be queried:</p>

<p><img alt="without-colocation" src="https://d3vv6lp55qjaqc.cloudfront.net/items/0u0N291S032U3U0S1Q1v/without-colocation.png?X-CloudApp-Visitor-Id=e4475d145dcf11ebcffabf840edcc11f&amp;v=96e3c57f" /></p>

<p>In this case, the data distribution creates substantial drawbacks:</p>

<p>Overhead from querying each shard, running multiple queries
Overhead of Q1 returning many rows to the client, also causes Q2 to be very large
Need to write queries in multiple steps, combine results, requires changes in the application</p>

<p>A potential upside of the relevant data being dispersed is that the queries can be parallelised, which Citus will do. However, this is only beneficial if the amount of work that the query does is substantially greater than the overhead of querying many shards. It’s generally better to avoid doing such heavy lifting directly from the application, for example by <a href="https://www.citusdata.com/blog/2016/11/29/event-aggregation-at-scale-with-postgresql/">pre-aggregating the data</a>.</p>

<h3>Distributing tables by tenant</h3>

<p>Looking at our query again, we can see that all the rows that the query needs have one dimension in common: <code>tenant_id</code>. The dashboard will only ever query for a tenant’s own data. That means that if data for the same tenant are always co-located on a single PostgreSQL node, our original query could be answered in a single step by that node by performing a join on <code>tenant_id</code> and <code>page_id</code>.</p>

<p>In Citus, rows with the same distribution column value are guaranteed to be on the same node. Each shard in a distributed table effectively has a set of co-located shards from other distributed tables that contain the same distribution column values (data for the same tenant). Starting over, we can create our tables with <code>tenant_id</code> as the distribution column.</p>
<pre class="highlight sql"><code><span class="c1">-- create Citus tables, co-locate them by using a common distribution column</span>
<span class="k">SELECT</span> <span class="n">create_distributed_table</span><span class="p">(</span><span class="s1">'event'</span><span class="p">,</span> <span class="s1">'tenant_id'</span><span class="p">);</span>
<span class="k">SELECT</span> <span class="n">create_distributed_table</span><span class="p">(</span><span class="s1">'page'</span><span class="p">,</span> <span class="s1">'tenant_id'</span><span class="p">);</span>
</code></pre>
<p>In this case, Citus can answer the same query that you would run on a single PostgreSQL node without modification (Q1):</p>
<pre class="highlight sql"><code><span class="k">SELECT</span> <span class="n">page_id</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="n">event_id</span><span class="p">)</span>
<span class="k">FROM</span>
  <span class="n">page</span> 
<span class="k">LEFT</span> <span class="k">JOIN</span>  <span class="p">(</span>
  <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">event</span>
  <span class="k">WHERE</span> <span class="p">(</span><span class="n">payload</span><span class="o">-&gt;&gt;</span><span class="s1">'time'</span><span class="p">)::</span><span class="n">timestamptz</span> <span class="o">&gt;=</span> <span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">interval</span> <span class="s1">'1 week'</span>
<span class="p">)</span> <span class="n">recent</span> 
<span class="k">USING</span> <span class="p">(</span><span class="n">tenant_id</span><span class="p">,</span> <span class="n">page_id</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">tenant_id</span> <span class="o">=</span> <span class="mi">6</span> <span class="k">AND</span> <span class="n">path</span> <span class="k">LIKE</span> <span class="s1">'/blog%'</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">page_id</span><span class="p">;</span>
</code></pre>
<p>Because of the tenant<em>id filter and join on tenant</em>id, Citus knows that the entire query can be answered using the set of co-located shards that contain the data for that particular tenant, and the PostgreSQL node can answer the query in a single step, which enables full SQL support.</p>

<p><img alt="with colocation" src="https://d3vv6lp55qjaqc.cloudfront.net/items/2a2B3s2x021n203I1g22/with-colocation.png?X-CloudApp-Visitor-Id=e4475d145dcf11ebcffabf840edcc11f&amp;v=bc3e5081" /></p>

<p>In some cases, queries and table schemas will require minor modifications to ensure that the tenant_id is always included in unique constraints and join conditions. However, this is usually a straightforward change, and the extensive rewrite that would be required without having co-location is avoided.</p>

<p>While the example above queries just one node because there is a specific <code>tenant_id = 6</code> filter, co-location also allows us to efficiently perform distributed joins on <code>tenant_id</code> across all nodes, be it with SQL limitations.</p>

<h3>Co-location means better feature support</h3>

<p>The full list of Citus features that are unlocked by co-location are:</p>

<ul>
<li>Full SQL support for queries on a single set of co-located shards</li>
<li>Multi-statement transaction support for modifications on a single set of co-located shards</li>
<li><a href="https://www.citusdata.com/blog/2016/11/29/event-aggregation-at-scale-with-postgresql/">Aggregation through INSERT..SELECT</a></li>
<li>Foreign keys</li>
<li>Distributed <a href="https://www.citusdata.com/blog/2016/10/10/outer-joins-in-citus/">outer joins</a></li>
</ul>

<p>This list is likely to grow further in the future, as we leverage the underlying PostgreSQL databases for co-located data.</p>

<p>Data co-location is a powerful technique for providing both horizontal scale and supporting relational data models. The cost of migrating or building applications using a distributed database that enables relational operations through co-location is often substantially lower than moving to a restrictive data model (e.g. NoSQL) and unlike a single-node database it can scale out with the size of your business.</p>

<p>Citus allows you to automatically shard and co-locate your data, providing horizontal scale while taking advantage of PostgreSQL’s rich feature set. If you would like to give Citus a try, you can set up a fully managed cluster in minutes using <a href="https://www.citusdata.com/product/cloud">Citus Cloud</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="http://lethain.com/braindump-on-load-generation/" title="Braindump on Load Generation">
            <h2>Braindump on Load Generation</h2>
        </a>

        <p class="discreet">
            
                  By Will Larson from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 18, 2016</span>.
            
        </p>

        <p>Stripe is starting to <a href="https://stripe.com/jobs/positions/infrastructure-engineer">build out a load generation team in Seattle</a> (that&rsquo;s a posting for San Francisco,
but also works for Seattle), and consequently I&rsquo;ve
been thinking more about load generation lately. In particular, I&rsquo;ve been thinking that I know
a lot less about the topic than I&rsquo;d like to, so here is a collection of sources and reading notes.</p>

<p>Hopefully, I&rsquo;ll  synthesize these into something readable soon!</p>

<h3>The Interesting Questions</h3>

<p>Perhaps because many companies never develop a mature solution for load generation,
and because none of the open source solutions command broad awareness (except maybe JMeter?),
it tends to be a place with far more opinions than average, and consequently there
are quite a few interesting questions to think through.</p>

<p>Let&rsquo;s start by exploring a few of those.</p>

<ol>
<li><p><strong>Should you be load testing?</strong> Surprisingly few companies invest much into load testing,
so it&rsquo;s never entirely clear if you <em>should</em> be investing at a given point in time.
My anecdotal impression is that companies which &ldquo;believe in QA&rdquo; tend to invest into load
testing early, because they have dedicated people who can build the tooling and integration,
and that most other companies tend to ignore it until they&rsquo;re doing a significant amount of
unplanned scalability investment. Said differently, for most companies
load testing is a mechanism to convert unplanned scalability work into planned scalability work.</p></li>

<li><p><strong>Should you be load testing, redux?</strong> Beyond whether you should invest into building load testing tooling,
<a href="https://twitter.com/davinbogan">my colleague Davin</a> suggested an interesting perspective
that most of the metrics generated by load testing can also be obtained through thoughtful
instrumentation and analysis of your existing traffic.</p></li>

<li><p><strong>What layer of your infrastructure should you load test against?</strong>
Depending on the application you&rsquo;re running, it may be easy to generate load against your external interfaces (website, API, etc)
but as you go deeper into your infrastructure you may want to run load
against a specific service or your stateful systems (Kafka, databases, etc).</p></li>

<li><p><strong>What environment should you run your tests against?</strong> Perhaps the most common argument when
rolling out load testing is whether you should run it against an existing QA environment,
against a dedicated performance environment, or against your production environment.
This depends a great deal on the layer you&rsquo;re testing at, and if you&rsquo;re doing load
(how does the system react to this traffic?) or stress (at what load does the system fail?)
testing.</p></li>

<li><p><strong>How should you model your traffic?</strong> Starting with the dead simple <a href="https://github.com/JoeDog/siege">Siege</a>,
there are quite a few different ways to think about generating your load.
Should you send a few request patterns at a high concurrency? Should you model your traffic using
a state machine (codified in a simple script, or perhaps in a DSL), or should you just replay
sanitized production traffic?</p></li>

<li><p><strong>Is the distinction between integration testing and load testing just a matter of scale?</strong>
As you start thinking about it, integration testing is running requests against a server and
ensuring the results are reasonable, and that&rsquo;s pretty much the exact same thing as
load testing. It&rsquo;s pretty tempting to try to solve both problems with one tool.</p></li>

<li><p><strong>How should you configure load tests? Where should that configuration live?</strong>
Merging into the whole &ldquo;is configuration code?&rdquo; debate, where should the configuration
for your load tests live? Ideally it would be in your service&rsquo;s repository, right?
Or perhaps it should be stored in a dynamic configuration database somewhere to
allow more organic exploration and testing? Hmm.</p></li>
</ol>

<p>Alright then, with those questions in mind, time to read some papers.</p>

<h3><a href="http://barbie.uta.edu/~jxu/Stress%20testing.htm">Stress and Load Testing Research</a></h3>

<p>As part of my research, I ran into <a href="http://barbie.uta.edu/~jxu/Stress%20testing.htm">an excellent list of stress and load testing papers</a>
from the Software Engineering Research Group at University of Texas Arlington. Many of these
papers are pulled from there, and it&rsquo;s a great starting point for your reading as well!</p>

<h3><a href="http://barbie.uta.edu/~jxu/A%20Methodology%20to%20Support%20Load%20Test%20Analysis.pdf">A Methodology to Support Load Test Analytics</a></h3>

<p><a href="http://barbie.uta.edu/~jxu/A%20Methodology%20to%20Support%20Load%20Test%20Analysis.pdf">A Methodology to Support Load Test Analytics</a> (2010) starts with an excellent
thought on why load testing is becoming increasingly important and complex:</p>

<blockquote>
<p>For [ultra large scale systems], it is impossible for an analyst to skim
through the huge volume of performance counters to find the
required information. Instead, analyst employ few key
performance counters known to [her] from past practice,
performance gurus and domain trends as &lsquo;rules of thumb&rsquo;. In a
ULSS, there is no single person with complete knowledge of end
to end geographically distributed system activities.</p>
</blockquote>

<p>That rings true to my experience.</p>

<p>With increasingly complex systems,
it is remarkably hard to actually find the performance choke points,
and load testing aspires to offer the distributed
systems equivalent of a profiler. (This is also why QA environments
are fraught with failures: as systems become increasingly complex, creating a useful
facimile becomes rather hard.)</p>

<p>A few other interesting ideas:</p>

<ol>
<li>Fairly naive software can batch together highly correlated metrics, to greatly reduce
the search space for humans to understand where things are degrading.</li>
<li>Most test designs mean they can only run occasionally (as opposed to continuously), and interfering workloads
(e.g. a weekly batch job occuring during your load test)
can easily invalidate the data of those infrequent runs.</li>
<li>Many tests end up with artificial constraints when run against non-production environments
like QA, for example running against underpowered or mis-configured databases.</li>
<li>They use &ldquo;Principal Component Analysis&rdquo; to find the minimal principal components
which are <em>not</em> correlated with each other, so you have less redundant data to explore.</li>
<li>After they&rsquo;ve found the key Principal Components, they then convert those back into the underlying
counters, which are human comprehensible, for further analysis.</li>
<li>Ideally, you should be able to use historical data to build load signatures, such that you
could quickly determine if the system&rsquo;s fundamental constraint has shifted (e.g. you&rsquo;ve
finally fixed your core bottleneck and got a new one, or something else has degraded such
that it is not your core bottleneck).</li>
</ol>

<p>In particular, my take away is that probably the right load generation tool
will start with a fairly simple approach with manually identified key metrics, and then
move increasingly to using machine learning to avoid our implicit biases around where our
systems <em>ought</em> to be slow.</p>

<h3><a href="http://du.diva-portal.org/smash/get/diva2:518118/FULLTEXT01">A Unified Load Generator For Geographically&hellip;</a></h3>

<p><a href="http://du.diva-portal.org/smash/get/diva2:518118/FULLTEXT01">A Unified Load Generator for Geographically Distributed Generation of Network Traffic</a> (2006)
is a master&rsquo;s thesis, that happens to be an pretty excellent survey of
academic ideas and topics around load generation.</p>

<p>One of the interesting ideas here is:</p>

<blockquote>
<p>to design an accurate artificial load generator which is responsible to act in a flexible
manner under different situations we need not only a load model but also a formal method to specify
the realistic load.</p>
</blockquote>

<p>I&rsquo;m not sure I entirely agree that we need a formal model to get value from our load testing,
we are after all trying to convert unplanned scalability work into planned scalability work,
but I have such an industry focus that it&rsquo;s a fascinating idea to me that you would even try to
create a formal model here.</p>

<p>It also introduces a more specific vocabulary for discussing load generation:</p>

<blockquote>
<p>The workload or load L=L (E, S, IF, T) denotes the total sequence of requests which
is offered by an environment E to a service system S via a well-defined interface IF during the timeinterval
T.</p>
</blockquote>

<p>Perhaps more interestingly, is the emphasize on how <a href="http://lethain.com/qos-cost-quotas/">quality of service</a>
forces us to redefine the goal of load testing:</p>

<blockquote>
<p>The need for telecommunication networks capable of providing communication services such as
data, voice and video motivated to deliver an acceptable QoS level to the users, and their success
depends on the development of effective congestion control schemes.</p>
</blockquote>

<p>I find this a fascinating point. As your systems start to include more systematic load shedding mechanisms,
it becomes increasingly challenging to push them out of equilibrium because they (typically) preserve
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.3690&amp;rep=rep1&amp;type=pdf">harvest by degrading yield</a>.
It&rsquo;s consequently not enough to say that your systems should or should not fail at a given level of load,
you also have to start to measure if it degrades appropriately based on load levels.</p>

<p>In section 3.5, it explains (the seemingly well known, albeit not to me) UniLog, also known as the Unified Load Generator.
(Which is perhaps based on <a href="https://www.researchgate.net/publication/220769797_A_unified_load_generator_based_on_formal_load_specification_and_load_transformation">this paper</a>,
which is sadly hidden behind a paywall.) UniLog has an interesting architecture with intimidatingly
exciting component names like PLM, ELM, GAR, LT, ADAPT and EEM. As best I can tell it is an extremely
generic architecture for running and evaluating load experiments. It feels slightly overdesigned
from my first reading, but perhaps as one spends more time in the caverns of load generation it
starts to make more sense.</p>

<p>In section 4.4, it discusses centralized versus distributed load generation, which feels like
one of the core design decisions you need to make for building such a system. My sense is that
you likely want a distributed approach at some point, if only to avoid getting completely throttled
by QoS operating on a per-IP ratelimit.</p>

<p>The rest of the paper focuses on some case studies and such. Overall, it was a surprisingly thorough
introduction to the related research.</p>

<h3><a href="http://barbie.uta.edu/~jxu/Automated%20analysis%20of%20load%20testing%20results.pdf">Automated Analysis of Load Testing Results</a></h3>

<p><a href="http://barbie.uta.edu/~jxu/Automated%20analysis%20of%20load%20testing%20results.pdf">Automated Analysis of Load Testing Results</a> takes a look at using automation to understand
load test results (using both the execution logs of the load test and overall system metrics during
the load test).</p>

<p>It summarizes the challenges of analyzing load test results as: outdated documentation,
process-level profiling is cost prohibitive, load testing typically occurs late in the development
cycle with short time lines, and the output from load tests can be overwhelmingly large.</p>

<p>I think the most interesting take away for me is the idea of very explicitly decoupling the gathering
of performance data from its analysis. For example, you could start logging performance data early on
(and likely your metrics tool, e.g. Graphite, already is capturing that data), and invest into more
sophisticated analysis much later on. There is particular focus on comparing results across multiple
load test runs, which can at a minimum narrow in on where performance &ldquo;lives&rdquo; within your metrics.</p>

<h3>Even more papers&hellip;</h3>

<p>Some additional papers with short summaries:</p>

<p><a href="http://barbie.uta.edu/~jxu/Converting%20users%20to%20testers%20an%20alternative%20approach%20to%20load%20test%20script%20creation,%20parameterization%20and%20data%20corellation.pdf">Converting Users to Testers</a> - This paper discusses recording user traffic as an input to your load testing, with the goal of reducing time spent writing load generation scripts.</p>

<p><a href="http://barbie.uta.edu/~jxu/automatic%20feedback,%20contro-based%20stress%20and%20load%20testing.pdf">Automatic Feedback, Control-Based, Stress and Load Testing</a> - This paper
explores the idea of systems that try to drive and maintain load on a system to targeted threshold. This is an interesting idea
because this would allow you to consistently run load against your production environment. The only caveat is that you have
to first identify the inputs you want to use to influence that load, so you still need to model the incoming traffic in
order to use it as an input (or record and sanitize real traffic), but at least once you have modeled it you could be more
abstract in how you use that model (if your target is to create load, you don&rsquo;t necessarily need to simulate realistic
traffic, and you could use something like an n-armed bandit approach to &ldquo;optimize&rdquo; your load to generate the correct amount
of load against the system). (Similarly, <a href="http://barbie.uta.edu/~jxu/stress%20testing%20real-time%20systems%20with%20genetic%20algorithms.pdf">this paper tries to do that using genetic algorithms</a>.)</p>

<h3>Existing Tools</h3>

<p>There are surprisingly few load testing tools, although <a href="https://en.wikipedia.org/wiki/Load_testing#Software_load_testing">wikipedia has a short list</a>.
Of that list, I&rsquo;ve actually used <a href="http://jmeter.apache.org/">JMeter</a> some years ago, and I enjoyed
<a href="http://www.fredberinger.com/2010/05/why-is-hp-killing-loadrunner/">this short rant about HP&rsquo;s Loadrunner tooling</a>.</p>

<p>I took a brief look at <a href="http://gatling.io/">Gatling</a>, which is a lightweight DSL written in Scala,
which can be easily run by Jenkins or such. This seems like an interesting potential starting point
for building a load generation tool. In particular the concept of treating your load tests as something
you would check into your repository feels right, allowing you to iterate on your load tests like you
would anything else.
Reading through <a href="https://www.thoughtworks.com/insights/blog/gatling-take-your-performance-tests-next-level">a few</a>
other
<a href="http://callistaenterprise.se/blogg/teknik/2014/04/16/a-first-look-at-gatling-a-dsl-based-load-test-tool/">blog posts</a>
on Gatling gave me a stronger sense that this might be a useful component of an overall load testing system
(that allowed, e.g. many instances to be run against different endpoints or such).</p>

<p>Are there others that I&rsquo;m missing out on?</p>

<h3><a href="http://drops.dagstuhl.de/opus/volltexte/2011/2957/pdf/5.pdf">Web Workload Generation According to&hellip;</a></h3>

<p>As the name suggests, <a href="http://drops.dagstuhl.de/opus/volltexte/2011/2957/pdf/5.pdf">Web Workload Generation According to UniLoG Approach</a>
looks at adapting the UniLoG approach to the web. It nicely summarizes UniLoG&rsquo;s approach as well:</p>

<blockquote>
<p>The basic principle underlying the design and elaboration of
UniLoG has been to start with a formal description of an abstract load model and thereafter
to use an interface-dependent adapter to map the abstract requests to the concrete requests
as they are “understood” by the service providing component at the real interface in question.</p>
</blockquote>

<p>It also does a nice job of exploring ways to generate requests, although again coming back to
either using logs of existing traffic or generating a model which defines your workload. There
is an interesting hybrid here which would be using the distribution of actual usage as an input
for the generated load (as opposed to using load on a one to one basis).</p>

<p>That said, unfortunately, I didn&rsquo;t really get much out of it.</p>
    </div>
    <div class="feedEntry">

        <a href="http://lethain.com/braindump-on-load-generation/" title="Braindump on Load Generation">
            <h2>Braindump on Load Generation</h2>
        </a>

        <p class="discreet">
            
                  By Will Larson from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 18, 2016</span>.
            
        </p>

        <p>Stripe is starting to <a href="https://stripe.com/jobs/positions/engineering-manager-infrastructure">build out a load generation team in Seattle</a> (that&rsquo;s a posting for San Francisco,
but also works for Seattle), and consequently I&rsquo;ve
been thinking more about load generation lately. In particular, I&rsquo;ve been thinking that I know
a lot less about the topic than I&rsquo;d like to, so here is a collection of sources and reading notes.</p>

<p>Hopefully, I&rsquo;ll  synthesize these into something readable soon!</p>

<h3>The Interesting Questions</h3>

<p>Perhaps because many companies never develop a mature solution for load generation,
and because none of the open source solutions command broad awareness (except maybe JMeter?),
it tends to be a place with far more opinions than average, and consequently there
are quite a few interesting questions to think through.</p>

<p>Let&rsquo;s start by exploring a few of those.</p>

<ol>
<li><p><strong>Should you be load testing?</strong> Surprisingly few companies invest much into load testing,
so it&rsquo;s never entirely clear if you <em>should</em> be investing at a given point in time.
My anecdotal impression is that companies which &ldquo;believe in QA&rdquo; tend to invest into load
testing early, because they have dedicated people who can build the tooling and integration,
and that most other companies tend to ignore it until they&rsquo;re doing a significant amount of
unplanned scalability investment. Said differently, for most companies
load testing is a mechanism to convert unplanned scalability work into planned scalability work.</p></li>

<li><p><strong>Should you be load testing, redux?</strong> Beyond whether you should invest into building load testing tooling,
<a href="https://twitter.com/davinbogan">my colleague Davin</a> suggested an interesting perspective
that most of the metrics generated by load testing can also be obtained through thoughtful
instrumentation and analysis of your existing traffic.</p></li>

<li><p><strong>What layer of your infrastructure should you load test against?</strong>
Depending on the application you&rsquo;re running, it may be easy to generate load against your external interfaces (website, API, etc)
but as you go deeper into your infrastructure you may want to run load
against a specific service or your stateful systems (Kafka, databases, etc).</p></li>

<li><p><strong>What environment should you run your tests against?</strong> Perhaps the most common argument when
rolling out load testing is whether you should run it against an existing QA environment,
against a dedicated performance environment, or against your production environment.
This depends a great deal on the layer you&rsquo;re testing at, and if you&rsquo;re doing load
(how does the system react to this traffic?) or stress (at what load does the system fail?)
testing.</p></li>

<li><p><strong>How should you model your traffic?</strong> Starting with the dead simple <a href="https://github.com/JoeDog/siege">Siege</a>,
there are quite a few different ways to think about generating your load.
Should you reply a few requests at higher concurrency? Should you model your traffic using
a state machine (codified in a simple script, or perhaps in a DSL), or should you just replay
sanitized production traffic?</p></li>

<li><p><strong>Is the distinction between integration testing and load testing just a matter of scale?</strong>
As you start thinking about it, integration testing is running requests against a server and
ensuring the results are reasonable, and that&rsquo;s pretty much the exact same thing as
load testing. It&rsquo;s pretty tempting to try to solve both problems with one tool.</p></li>

<li><p><strong>How should you configure load tests? Where should that configuration live?</strong>
Merging into the whole &ldquo;is configuration code?&rdquo; debate, where should the configuration
for your load tests live? Ideally it would be in your service&rsquo;s repository, right?
Or perhaps it should be stored in a dynamic configuration database somewhere to
allow more organic exploration and testing? Hmm.</p></li>
</ol>

<p>Alright then, with those questions in mind, time to read some papers.</p>

<h3><a href="http://barbie.uta.edu/~jxu/Stress%20testing.htm">Stress and Load Testing Research</a></h3>

<p>As part of my research, I ran into <a href="http://barbie.uta.edu/~jxu/Stress%20testing.htm">an excellent list of stress and load testing papers</a>
from the Software Engineering Research Group at University of Texas Arlington. Many of these
papers are pulled from there, and it&rsquo;s a great starting point for your reading as well!</p>

<h3><a href="http://barbie.uta.edu/~jxu/A%20Methodology%20to%20Support%20Load%20Test%20Analysis.pdf">A Methodology to Support Load Test Analytics</a></h3>

<p><a href="http://barbie.uta.edu/~jxu/A%20Methodology%20to%20Support%20Load%20Test%20Analysis.pdf">A Methodology to Support Load Test Analytics</a> (2010) starts with an excellent
thought on why load testing is becoming increasingly important and complex:</p>

<blockquote>
<p>For [ultra large scale systems], it is impossible for an analyst to skim
through the huge volume of performance counters to find the
required information. Instead, analyst employ few key
performance counters known to [her] from past practice,
performance gurus and domain trends as &lsquo;rules of thumb&rsquo;. In a
ULSS, there is no single person with complete knowledge of end
to end geographically distributed system activities.</p>
</blockquote>

<p>That rings true to my experience.</p>

<p>With increasingly complex systems,
it is remarkably hard to actually find the performance choke points,
and load testing aspires to offer the distributed
systems equivalent of a profiler. (This is also why QA environments
are fraught with failures: as systems become increasingly complex, creating a useful
facimile becomes rather hard.)</p>

<p>A few other interesting ideas:</p>

<ol>
<li>Fairly naive software can batch together highly correlated metrics, to greatly reduce
the search space for humans to understand where things are degrading.</li>
<li>Most test designs mean they can only run occasionally (as opposed to continuously), and interfering workloads
(e.g. a weekly batch job occuring during your load test)
can easily invalidate the data of those infrequent runs.</li>
<li>Many tests end up with artificial constraints when run against non-production environments
like QA, for example running against underpowered or mis-configured databases.</li>
<li>They use &ldquo;Principal Component Analysis&rdquo; to find the minimal principal components
which are <em>not</em> correlated with each other, so you have less redundant data to explore.</li>
<li>After they&rsquo;ve found the key Principal Components, they then convert those back into the underlying
counters, which are human comprehensible, for further analysis.</li>
<li>Ideally, you should be able to use historical data to build load signatures, such that you
could quickly determine if the system&rsquo;s fundamental constraint has shifted (e.g. you&rsquo;ve
finally fixed your core bottleneck and got a new one, or something else has degraded such
that it is not your core bottleneck).</li>
</ol>

<p>In particular, my take away is that probably the right load generation tool
will start with a fairly simple approach with manually identified key metrics, and then
move increasingly to using machine learning to avoid our implicit biases around where our
systems <em>ought</em> to be slow.</p>

<h3><a href="http://du.diva-portal.org/smash/get/diva2:518118/FULLTEXT01">A Unified Load Generator For Geographically&hellip;</a></h3>

<p><a href="http://du.diva-portal.org/smash/get/diva2:518118/FULLTEXT01">A Unified Load Generator for Geographically Distributed Generation of Network Traffic</a> (2006)
is a master&rsquo;s thesis, that happens to be an pretty excellent survey of
academic ideas and topics around load generation.</p>

<p>One of the interesting ideas here is:</p>

<blockquote>
<p>to design an accurate artificial load generator which is responsible to act in a flexible
manner under different situations we need not only a load model but also a formal method to specify
the realistic load.</p>
</blockquote>

<p>I&rsquo;m not sure I entirely agree that we need a formal model to get value from our load testing,
we are after all trying to convert unplanned scalability work into planned scalability work,
but I have such an industry focus that it&rsquo;s a fascinating idea to me that you would even try to
create a formal model here.</p>

<p>It also introduces a more specific vocabulary for discussing load generation:</p>

<blockquote>
<p>The workload or load L=L (E, S, IF, T) denotes the total sequence of requests which
is offered by an environment E to a service system S via a well-defined interface IF during the timeinterval
T.</p>
</blockquote>

<p>Perhaps more interestingly, is the emphasize on how <a href="http://lethain.com/qos-cost-quotas/">quality of service</a>
forces us to redefine the goal of load testing:</p>

<blockquote>
<p>The need for telecommunication networks capable of providing communication services such as
data, voice and video motivated to deliver an acceptable QoS level to the users, and their success
depends on the development of effective congestion control schemes.</p>
</blockquote>

<p>I find this a fascinating point. As your systems start to include more systematic load shedding mechanisms,
it becomes increasingly challenging to push them out of equilibrium because they (typically) preserve
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.3690&amp;rep=rep1&amp;type=pdf">harvest by degrading yield</a>.
It&rsquo;s consequently not enough to say that your systems should or should not fail at a given level of load,
you also have to start to measure if it degrades appropriately based on load levels.</p>

<p>In section 3.5, it explains (the seemingly well known, albeit not to me) UniLog, also known as the Unified Load Generator.
(Which is perhaps based on <a href="https://www.researchgate.net/publication/220769797_A_unified_load_generator_based_on_formal_load_specification_and_load_transformation">this paper</a>,
which is sadly hidden behind a paywall.) UniLog has an interesting architecture with intimidatingly
exciting component names like PLM, ELM, GAR, LT, ADAPT and EEM. As best I can tell it is an extremely
generic architecture for running and evaluating load experiments. It feels slightly overdesigned
from my first reading, but perhaps as one spends more time in the caverns of load generation it
starts to make more sense.</p>

<p>In section 4.4, it discusses centralized versus distributed load generation, which feels like
one of the core design decisions you need to make for building such a system. My sense is that
you likely want a distributed approach at some point, if only to avoid getting completely throttled
by QoS operating on a per-IP ratelimit.</p>

<p>The rest of the paper focuses on some case studies and such. Overall, it was a surprisingly thorough
introduction to the related research.</p>

<h3><a href="http://barbie.uta.edu/~jxu/Automated%20analysis%20of%20load%20testing%20results.pdf">Automated Analysis of Load Testing Results</a></h3>

<p><a href="http://barbie.uta.edu/~jxu/Automated%20analysis%20of%20load%20testing%20results.pdf">Automated Analysis of Load Testing Results</a> takes a look at using automation to understand
load test results (using both the execution logs of the load test and overall system metrics during
the load test).</p>

<p>It summarizes the challenges of analyzing load test results as: outdated documentation,
process-level profiling is cost prohibitive, load testing typically occurs late in the development
cycle with short time lines, and the output from load tests can be overwhelmingly large.</p>

<p>I think the most interesting take away for me is the idea of very explicitly decoupling the gathering
of performance data from its analysis. For example, you could start logging performance data early on
(and likely your metrics tool, e.g. Graphite, already is capturing that data), and invest into more
sophisticated analysis much later on. There is particular focus on comparing results across multiple
load test runs, which can at a minimum narrow in on where performance &ldquo;lives&rdquo; within your metrics.</p>

<h3>Even more papers&hellip;</h3>

<p>Some additional papers with short summaries:</p>

<p><a href="http://barbie.uta.edu/~jxu/Converting%20users%20to%20testers%20an%20alternative%20approach%20to%20load%20test%20script%20creation,%20parameterization%20and%20data%20corellation.pdf">Converting Users to Testers</a> - This paper discusses recording user traffic as an input to your load testing, with the goal of reducing time spent writing load generation scripts.</p>

<p><a href="http://barbie.uta.edu/~jxu/automatic%20feedback,%20contro-based%20stress%20and%20load%20testing.pdf">Automatic Feedback, Control-Based, Stress and Load Testing</a> - This paper
explores the idea of systems that try to drive and maintain load on a system to targeted threshold. This is an interesting idea
because this would allow you to consistently run load against your production environment. The only caveat is that you have
to first identify the inputs you want to use to influence that load, so you still need to model the incoming traffic in
order to use it as an input (or record and sanitize real traffic), but at least once you have modeled it you could be more
abstract in how you use that model (if your target is to create load, you don&rsquo;t necessarily need to simulate realistic
traffic, and you could use something like an n-armed bandit approach to &ldquo;optimize&rdquo; your load to generate the correct amount
of load against the system). (Similarly, <a href="http://barbie.uta.edu/~jxu/stress%20testing%20real-time%20systems%20with%20genetic%20algorithms.pdf">this paper tries to do that using genetic algorithms</a>.)</p>

<h3>Existing Tools</h3>

<p>There are surprisingly few load testing tools, although <a href="https://en.wikipedia.org/wiki/Load_testing#Software_load_testing">wikipedia has a short list</a>.
Of that list, I&rsquo;ve actually used <a href="http://jmeter.apache.org/">JMeter</a> some years ago, and I enjoyed
<a href="http://www.fredberinger.com/2010/05/why-is-hp-killing-loadrunner/">this short rant about HP&rsquo;s Loadrunner tooling</a>.</p>

<p>I took a brief look at <a href="http://gatling.io/">Gatling</a>, which is a lightweight DSL written in Scala,
which can be easily run by Jenkins or such. This seems like an interesting potential starting point
for building a load generation tool. In particular the concept of treating your load tests as something
you would check into your repository feels right, allowing you to iterate on your load tests like you
would anything else.
Reading through <a href="https://www.thoughtworks.com/insights/blog/gatling-take-your-performance-tests-next-level">a few</a>
other
<a href="http://callistaenterprise.se/blogg/teknik/2014/04/16/a-first-look-at-gatling-a-dsl-based-load-test-tool/">blog posts</a>
on Gatling gave me a stronger sense that this might be a useful component of an overall load testing system
(that allowed, e.g. many instances to be run against different endpoints or such).</p>

<p>Are there others that I&rsquo;m missing out on?</p>

<h3><a href="http://drops.dagstuhl.de/opus/volltexte/2011/2957/pdf/5.pdf">Web Workload Generation According to&hellip;</a></h3>

<p>As the name suggests, <a href="http://drops.dagstuhl.de/opus/volltexte/2011/2957/pdf/5.pdf">Web Workload Generation According to UniLoG Approach</a>
looks at adapting the UniLoG approach to the web. It nicely summarizes UniLoG&rsquo;s approach as well:</p>

<blockquote>
<p>The basic principle underlying the design and elaboration of
UniLoG has been to start with a formal description of an abstract load model and thereafter
to use an interface-dependent adapter to map the abstract requests to the concrete requests
as they are “understood” by the service providing component at the real interface in question.</p>
</blockquote>

<p>It also does a nice job of exploring ways to generate requests, although again coming back to
either using logs of existing traffic or generating a model which defines your workload. There
is an interesting hybrid here which would be using the distribution of actual usage as an input
for the generated load (as opposed to using load on a one to one basis).</p>

<p>That said, unfortunately, I didn&rsquo;t really get much out of it.</p>
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/djangotricks/~3/XK9299eepSk/django-administration-inlines-for-inlines.html" title="Django Administration: Inlines for Inlines">
            <h2>Django Administration: Inlines for Inlines</h2>
        </a>

        <p class="discreet">
            
                  By DjangoTricks from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 16, 2016</span>.
            
        </p>

        <img border="0" src="https://1.bp.blogspot.com/-76HnA7StJQA/WFN_Rn-JDSI/AAAAAAAABxQ/WNkXJyBjuxEv4jT3_p91b4vSP2w7x-HagCLcB/s1600/Django%2BAdministration-%2BInlines%2Bfor%2BInlines.png" /> <p>The default Django model administration comes with a <a href="https://docs.djangoproject.com/en/1.10/ref/contrib/admin/#inlinemodeladmin-objects">concept of inlines</a>. If you have a one-to-many relationship, you can edit the parent and its children in the same form. However, you are limited in a way that you cannot have inlines under inlines at nested one-to-many relations. For example, you can't show models <code>Painter</code>, <code>Picture</code>, and <code>Review</code> in the same form if one <strong>painter</strong> may have drawn multiple <strong>pictures</strong> and each <strong>picture</strong> may have several <strong>reviews</strong>.</p> <p>In this article I would like to share a workaround allowing you to quickly access the inlines of an inline model. The idea is that for every inline you can provide a HTML link leading to the separate form where you can edit the related model and its own relations. It's as simple as that.</p> <p>For example, in the form of <code>Painter</code> model, you have the instances of <code>Picture</code> listed with specific links "Edit this Picture separately":</p> <img border="0" src="https://4.bp.blogspot.com/-_dnJS_4sgVA/WFF_qUh6oeI/AAAAAAAABw8/1OvFUeVcDAM4Fdc0vu2WfLNrwnyb1XnagCLcB/s1600/painter-fullpage.png" /> <p>When such a link is clicked, the administrator goes to the form of the <code>Picture</code> model which shows the instances of <code>Review</code> model listed underneath:</p> <img border="0" src="https://1.bp.blogspot.com/-LKT31vHsjQU/WFCbSBaeb-I/AAAAAAAABv0/Bokt-STUvm0vIVRNPw-z3HNPcnYwTSYBACLcB/s1600/picture-fullpage.png" /> <p>Let's have a look, how to implement this.</p> <p>First of all, I will create a <code>gallery</code> app and define the three models there. Nothing fancy here. The important part there is just that the <code>Picture</code> model has a foreign key to the <code>Painter</code> model and the <code>Review</code> model has a foreign key to the <code>Picture</code> model.</p>  <pre><code><strong># <a href="https://gist.github.com/archatas/3dd5d271e72f1731d10981344af42813#file-models-py">gallery/models.py</a></strong><br /># -*- coding: UTF-8 -*-<br />from __future__ import unicode_literals<br /><br />import os<br /><br />from django.db import models<br />from django.utils.encoding import python_2_unicode_compatible<br />from django.utils.translation import ugettext_lazy as _<br />from django.utils.text import slugify<br /><br /><br />@python_2_unicode_compatible<br />class <strong>Painter</strong>(models.Model):<br />    name = models.CharField(_("Name"), max_length=255)<br /><br />    class Meta:<br />        verbose_name = _("Painter")<br />        verbose_name_plural = _("Painters")<br /><br />    def __str__(self):<br />        return self.name<br /><br /><br />def upload_to(instance, filename):<br />    filename_base, filename_ext = os.path.splitext(filename)<br />    return "painters/{painter}/{filename}{extension}".format(<br />        painter=slugify(instance.painter.name),<br />        filename=slugify(filename_base),<br />        extension=filename_ext.lower(),<br />    )<br /><br />@python_2_unicode_compatible<br />class <strong>Picture</strong>(models.Model):<br />    painter = models.ForeignKey(Painter, verbose_name=_("Painter"), on_delete=models.CASCADE)<br />    title = models.CharField(_("Title"), max_length=255)<br />    picture = models.ImageField(_("Picture"), upload_to=upload_to)<br /><br />    class Meta:<br />        verbose_name = _("Picture")<br />        verbose_name_plural = _("Pictures")<br /><br />    def __str__(self):<br />        return self.title<br /><br /><br />@python_2_unicode_compatible<br />class <strong>Review</strong>(models.Model):<br />    picture = models.ForeignKey(Picture, verbose_name=_("Picture"), on_delete=models.CASCADE)<br />    reviewer = models.CharField(_("Reviewer name"), max_length=255)<br />    comment = models.TextField(_("Comment"))<br /><br />    class Meta:<br />        verbose_name = _("Review")<br />        verbose_name_plural = _("Reviews")<br /><br />    def __str__(self):<br />        return self.reviewer<br /></code></pre> <p>Then I will create the administration definition for the models of the <code>gallery</code> app. Here I will set two types of administration for the <code>Picture</code> model:</p><ul><li>By extending <code>admin.StackedInline</code> I will create administration stacked as inline.</li><li>By extending <code>admin.ModelAdmin</code> I will create administration in a separate form.</li></ul> <p>In Django model administration besides usual form fields, you can also include some computed values. This can be done by your <code>fields</code> (or <code>fieldsets</code>) and <code>readonly_fields</code> attributes referring to a callable or a method name.</p> <p>You can set a translatable label for those computed values by defining <code>short_description</code> attribute for the callable or method. If you want to render some HTML, you can also set the <code>allow_tags</code> attribute to <code>True</code> (otherwise your HTML string will be escaped).</p> <pre><code><strong># <a href="https://gist.github.com/archatas/3dd5d271e72f1731d10981344af42813#file-admin-py">gallery/admin.py</a></strong><br /># -*- coding: UTF-8 -*-<br />from django.contrib import admin<br />from django.core.urlresolvers import reverse<br />from django.utils.translation import ugettext_lazy as _<br />from django.utils.text import force_text<br /><br />from .models import Painter, Picture, Review<br /><br />def get_picture_preview(obj):<br />    if obj.pk:  # if object has already been saved and has a primary key, show picture preview<br />        return """&lt;a href="{src}" target="_blank">&lt;img src="{src}" alt="{title}" style="max-width: 200px; max-height: 200px;" />&lt;/a>""".format(<br />            src=obj.picture.url,<br />            title=obj.title,<br />        )<br />    return _("(choose a picture and save and continue editing to see the preview)")<br />get_picture_preview.allow_tags = True<br />get_picture_preview.short_description = _("Picture Preview")<br /><br /><br />class PictureInline(admin.StackedInline):<br />    model = Picture<br />    extra = 0<br />    fields = ["get_edit_link", "title", "picture", get_picture_preview]<br />    readonly_fields = ["get_edit_link", get_picture_preview]<br /><br />    def get_edit_link(self, obj=None):<br />        if obj.pk:  # if object has already been saved and has a primary key, show link to it<br />            url = reverse('admin:%s_%s_change' % (obj._meta.app_label, obj._meta.model_name), args=[force_text(obj.pk)])<br />            return """&lt;a href="{url}">{text}&lt;/a>""".format(<br />                url=url,<br />                text=_("Edit this %s separately") % obj._meta.verbose_name,<br />            )<br />        return _("(save and continue editing to create a link)")<br />    get_edit_link.short_description = _("Edit link")<br />    get_edit_link.allow_tags = True<br /><br /><br />@admin.register(Painter)<br />class PainterAdmin(admin.ModelAdmin):<br />    save_on_top = True<br />    fields = ["name"]<br />    inlines = [PictureInline]<br /><br /><br />class ReviewInline(admin.StackedInline):<br />    model = Review<br />    extra = 0<br />    fields = ["reviewer", "comment"]<br /><br /><br />@admin.register(Picture)<br />class PictureAdmin(admin.ModelAdmin):<br />    save_on_top = True<br />    fields = ["painter", "title", "picture", get_picture_preview]<br />    readonly_fields = [get_picture_preview]<br />    inlines = [ReviewInline]<br /></code></pre> <p>In this administration setup, the <code>get_edit_link()</code> method creates a HTML link between the inline and the separate administration form for the <code>Picture</code> model.  As you can see, I also added the <code>get_picture_preview()</code> function as a bonus. It is included in both administration definitions for the <code>Picture</code> model and its purpose is to show a preview of the uploaded picture after saving it.</p> <p>To recap, nested inlines are not supported by Django out of the box. However, you can have your inlines edited in a separate page with the forms linked to each other. For the linking you would use some magic of the <code>readonly_fields</code> attribute.</p> <p>What if you really need to have inlines under inlines in your project? In that case you might check <a href="https://github.com/theatlantic/django-nested-admin">django-nested-admin</a> and don't hesitate to share your experience with it in the comments.</p><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/djangotricks?a=XK9299eepSk:xRLuuOHzpb8:4cEx4HpKnUU"><img border="0" src="http://feeds.feedburner.com/~ff/djangotricks?i=XK9299eepSk:xRLuuOHzpb8:4cEx4HpKnUU" /></a> <a href="http://feeds.feedburner.com/~ff/djangotricks?a=XK9299eepSk:xRLuuOHzpb8:F7zBnMyn0Lo"><img border="0" src="http://feeds.feedburner.com/~ff/djangotricks?i=XK9299eepSk:xRLuuOHzpb8:F7zBnMyn0Lo" /></a>
</div><img alt="" height="1" src="http://feeds.feedburner.com/~r/djangotricks/~4/XK9299eepSk" width="1" />
    </div>
    <div class="feedEntry">

        <a href="https://www.caktusgroup.com/blog/2016/12/14/django-boring-or-why-tech-startups-should-use-django/" title="Django is Boring, or Why Tech Startups (Should) Use Django">
            <h2>Django is Boring, or Why Tech Startups (Should) Use Django</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 14, 2016</span>.
            
        </p>

        <p>I recently attended <a href="https://www.djangounderthehood.com/">Django Under The Hood</a> in Amsterdam, an annual gathering of Django core team members and developers from around the world. A common theme discussed at the conference this year is that “Django is boring.” While it’s not the first time this has been discussed, it still struck me as odd. Upon further reflection, however, I see Django’s “boringness” as a huge asset to the community and potential adopters of the framework.</p>
<p>Caktus first began using Django in late 2007. This was well before the release of Django 1.0, in the days when startups and established companies alike ran production web applications using Subversion “trunk” (akin to the Git “master” branch) rather than using a released version of the software. Using Django was definitely not boring, because it required reading each commit merged to see if it added a new feature you could use and to make sure it wasn’t going to break your project . Although Django kept us on our toes in the early days, it was clear that Django was growing into a robust and stable framework with hope for the future.</p>
<p>With the help of thousands of volunteers from around the world, Django’s progressed a lot since the early days of “tracking trunk.” What does it mean that the people developing Django itself consider it “boring,” and how does that change our outlook for the future of the framework? If you’re a tech startup looking for a web framework, why would you choose the “boring” option? Following are several reasons that Caktus still uses Django for all new custom web/SMS projects, reasons I think apply equally well in the startup environment.</p>
<h2>1. Django has long taken pride in its “batteries included” philosophy.</h2>
<p>Django strives to be a framework that solves common problems in web development in the best way possible. In <a href="https://www.caktusgroup.com/blog/2009/01/13/why-caktus-uses-django/">my original post</a> on the topic nearly 8 years ago, some of the key features included with Django were the built-in admin interface and a strong focus on data integrity, two features missing from Ruby on Rails, the other major web framework at the time.</p>
<p>Significant features that have arrived in Django since that time include support for aggregates and query expressions in the ORM, a built-in application for geographic applications (django.contrib.gis), a user messages framework, CSRF protection, Python 3 support, a configurable User model, improved database transaction management, support for database migrations, support for full-text search in Postgres, and countless other features, bug fixes, and security updates. The entire time, Django’s emphasis on backwards compatibility and its generous deprecation policy have made it perfectly reasonable to plan to support and grow applications over 10 years or more.</p>
<h2>2. The community around Django continues to grow.</h2>
<p>In the tradition of open source software, users of the framework new and old support each other via the mailing list, IRC channel, blog posts, StackOverflow, and cost-effective conferences around the globe. The ecosystem of reusable apps continues to grow, with 3317 packages available on <a href="https://djangopackages.org/">https://djangopackages.org/</a> as of the time of this post.</p>
<p>A common historical pattern has been for apps or features to live external to Django until they’re “proven” in production by a large number of users, after which they might be merged into Django proper. Django also recently adopted the concept of “official” packages, where a third-party app might not make sense to merge into Django proper, but it’s sufficiently important to the wider Django community that the core team agrees to take ownership of its ongoing maintenance.</p>
<p>The batteries included in Django itself and the wealth of reusable apps not only help new projects get off the ground quickly, they also provide solutions that have undergone rigorous code review by experts in the relevant fields. This is particularly important in startup environments when the focus must be on building business-critical features quickly. The last thing a startup wants to do, for example, is focus on business-critical features at the expense of security or reliability; with Django, one doesn’t have to make this compromise.</p>
<h2>3. Django is written in Python.</h2>
<p>Python is one of the <a href="http://blog.codeeval.com/codeevalblog/2016/2/2/most-popular-coding-languages-of-2016">most popular</a>, <a href="http://cacm.acm.org/blogs/blog-cacm/176450-python-is-now-the-most-popular-introductory-teaching-language-at-top-u-s-universities/fulltext">most taught</a> programming languages in the world. Availability of skilled staff is a key concern for startups hoping to grow their team in the near future, so the prevalence of Python should reassure those teams looking to grow.</p>
<p>Similarly, Python as a programming language prides itself on readability; one should be able to understand the code one wrote 6-12 months ago. Although this is by no means new nor unique to Django, Python’s straightforward approach to development is another reason some developers might consider it “boring.” Both by necessity and convention, Python espouses the idea of clarity over cleverness in code, as articulated by Brian Kernighan in <em>The Elements of Programming Style</em>. Python’s philosophy about coding style is described in more detail in <a href="https://www.python.org/dev/peps/pep-0020/">PEP 20 -- The Zen of Python</a>. Leveraging this philosophy helps increase readability of the code and the bus factor of the project.</p>
<h2>4. The documentation included with Django is stellar.</h2>
<p>Not only does the <a href="https://docs.djangoproject.com/">documentation</a> detail the usage of each and every feature in Django, it also includes detailed release notes, including any backwards-incompatible changes, along with each release. Again, while Django’s rigorous documentation practices aren’t anything new, writing and reading documentation might be considered “boring” by some developers.</p>
<p>Django’s documentation is important for two key reasons. First, it helps both new and existing users of the framework quickly determine how to use a given feature. Second, it serves as a “contract” for backwards-compatibility in Django; that is, if a feature is documented in Django, the project pledges that it will be supported for at least two additional releases (unless it’s already been deprecated in the release notes). Django’s documentation is helpful both to one-off projects that need to be built quickly, and to projects that need to grow and improve through numerous Django releases.</p>
<h2>5. Last but not least, Django is immensely scalable.</h2>
<p>The framework is used at companies like EventBrite, Disqus, and Instagram to handle web traffic and mobile app API usage on behalf of 500M+ users. Even after being acquired by Facebook, Instagram <a href="https://youtu.be/lx5WQjXLlq8?list=PLQdy7QUATciZ4V3g3iCTnG5fvkZkuNGyg">swapped out their database server but did not abandon Django</a>. Although early startups don’t often have the luxury of worrying about this much traffic, it’s always good to know that one’s web framework can scale to handle dramatic and continuing spikes in demand.</p>
<p>At Caktus, we’ve engineered solutions for several projects using AWS Auto Scaling that create servers only when they’re needed, thereby maximizing scalability and minimizing hosting costs.</p>
<h2>Django into the future</h2>
<p>Caktus has long been a proponent of the Django framework, and I’m happy to say that remains true today. We established ourselves early on as one of the premiere web development companies specializing in Django, we’ve written previously about why we use Django in particular, and Caktus staff are regular contributors not only to Django itself but also to the wider community of open source apps and discussion surrounding the framework.</p>
<p>Django can be considered a best of breed collection of solutions to nearly all the problems common to web development and restful, mobile app API development that can be solved in generic ways. This is “boring” because most of the common problems have been solved already; there’s not a lot of low-hanging fruit for new developers to contribute. This is a good thing for startups, because it means there’s less need to build features manually that aren’t specific to the business.</p>
<p>The risk of adopting any “bleeding edge” technology is that the community behind it will lose interest and move on to something else, leaving the job of maintaining the framework up to the few companies without the budget to switch frameworks. There’s a secondary risk specific to more “fragmented” frameworks as well. Because of Django’s “batteries included” philosophy and focus on backwards compatibility, one can be assured that the features one selects today will continue to work well together in the future, which won’t always be the case with frameworks that rely on third-party packages to perform business-critical functions such as user management.</p>
<p>These risks couldn’t be any stronger in the world of web development, where the framework chosen must be considered a tried and true partner. A web framework is not a service, like a web server or a database, that can be swapped out for another similar solution with some effort. Switching web frameworks, especially if the programming language changes, may require rewriting the entire application from scratch, so it’s important to make the right choice up front. Django has matured substantially over the last 10 years, and I’m happy to celebrate that it’s now the “boring” option for web development. This means startups choosing Django today can focus more on what makes their projects special, and less on implementing common patterns in web development or struggling to perform a framework upgrade with significant, backwards-incompatible changes. It’s clear we made the right choice, and I can’t wait to see what startups adopt and grow on Django in the future.</p>
    </div>
    <div class="feedEntry">

        <a href="https://www.peterbe.com/plog/using-fanout.io-in-django" title="Using Fanout.io in Django">
            <h2>Using Fanout.io in Django</h2>
        </a>

        <p class="discreet">
            
                  By Peter Bengtsson from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 13, 2016</span>.
            
        </p>

        <p>Earlier this year we started using <a href="https://fanout.io/">Fanout.io</a> in <a href="https://air.mozilla.org/">Air Mozilla</a> to enhance the experience for users awaiting content updates. Here I hope to flesh out its details a bit to inspire others to deploy a similar solution.  </p>
<h2>What It Is</h2>
<p>First of all, Fanout.io is basically a service that handles your WebSockets. You put in some of Fanout's JavaScript into your site that handles a persistent WebSocket connection between your site and Fanout.io. And to push messages to your user you basically send them to Fanout.io from the server and they "forward" it to the WebSocket.  </p>
<p>The HTML page looks like this:  </p>
<div class="highlight">

<pre><span></span><span class="p">&lt;</span><span class="nt">html</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">body</span><span class="p">&gt;</span>

  <span class="p">&lt;</span><span class="nt">h1</span><span class="p">&gt;</span>Web Page<span class="p">&lt;/</span><span class="nt">h1</span><span class="p">&gt;</span>

<span class="c">&lt;!-- replace the FANOUT_REALM_ID with the ID you get in the Fanout.io admin page --&gt;</span>
<span class="p">&lt;</span><span class="nt">script</span> 
  <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://{{ FANOUT_REALM_ID }}.fanoutcdn.com/bayeux/static/faye-browser-1.1.2-fanout1-min.js&quot;</span>
<span class="p">&gt;&lt;/</span><span class="nt">script</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">script</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;fanout.js&quot;</span><span class="p">&gt;&lt;/</span><span class="nt">script</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">body</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">html</span><span class="p">&gt;</span>
</pre></div>

<p>And the <code>fanout.js</code> script looks like this:<br />
<div class="highlight"></p>
<pre><span></span><span class="nb">window</span><span class="p">.</span><span class="nx">onload</span> <span class="o">=</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// replace the FANOUT_REALM_ID with the ID you get in the Fanout.io admin page</span>
  <span class="kd">var</span> <span class="nx">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Faye</span><span class="p">.</span><span class="nx">Client</span><span class="p">(</span><span class="s1">'https://{{ FANOUT_REALM_ID }}.fanoutcdn.com/bayeux'</span><span class="p">)</span>
  <span class="nx">client</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="s1">'/mycomments'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>  
     <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">'Incoming updated data from the server:'</span><span class="p">,</span> <span class="nx">data</span><span class="p">);</span>
  <span class="p">})</span>
<span class="p">};</span>
</pre>

<p></div>  </p>
<p>And in server it looks something like this:  </p>
<div class="highlight">

<pre><span></span><span class="kn">from</span> <span class="nn">django.conf</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">import</span> <span class="nn">fanout</span>

<span class="n">fanout</span><span class="o">.</span><span class="n">realm</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">FANOUT_REALM_ID</span>
<span class="n">fanout</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">FANOUT_REALM_KEY</span>


<span class="k">def</span> <span class="nf">post_comment</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A django view function that saves the posted comment&quot;&quot;&quot;</span>
   <span class="n">text</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">POST</span><span class="p">[</span><span class="s1">'comment'</span><span class="p">]</span>
   <span class="n">saved_comment</span> <span class="o">=</span> <span class="n">Comment</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="p">)</span>
   <span class="n">fanout</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="s1">'mycomments'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'new_comment'</span><span class="p">:</span> <span class="n">saved_comment</span><span class="o">.</span><span class="n">id</span><span class="p">})</span>
   <span class="k">return</span> <span class="n">http</span><span class="o">.</span><span class="n">JsonResponse</span><span class="p">({</span><span class="s1">'comment_posted'</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>
</pre></div>

<p>Note that, in the client-side code, there's no security since there's no authentication. Any client can connect to any channel. So it's important that you don't send anything sensitive. In fact, you should think of this pattern simply as a <em>hint</em> that something has changed. For example, here's a slightly more fleshed out example of how you'd use the subscription.  </p>
<div class="highlight">

<pre><span></span><span class="nb">window</span><span class="p">.</span><span class="nx">onload</span> <span class="o">=</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// replace the FANOUT_REALM_ID with the ID you get in the Fanout.io admin page</span>
  <span class="kd">var</span> <span class="nx">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Faye</span><span class="p">.</span><span class="nx">Client</span><span class="p">(</span><span class="s1">'https://{{ FANOUT_REALM_ID }}.fanoutcdn.com/bayeux'</span><span class="p">)</span>
  <span class="nx">client</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="s1">'/mycomments'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>  
    <span class="k">if</span> <span class="p">(</span><span class="nx">data</span><span class="p">.</span><span class="nx">new_comment</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// server says a new comment has been posted in the server</span>
      <span class="nx">$</span><span class="p">.</span><span class="nx">json</span><span class="p">(</span><span class="s1">'/comments'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">response</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">$</span><span class="p">(</span><span class="s1">'#comments .comment'</span><span class="p">).</span><span class="nx">remove</span><span class="p">();</span>
        <span class="nx">$</span><span class="p">.</span><span class="nx">each</span><span class="p">(</span><span class="nx">response</span><span class="p">.</span><span class="nx">comments</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">comment</span><span class="p">)</span> <span class="p">{</span>        
          <span class="nx">$</span><span class="p">(</span><span class="s1">'&lt;div class=&quot;comment&quot;&gt;'</span><span class="p">)</span>
          <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="nx">$</span><span class="p">(</span><span class="s1">'&lt;p&gt;'</span><span class="p">).</span><span class="nx">text</span><span class="p">(</span><span class="nx">comment</span><span class="p">.</span><span class="nx">text</span><span class="p">))</span>
          <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="nx">$</span><span class="p">(</span><span class="s1">'&lt;span&gt;'</span><span class="p">).</span><span class="nx">text</span><span class="p">(</span><span class="s1">'By: '</span> <span class="o">+</span> <span class="nx">comment</span><span class="p">.</span><span class="nx">user</span><span class="p">.</span><span class="nx">name</span><span class="p">))</span>
          <span class="p">.</span><span class="nx">appendTo</span><span class="p">(</span><span class="s1">'#comments'</span><span class="p">);</span>
        <span class="p">});</span>
      <span class="p">});</span>
    <span class="p">}</span>
  <span class="p">})</span>
<span class="p">};</span>
</pre></div>

<p>Yes, I know jQuery isn't hip but it demonstrates the pattern well. Also, in the real world you might not want to ask the server for <em>all</em> comments (and re-render) but instead do an AJAX query to get all <em>new</em> comments since some parameter or something.  </p>
<h2>Why It's Awesome</h2>
<p>It's awesome because you can have a simple page that updates near instantly when the server's database is updated. The alternative would be to do a <code>setInterval</code> loop that frequently does an AJAX query to see if there's new content to update. This is cumbersome because it requires a lot heavier AJAX queries. You might want to make it secure so you engage sessions that need to be looked up each time. Or, since you're going to request it often you have to write a very optimized server-side endpoint that is cheap to query often.  </p>
<p>And last but not least, if you rely on an AJAX loop interval, you have to pick a frequency that your server can cope with and it's likely to be in the range of several seconds or else it might overload the server. That means that updates are quite delayed.  </p>
<p>But maybe most important, you don't need to worry about running a WebSocket server. It's not terribly hard to do one yourself on your laptop with a bit of Node Express or Tornado but now you have yet another server to maintain and it, internally, needs to be connected to a "pub-sub framework" like Redis or a full blown message queue.  </p>
<h2>Alternatives</h2>
<p>Fanout.io is not the only service that offers this. The decision to use Fanout.io was taken about a year ago and one of the attractive things it offers is that it's got a freemium option which is ideal for doing local testing. The honest truth is that I can't remember the other justifications used to chose Fanout.io over its competitors but here are some alternatives that popped up on a quick search:  </p>
<ul>
<li><a href="https://socketize.com/">Socketize</a> </li>
<li><a href="https://pusher.com/">Pusher</a></li>
<li><a href="http://pushpin.org/">pushping</a></li>
</ul>
<p>It seems they all (including Fanout.io) has freemium plans, supports authentication, REST APIs (for sending and for querying connected clients' stats).  </p>
<p>There are also some more advanced feature packed solutions like Meteor, Firebase and GunDB that act more like databases that are connected via WebSockets or alike. For example, you can have a database as a "conduit" for pushing data to a client. Meaning, instead of sending the data from the server directly you save it in a database which syncs to the connected clients.  </p>
<p>Lastly, I've heard that Heroku has a really neat solution that does something similar whereby it sets up something similar as an extension.  </p>
<h2>Let's Get Realistic</h2>
<p>The solution sketched out above is very simplistic. There are a lot more fine-grained details that you'd probably want to zoom in to if you're going to do this properly.  </p>
<h3>Throttling</h3>
<p>In Air Mozilla, we call <code>fanout.publish(channel, message)</code> from a <code>post_save</code> ORM signal. If you have a lot of saves for some reason, you might be sending too many messages to the client. A throttling solution, per channel, simply makes sure your "callback" gets called only once per channel per small time frame. Here's the solution we employed:  </p>
<div class="highlight">

<pre><span></span><span class="nb">window</span><span class="p">.</span><span class="nx">Fanout</span> <span class="o">=</span> <span class="p">(</span><span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">_locks</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="nx">subscribe</span><span class="o">:</span> <span class="kd">function</span> <span class="nx">subscribe</span><span class="p">(</span><span class="nx">channel</span><span class="p">,</span> <span class="nx">callback</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">_client</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="nx">channel</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">if</span> <span class="p">(</span><span class="nx">_locks</span><span class="p">[</span><span class="nx">channel</span><span class="p">])</span> <span class="p">{</span>
              <span class="c1">// throttled</span>
              <span class="k">return</span><span class="p">;</span>
          <span class="p">}</span>
          <span class="nx">_locks</span><span class="p">[</span><span class="nx">channel</span><span class="p">]</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
          <span class="nx">callback</span><span class="p">(</span><span class="nx">data</span><span class="p">);</span>
          <span class="nx">setTimeout</span><span class="p">(</span><span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
              <span class="nx">_locks</span><span class="p">[</span><span class="nx">channel</span><span class="p">]</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>
          <span class="p">},</span> <span class="mi">500</span><span class="p">);</span>
      <span class="p">});</span>        
    <span class="p">};</span>
  <span class="p">}</span>
<span class="p">})();</span>
</pre></div>

<h3>Subresource Integrity</h3>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity">Subresource integrity</a> is an important web security technique where you know in advance a hash of the remote JavaScript you include. That means that if someone hacks the result of loading <code>https://cdn.example.com/somelib.js</code> the browser compares the hash of that with a hash mentioned in the <code>&lt;script&gt;</code> tag and refuses to load it if the hash doesn't match. </p>
<p>In the example of Fanout.io it actually looks like this:  </p>
<div class="highlight">

<pre><span></span><span class="p">&lt;</span><span class="nt">script</span> 
  <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://{{ FANOUT_REALM_ID }}.fanoutcdn.com/bayeux/static/faye-browser-1.1.2-fanout1-min.js&quot;</span>
  <span class="na">crossOrigin</span><span class="o">=</span><span class="s">&quot;anonymous&quot;</span>
  <span class="na">integrity</span><span class="o">=</span><span class="s">&quot;sha384-/9uLm3UDnP3tBHstjgZiqLa7fopVRjYmFinSBjz+FPS/ibb2C4aowhIttvYIGGt9&quot;</span>
<span class="p">&gt;&lt;/</span><span class="nt">script</span><span class="p">&gt;</span>
</pre></div>

<p>The SHA you get from the Fanout.io documentation. It requires, and implies, that you need to use an exact version of the library. You can't use it like this: <code>&lt;script src="https://cdn.example/somelib.latest.min.js" ...</code>.  </p>
<h3>WebSockets vs. Long-polling</h3>
<p>Fanout.io's JavaScript client follows a pattern that makes it compatible with clients that don't support WebSockets. The first technique it uses is called <a href="https://www.pubnub.com/blog/2014-12-01-http-long-polling/">long-polling</a>. With this the server basically relys on standard HTTP techniques but the responses are long lasting instead. It means the request simply takes a very long time to respond and when it does, that's when data can be passed.  </p>
<p>This is not a problem for modern browsers. They almost <a href="http://caniuse.com/#search=websocket">all support WebSocket</a> but you might have an application that isn't a modern browser.  </p>
<p>Anyway, what Fanout.io does internally is that it <em>first</em> creates a long-polling connection but then shortly after tries to "upgrade" to WebSockets if it's supported. However, the projects I work only need to support modern browsers and there's a trick to tell Fanout to go straight to WebSockets:  </p>
<div class="highlight">

<pre><span></span><span class="kd">var</span> <span class="nx">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Faye</span><span class="p">.</span><span class="nx">Client</span><span class="p">(</span><span class="s1">'https://{{ FANOUT_REALM_ID }}.fanoutcdn.com/bayeux'</span><span class="p">,</span> <span class="p">{</span>
    <span class="c1">// What this means is that we're opting to have</span>
    <span class="c1">// Fanout *start* with fancy-pants WebSocket and</span>
    <span class="c1">// if that doesn't work it **falls back** on other</span>
    <span class="c1">// options, such as long-polling.</span>
    <span class="c1">// The default behaviour is that it starts with</span>
    <span class="c1">// long-polling and tries to &quot;upgrade&quot; itself</span>
    <span class="c1">// to WebSocket.</span>
    <span class="nx">transportMode</span><span class="o">:</span> <span class="s1">'fallback'</span>
<span class="p">});</span>
</pre></div>

<h3>Fallbacks</h3>
<p>In the case of Air Mozilla, it already had a traditional solution whereby it does a <code>setInterval</code> loop that does an AJAX query frequently.  </p>
<p>Because the networks can be flaky or because something might go wrong in the client, the way we use it is like this:  </p>
<div class="highlight">

<pre><span></span><span class="kd">var</span> <span class="nx">RELOAD_INTERVAL</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>  <span class="c1">// seconds</span>

<span class="k">if</span> <span class="p">(</span><span class="k">typeof</span> <span class="nb">window</span><span class="p">.</span><span class="nx">Fanout</span> <span class="o">!==</span> <span class="s1">'undefined'</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">Fanout</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="s1">'/'</span> <span class="o">+</span> <span class="nx">container</span><span class="p">.</span><span class="nx">data</span><span class="p">(</span><span class="s1">'subscription-channel-comments'</span><span class="p">),</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Supposedly the comments have changed.</span>
        <span class="c1">// For security, let's not trust the data but just take it</span>
        <span class="c1">// as a hint that it's worth doing an AJAX query</span>
        <span class="c1">// now.</span>
        <span class="nx">Comments</span><span class="p">.</span><span class="nx">load</span><span class="p">(</span><span class="nx">container</span><span class="p">,</span> <span class="nx">data</span><span class="p">);</span>
    <span class="p">});</span>
    <span class="c1">// If Fanout doesn't work for some reason even though it</span>
    <span class="c1">// was made available, still use the regular old</span>
    <span class="c1">// interval. Just not as frequently.</span>
    <span class="nx">RELOAD_INTERVAL</span> <span class="o">=</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">5</span><span class="p">;</span>
<span class="p">}</span>
<span class="nx">setInterval</span><span class="p">(</span><span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">Comments</span><span class="p">.</span><span class="nx">reload_loop</span><span class="p">(</span><span class="nx">container</span><span class="p">);</span>
<span class="p">},</span> <span class="nx">RELOAD_INTERVAL</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">);</span>
</pre></div>

<h3>Use Fanout Selectively/Progressively</h3>
<p>In the case of Air Mozilla, there are lots of pages. Some don't ever need a WebSocket connection. For example, it might be a simple CRUD (Create Update Delete) page. So, for that I made the whole Fanout functionality "lazy" and it only gets set up if the page has some JavaScript that knows it needs it.  </p>
<p>This also has the benefit that the Fanout resource loading etc. is slightly delayed until more pressing things have loaded and the DOM is ready.  </p>
<p>You can <a href="https://github.com/mozilla/airmozilla/blob/master/airmozilla/base/static/js/fanout.js">see the whole solution here</a>. And <a href="https://github.com/mozilla/airmozilla/blob/0c6337a44c5a2842c4cbd7a8000c08a5c6be5a0f/airmozilla/comments/static/comments/js/comments.js#L252-L258">the way you use it here</a>.  </p>
<h3>Have Many Channels</h3>
<p>You can have as many channels as you like. Don't create a channel called <code>comments</code> when you can have a channel called <code>comments-123</code> where <code>123</code> is the ID of the page you're on for example.  </p>
<p>In the case of Air Mozilla, there's a channel for every single page. If you're sitting on a page with a commenting widget, it doesn't get WebSocket messages about newly posted comments on other pages.  </p>
<h3>Conclusion</h3>
<p>We've now used Fanout for almost a year in our little Django + jQuery app and it's been great. The management pages in Air Mozilla use AngularJS and the integration looks like this in the event manager page:  </p>
<div class="highlight">

<pre><span></span><span class="nb">window</span><span class="p">.</span><span class="nx">Fanout</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="s1">'/events'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">$scope</span><span class="p">.</span><span class="nx">$apply</span><span class="p">(</span><span class="nx">lookForModifiedEvents</span><span class="p">);</span>
<span class="p">});</span>
</pre></div>

<p>Fanout.io's been great to us. Really responsive support and very reliable. But if I were to start a fresh new project that needs a solution like this I'd try to spend a little time to investigate the competitors to see if there are some neat features I'd enjoy.  </p>
<p><strong>UPDATE</strong></p>
<p>Fanout reached out to help explain more what's great about Fanout.io  </p>
<p><em>"One of Fanout's biggest differentiators is that we use and promote open technologies/standards. For example, our service supports the open Bayeux protocol, and you can connect to it with any compatible client library, such as Faye. Nearly all competing services have proprietary protocols. This "open" aspect of Fanout aligns pretty well with Mozilla's values, and in fact you'd have a hard time finding any alternative that works the same way."</em></p>
    </div>
    <div class="feedEntry">

        <a href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-two.html" title="Transcoding with AWS- part two">
            <h2>Transcoding with AWS- part two</h2>
        </a>

        <p class="discreet">
            
                  By Krzysztof Żuraw Personal Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 11, 2016</span>.
            
        </p>

        <p><strong>As I have static and media files integrated with AWS now it's time to transcode
them. In this post, I will write a short example of how to integrate AWS ElasticTranscoder
with Django application.</strong></p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#basic-terms" id="id1">Basic terms</a></li>
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#code" id="id2">Code</a></li>
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#other-blog-posts-in-this-series" id="id3">Other blog posts in this series</a></li>
</ul>
</div>
<div class="section" id="basic-terms">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id1">Basic terms</a></h2>
<p>ElasticTranscoder allows you to transcode files from your S3 bucket to various formats.
To set this service up first you have to create a pipeline. What pipeline is? Basically, it's
a workflow- how your transcoder should work. You can create a different pipeline for long
content and different for short one. In my application I created the following pipeline:</p>
<img alt="Pipeline configuration" src="https://www.djangoproject.com/images/aws_transcoder1.png" />
<p>As I have my pipeline configured next step is to create jobs. Jobs are tasks for a transcoder
that say which file I want to transcode, to what format or codec I want to do this:</p>
<img alt="Job details" src="https://www.djangoproject.com/images/aws_transcoder2.png" />
<p>PresetID is user created or already existing configuration that defines the format of transcoder
output: is it mp4 or maybe flac? What resolution should video files have? All of this
is set up in present.</p>
<p>As we know basic terms used in AWS Elastic Transcoder let's jump into the code.</p>
</div>
<div class="section" id="code">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id2">Code</a></h2>
<p>AWS has very good python API called <a class="reference external" href="http://boto3.readthedocs.io/en/latest/">boto3</a>. Using that
API and few examples from the internet I was able to create a simple class to create transcode job:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">django.conf</span> <span class="kn">import</span> <span class="n">settings</span>

<span class="kn">import</span> <span class="nn">boto3</span>


<span class="k">class</span> <span class="nc">AudioTranscoder</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="s1">'eu-west-1'</span><span class="p">,</span> <span class="n">pipeline_name</span><span class="o">=</span><span class="s1">'Audio Files'</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">region_name</span> <span class="o">=</span> <span class="n">region_name</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_name</span> <span class="o">=</span> <span class="n">pipeline_name</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">transcoder</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'elastictranscoder'</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">region_name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_pipeline</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">get_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="n">paginator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transcoder</span><span class="o">.</span><span class="n">get_paginator</span><span class="p">(</span><span class="s1">'list_pipelines'</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">paginator</span><span class="o">.</span><span class="n">paginate</span><span class="p">():</span>
          <span class="k">for</span> <span class="n">pipeline</span> <span class="ow">in</span> <span class="n">page</span><span class="p">[</span><span class="s1">'Pipelines'</span><span class="p">]:</span>
              <span class="k">if</span> <span class="n">pipeline</span><span class="p">[</span><span class="s1">'Name'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_name</span><span class="p">:</span>
                  <span class="k">return</span> <span class="n">pipeline</span><span class="p">[</span><span class="s1">'Id'</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">start_transcode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
      <span class="n">base_filename</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_aws_filename</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
      <span class="n">wav_aws_filename</span><span class="p">,</span> <span class="n">wav_filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_aws_filename</span><span class="p">(</span>
          <span class="n">filename</span><span class="p">,</span> <span class="n">extension</span><span class="o">=</span><span class="s1">'.wav'</span>
      <span class="p">)</span>
      <span class="n">flac_aws_filename</span><span class="p">,</span> <span class="n">flac_filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_aws_filename</span><span class="p">(</span>
          <span class="n">filename</span><span class="p">,</span> <span class="n">extension</span><span class="o">=</span><span class="s1">'.flac'</span>
      <span class="p">)</span>
      <span class="n">mp4_aws_filename</span><span class="p">,</span> <span class="n">mp4_filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_aws_filename</span><span class="p">(</span>
          <span class="n">filename</span><span class="p">,</span> <span class="n">extension</span><span class="o">=</span><span class="s1">'.mp4'</span>
      <span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">transcoder</span><span class="o">.</span><span class="n">create_job</span><span class="p">(</span>
          <span class="n">PipelineId</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_id</span><span class="p">,</span>
          <span class="n">Input</span><span class="o">=</span><span class="p">{</span>
              <span class="s1">'Key'</span><span class="p">:</span> <span class="n">base_filename</span><span class="p">,</span>
              <span class="s1">'FrameRate'</span><span class="p">:</span> <span class="s1">'auto'</span><span class="p">,</span>
              <span class="s1">'Resolution'</span><span class="p">:</span> <span class="s1">'auto'</span><span class="p">,</span>
              <span class="s1">'AspectRatio'</span><span class="p">:</span> <span class="s1">'auto'</span><span class="p">,</span>
              <span class="s1">'Interlaced'</span><span class="p">:</span> <span class="s1">'auto'</span><span class="p">,</span>
              <span class="s1">'Container'</span><span class="p">:</span> <span class="s1">'auto'</span>
          <span class="p">},</span>
          <span class="n">Outputs</span><span class="o">=</span><span class="p">[{</span>
              <span class="s1">'Key'</span><span class="p">:</span> <span class="n">wav_aws_filename</span><span class="p">,</span>
              <span class="s1">'PresetId'</span><span class="p">:</span> <span class="s1">'1351620000001-300300'</span>
              <span class="p">},</span> <span class="p">{</span>
              <span class="s1">'Key'</span><span class="p">:</span> <span class="n">flac_aws_filename</span><span class="p">,</span>
              <span class="s1">'PresetId'</span><span class="p">:</span> <span class="s1">'1351620000001-300110'</span>
              <span class="p">},</span> <span class="p">{</span>
              <span class="s1">'Key'</span><span class="p">:</span> <span class="n">mp4_aws_filename</span><span class="p">,</span>
              <span class="s1">'PresetId'</span><span class="p">:</span> <span class="s1">'1351620000001-100110'</span>
              <span class="p">}</span>
          <span class="p">]</span>
      <span class="p">)</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">wav_filename</span><span class="p">,</span> <span class="n">flac_filename</span><span class="p">,</span> <span class="n">mp4_filename</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">create_aws_filename</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">extension</span><span class="p">):</span>
      <span class="n">aws_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
          <span class="n">settings</span><span class="o">.</span><span class="n">MEDIAFILES_LOCATION</span><span class="p">,</span> <span class="n">filename</span> <span class="o">+</span> <span class="n">extension</span>
      <span class="p">)</span>
      <span class="k">return</span> <span class="n">aws_filename</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">aws_filename</span><span class="p">)</span>


<span class="n">transcoder</span> <span class="o">=</span> <span class="n">AudioTranscoder</span><span class="p">()</span>
</pre></div>
<p>Going from the top - I specified my <tt class="docutils literal">region_name</tt> as well as <tt class="docutils literal">pipeline_name</tt>
for boto3 to know to which region it should connect. In method <tt class="docutils literal">get_pipeline</tt> I
iterate through all available pipelines and return that has the same name as <tt class="docutils literal">pipeline_name</tt>.
In this function <tt class="docutils literal">paginator</tt> is an object which holds on portion of data so user
don't have to wait until all available pipelines are fetched.</p>
<p>The main logic is in <tt class="docutils literal">start_transcode</tt> method. At the beginning, I used helper function
<tt class="docutils literal">create_aws_filename</tt> that's creating proper AWS file name like <tt class="docutils literal">media/my_mp3.mp3</tt> and
returns that whole path with filename. After I created filenames for all of my files I'm
calling <tt class="docutils literal">create_job</tt> that creates a job basing on <tt class="docutils literal">pipeline_id</tt> and <tt class="docutils literal">base_filename</tt>. The job
can have multiple outputs so I specified one for wav, flac and mp4 files. How is it used in code?
Let's go to view:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UploadAudioFileView</span><span class="p">(</span><span class="n">FormView</span><span class="p">):</span>
  <span class="c1"># some code</span>

  <span class="k">def</span> <span class="nf">form_valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">form</span><span class="p">):</span>
      <span class="n">audio_file</span> <span class="o">=</span> <span class="n">AudioFile</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_form_kwargs</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'data'</span><span class="p">)[</span><span class="s1">'name'</span><span class="p">],</span>
            <span class="n">mp3_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_form_kwargs</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'files'</span><span class="p">)[</span><span class="s1">'mp3_file'</span><span class="p">]</span>
      <span class="p">)</span>
      <span class="n">audio_file</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
      <span class="n">wav_filename</span><span class="p">,</span> <span class="n">flac_filename</span><span class="p">,</span> <span class="n">mp4_filename</span> <span class="o">=</span> <span class="n">transcoder</span><span class="o">.</span><span class="n">start_transcode</span><span class="p">(</span>
          <span class="n">filename</span><span class="o">=</span><span class="n">audio_file</span><span class="o">.</span><span class="n">mp3_file</span><span class="o">.</span><span class="n">name</span>
      <span class="p">)</span>
      <span class="n">audio_file</span><span class="o">.</span><span class="n">mp4_file</span> <span class="o">=</span> <span class="n">mp4_filename</span>
      <span class="n">audio_file</span><span class="o">.</span><span class="n">flac_file</span> <span class="o">=</span> <span class="n">flac_filename</span>
      <span class="n">audio_file</span><span class="o">.</span><span class="n">wav_file</span> <span class="o">=</span> <span class="n">wav_filename</span>
      <span class="n">audio_file</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
      <span class="k">return</span> <span class="n">HttpResponseRedirect</span><span class="p">(</span>
          <span class="n">reverse</span><span class="p">(</span><span class="s1">'audio:detail'</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'pk'</span><span class="p">:</span> <span class="n">audio_file</span><span class="o">.</span><span class="n">pk</span><span class="p">})</span>
      <span class="p">)</span>
</pre></div>
<p>In <tt class="docutils literal">form_valid</tt> first I'm calling <tt class="docutils literal">save()</tt> on <tt class="docutils literal">AudioFile</tt> object which is uploading the file
to S3 bucket. Then I'm using <tt class="docutils literal">transcoder.start_transcode</tt> and basing on output from this function
I match filenames to their respective fields. I know that this solution is not the best one
as I have to call <tt class="docutils literal">save</tt> twice and if you have a better way to do this I'm glad to hear
it from you.</p>
<p>That's all for today! Transcoding works fine but there is a problem with what when files are big?
Transcoding such files will take lots of time and user don't want to wait for a response.
The solution will be revealed in next post.</p>
</div>
<div class="section" id="other-blog-posts-in-this-series">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id3">Other blog posts in this series</a></h2>
<ul class="simple">
<li><a class="reference external" href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-one.html">Transcoding with AWS- part one</a></li>
</ul>
<p>The code that I have made so far is available on
<a class="reference external" href="https://github.com/krzysztofzuraw/blog_transcoder_aws">github</a>. Stay
tuned for next blog post from this series.</p>
<p>Special thanks to Kasia for being an editor for this post. Thank you.</p>
<p>While creating this blog post I used an code from offcial
<a class="reference external" href="https://github.com/boto/boto3-sample/blob/master/transcoder.py">boto github account</a>.</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="https://simpleisbetterthancomplex.com/tutorial/2016/12/06/how-to-create-group-by-queries.html" title="How to Create Group By Queries With Django ORM">
            <h2>How to Create Group By Queries With Django ORM</h2>
        </a>

        <p class="discreet">
            
                  By Simple is Better Than Complex from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 06, 2016</span>.
            
        </p>

        <p>This tutorial is about how to implement SQL-like group by queries using the Django ORM. It’s a fairly common operation,
specially for those who are familiar with SQL. The Django ORM is actually an abstraction layer, that let us play with
the database as it was object-oriented but in the end it’s just a relational database and all the operations are
translated into SQL statements.</p>

<p>Most of the work can be done retrieving the raw data from the database, and playing with it in the Python side,
grouping the data in dictionaries, iterating through it, making sums, averages and what not. But the database is a very
powerful tool and do much more than simply storing the data, and often you can do the work much faster directly in the
database.</p>

<p>Generally speaking, when you start doing group by queries, you are no longer interested in each model instances (or
in a table row) details, but you want extract new information from your dataset, based on some common aspects shared
between the model instances.</p>

<p>Let’s have a look in an example:</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">class</span> <span class="nc">Country</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">CharField</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">City</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">CharField</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">country</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">Country</span><span class="p">)</span>
    <span class="n">population</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">PositiveIntegerField</span><span class="p">()</span></code></pre></figure>

<p>And the raw data stored in the database:</p>

<div style="height: 300px; border: 1px dashed #e1e1e1; padding: 1em;">
  <div class="row">
    <div class="seven columns" style="font-size: 14px; border-radius: 4px; background-color: #f1f1f1; border: 1px solid #e1e1e1;">
      <table class="u-full-width">
        <thead>
          <tr>
            <th colspan="4">
              <strong>cities</strong>
            </th>
          </tr>
          <tr>
            <th>id</th>
            <th>name</th>
            <th>country_id</th>
            <th>population</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>1</td><td>Tokyo</td><td>28</td><td>36,923,000</td></tr>
          <tr><td>2</td><td>Shanghai</td><td>13</td><td>34,000,000</td></tr>
          <tr><td>3</td><td>Jakarta</td><td>19</td><td>30,000,000</td></tr>
          <tr><td>4</td><td>Seoul</td><td>21</td><td>25,514,000</td></tr>
          <tr><td>5</td><td>Guangzhou</td><td>13</td><td>25,000,000</td></tr>
          <tr><td>6</td><td>Beijing</td><td>13</td><td>24,900,000</td></tr>
          <tr><td>7</td><td>Karachi</td><td>22</td><td>24,300,000</td></tr>
          <tr><td>8</td><td>Shenzhen</td><td>13</td><td>23,300,000</td></tr>
          <tr><td>9</td><td>Delhi</td><td>25</td><td>21,753,486</td></tr>
          <tr><td>10</td><td>Mexico City</td><td>24</td><td>21,339,781</td></tr>
          <tr><td>11</td><td>Lagos</td><td>9</td><td>21,000,000</td></tr>
          <tr><td>12</td><td>São Paulo</td><td>1</td><td>20,935,204</td></tr>
          <tr><td>13</td><td>Mumbai</td><td>25</td><td>20,748,395</td></tr>
          <tr><td>14</td><td>New York City</td><td>20</td><td>20,092,883</td></tr>
          <tr><td>15</td><td>Osaka</td><td>28</td><td>19,342,000</td></tr>
          <tr><td>16</td><td>Wuhan</td><td>13</td><td>19,000,000</td></tr>
          <tr><td>17</td><td>Chengdu</td><td>13</td><td>18,100,000</td></tr>
          <tr><td>18</td><td>Dhaka</td><td>4</td><td>17,151,925</td></tr>
          <tr><td>19</td><td>Chongqing</td><td>13</td><td>17,000,000</td></tr>
          <tr><td>20</td><td>Tianjin</td><td>13</td><td>15,400,000</td></tr>
          <tr><td>21</td><td>Kolkata</td><td>25</td><td>14,617,882</td></tr>
          <tr><td>22</td><td>Tehran</td><td>11</td><td>14,595,904</td></tr>
          <tr><td>23</td><td>Istanbul</td><td>2</td><td>14,377,018</td></tr>
          <tr><td>24</td><td>London</td><td>26</td><td>14,031,830</td></tr>
          <tr><td>25</td><td>Hangzhou</td><td>13</td><td>13,400,000</td></tr>
          <tr><td>26</td><td>Los Angeles</td><td>20</td><td>13,262,220</td></tr>
          <tr><td>27</td><td>Buenos Aires</td><td>8</td><td>13,074,000</td></tr>
          <tr><td>28</td><td>Xi'an</td><td>13</td><td>12,900,000</td></tr>
          <tr><td>29</td><td>Paris</td><td>6</td><td>12,405,426</td></tr>
          <tr><td>30</td><td>Changzhou</td><td>13</td><td>12,400,000</td></tr>
          <tr><td>31</td><td>Shantou</td><td>13</td><td>12,000,000</td></tr>
          <tr><td>32</td><td>Rio de Janeiro</td><td>1</td><td>11,973,505</td></tr>
          <tr><td>33</td><td>Manila</td><td>18</td><td>11,855,975</td></tr>
          <tr><td>34</td><td>Nanjing</td><td>13</td><td>11,700,000</td></tr>
          <tr><td>35</td><td>Rhine-Ruhr</td><td>16</td><td>11,470,000</td></tr>
          <tr><td>36</td><td>Jinan</td><td>13</td><td>11,000,000</td></tr>
          <tr><td>37</td><td>Bangalore</td><td>25</td><td>10,576,167</td></tr>
          <tr><td>38</td><td>Harbin</td><td>13</td><td>10,500,000</td></tr>
          <tr><td>39</td><td>Lima</td><td>7</td><td>9,886,647</td></tr>
          <tr><td>40</td><td>Zhengzhou</td><td>13</td><td>9,700,000</td></tr>
          <tr><td>41</td><td>Qingdao</td><td>13</td><td>9,600,000</td></tr>
          <tr><td>42</td><td>Chicago</td><td>20</td><td>9,554,598</td></tr>
          <tr><td>43</td><td>Nagoya</td><td>28</td><td>9,107,000</td></tr>
          <tr><td>44</td><td>Chennai</td><td>25</td><td>8,917,749</td></tr>
          <tr><td>45</td><td>Bangkok</td><td>15</td><td>8,305,218</td></tr>
          <tr><td>46</td><td>Bogotá</td><td>27</td><td>7,878,783</td></tr>
          <tr><td>47</td><td>Hyderabad</td><td>25</td><td>7,749,334</td></tr>
          <tr><td>48</td><td>Shenyang</td><td>13</td><td>7,700,000</td></tr>
          <tr><td>49</td><td>Wenzhou</td><td>13</td><td>7,600,000</td></tr>
          <tr><td>50</td><td>Nanchang</td><td>13</td><td>7,400,000</td></tr>
          <tr><td>51</td><td>Hong Kong</td><td>13</td><td>7,298,600</td></tr>
          <tr><td>52</td><td>Taipei</td><td>29</td><td>7,045,488</td></tr>
          <tr><td>53</td><td>Dallas–Fort Worth</td><td>20</td><td>6,954,330</td></tr>
          <tr><td>54</td><td>Santiago</td><td>14</td><td>6,683,852</td></tr>
          <tr><td>55</td><td>Luanda</td><td>23</td><td>6,542,944</td></tr>
          <tr><td>56</td><td>Houston</td><td>20</td><td>6,490,180</td></tr>
          <tr><td>57</td><td>Madrid</td><td>17</td><td>6,378,297</td></tr>
          <tr><td>58</td><td>Ahmedabad</td><td>25</td><td>6,352,254</td></tr>
          <tr><td>59</td><td>Toronto</td><td>5</td><td>6,055,724</td></tr>
          <tr><td>60</td><td>Philadelphia</td><td>20</td><td>6,051,170</td></tr>
          <tr><td>61</td><td>Washington, D.C.</td><td>20</td><td>6,033,737</td></tr>
          <tr><td>62</td><td>Miami</td><td>20</td><td>5,929,819</td></tr>
          <tr><td>63</td><td>Belo Horizonte</td><td>1</td><td>5,767,414</td></tr>
          <tr><td>64</td><td>Atlanta</td><td>20</td><td>5,614,323</td></tr>
          <tr><td>65</td><td>Singapore</td><td>12</td><td>5,535,000</td></tr>
          <tr><td>66</td><td>Barcelona</td><td>17</td><td>5,445,616</td></tr>
          <tr><td>67</td><td>Munich</td><td>16</td><td>5,203,738</td></tr>
          <tr><td>68</td><td>Stuttgart</td><td>16</td><td>5,200,000</td></tr>
          <tr><td>69</td><td>Ankara</td><td>2</td><td>5,150,072</td></tr>
          <tr><td>70</td><td>Hamburg</td><td>16</td><td>5,100,000</td></tr>
          <tr><td>71</td><td>Pune</td><td>25</td><td>5,049,968</td></tr>
          <tr><td>72</td><td>Berlin</td><td>16</td><td>5,005,216</td></tr>
          <tr><td>73</td><td>Guadalajara</td><td>24</td><td>4,796,050</td></tr>
          <tr><td>74</td><td>Boston</td><td>20</td><td>4,732,161</td></tr>
          <tr><td>75</td><td>Sydney</td><td>10</td><td>5,000,500</td></tr>
          <tr><td>76</td><td>San Francisco</td><td>20</td><td>4,594,060</td></tr>
          <tr><td>77</td><td>Surat</td><td>25</td><td>4,585,367</td></tr>
          <tr><td>78</td><td>Phoenix</td><td>20</td><td>4,489,109</td></tr>
          <tr><td>79</td><td>Monterrey</td><td>24</td><td>4,477,614</td></tr>
          <tr><td>80</td><td>Inland Empire</td><td>20</td><td>4,441,890</td></tr>
          <tr><td>81</td><td>Rome</td><td>3</td><td>4,321,244</td></tr>
          <tr><td>82</td><td>Detroit</td><td>20</td><td>4,296,611</td></tr>
          <tr><td>83</td><td>Milan</td><td>3</td><td>4,267,946</td></tr>
          <tr><td>84</td><td>Melbourne</td><td>10</td><td>4,650,000</td></tr>
        </tbody>
      </table>
    </div>
    <div class="five columns" style="font-size: 14px; border-radius: 4px; background-color: #f1f1f1; border: 1px solid #e1e1e1;">
      <table class="u-full-width">
        <thead>
          <tr>
            <th colspan="2">
              <strong>countries</strong>
            </th>
          </tr>
          <tr>
            <th>id</th>
            <th>name</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>1</td><td>Brazil</td></tr>
          <tr><td>2</td><td>Turkey</td></tr>
          <tr><td>3</td><td>Italy</td></tr>
          <tr><td>4</td><td>Bangladesh</td></tr>
          <tr><td>5</td><td>Canada</td></tr>
          <tr><td>6</td><td>France</td></tr>
          <tr><td>7</td><td>Peru</td></tr>
          <tr><td>8</td><td>Argentina</td></tr>
          <tr><td>9</td><td>Nigeria</td></tr>
          <tr><td>10</td><td>Australia</td></tr>
          <tr><td>11</td><td>Iran</td></tr>
          <tr><td>12</td><td>Singapore</td></tr>
          <tr><td>13</td><td>China</td></tr>
          <tr><td>14</td><td>Chile</td></tr>
          <tr><td>15</td><td>Thailand</td></tr>
          <tr><td>16</td><td>Germany</td></tr>
          <tr><td>17</td><td>Spain</td></tr>
          <tr><td>18</td><td>Philippines</td></tr>
          <tr><td>19</td><td>Indonesia</td></tr>
          <tr><td>20</td><td>United States</td></tr>
          <tr><td>21</td><td>South Korea</td></tr>
          <tr><td>22</td><td>Pakistan</td></tr>
          <tr><td>23</td><td>Angola</td></tr>
          <tr><td>24</td><td>Mexico</td></tr>
          <tr><td>25</td><td>India</td></tr>
          <tr><td>26</td><td>United Kingdom</td></tr>
          <tr><td>27</td><td>Colombia</td></tr>
          <tr><td>28</td><td>Japan</td></tr>
          <tr><td>29</td><td>Taiwan</td></tr>
        </tbody>
      </table>
    </div>
  </div>
</div>

<p>This data is from Wikipedia, and I don’t know to what extent it is correct, but for our example it doesn’t really
matter.</p>

<p>Considering the whole dataset, if we wanted to know the total of habitants in all the 84 cities, we could perhaps use
an <code class="highlighter-rouge">aggregate</code> query:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">django.db.models</span> <span class="kn">import</span> <span class="n">Sum</span>

<span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span>
<span class="p">{</span><span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">970880224</span><span class="p">}</span>  <span class="c"># 970,880,224</span></code></pre></figure>

<p>Or the average population in the top 84 cities:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">django.db.models</span> <span class="kn">import</span> <span class="n">Avg</span>

<span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">Avg</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span>
<span class="p">{</span><span class="s">'population__avg'</span><span class="p">:</span> <span class="mf">11558097.904761905</span><span class="p">}</span>  <span class="c"># 11,558,097.90</span></code></pre></figure>

<p>What if we now wanted to see the total population, but aggregated by the country instead? Not the whole dataset. In
this case we no longer can use <code class="highlighter-rouge">aggregate</code>, instead we will be using <code class="highlighter-rouge">annotate</code>.</p>

<p>The <code class="highlighter-rouge">aggregate</code> clause is terminal, it returns a Python dictionary, meaning you can’t append any queryset methods.
Also, it will always return a single result. So if you wanted to get the population sum by country, using <code class="highlighter-rouge">aggregate</code>,
you would need to do something like this:</p>

<div class="panel panel-danger">
  <div class="panel-header">Don't</div>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">django.db.models</span> <span class="kn">import</span> <span class="n">Sum</span>

<span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">Country</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">country</span><span class="o">=</span><span class="n">country</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span>
    <span class="k">print</span> <span class="s">'{}: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">country</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s">'population__sum'</span><span class="p">])</span>

<span class="c"># Output:</span>
<span class="c"># -------</span>
<span class="c"># Brazil: 38676123</span>
<span class="c"># Turkey: 19527090</span>
<span class="c"># Italy: 8589190</span>
<span class="c"># Bangladesh: 17151925</span>
<span class="c"># Canada: 6055724</span>
<span class="c"># France: 12405426</span>
<span class="c"># Peru: 9886647</span>
<span class="c"># Argentina: 13074000</span>
<span class="c"># Nigeria: 21000000</span>
<span class="c"># Australia: 9650500</span>
<span class="c"># Iran: 14595904</span>
<span class="c"># ...</span></code></pre></figure>

</div>

<p>While the result is correct, we needed to execute <strong>30</strong> different queries in the database. And we’ve lost some of the
capabilities of the ORM, such as ordering this result set. Perhaps the data would be more interesting if we could order
by the country with the most population for example.</p>

<p>Now a better way to do it is using <code class="highlighter-rouge">annotate</code>, which will be translated as a <strong>group by</strong> query in the database:</p>

<div class="panel panel-success">
  <div class="panel-header">Do</div>

<figure class="highlight"><pre><code class="language-python"><span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'country__name'</span><span class="p">)</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span>

<span class="p">[</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Angola'</span><span class="p">,</span> <span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">6542944</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Argentina'</span><span class="p">,</span> <span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">13074000</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Australia'</span><span class="p">,</span> <span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">9650500</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Bangladesh'</span><span class="p">,</span> <span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">17151925</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Brazil'</span><span class="p">,</span> <span class="s">'population__sum'</span><span class="p">:</span> <span class="mi">38676123</span><span class="p">},</span>
  <span class="s">'...(remaining elements truncated)...'</span>
<span class="p">]</span></code></pre></figure>

</div>

<p>Much better, right?</p>

<p>Now if we wanted to order by the country population, we can use an alias to make it look cleaner and to use in the
<code class="highlighter-rouge">order_by()</code> clause:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span> \
  <span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'country__name'</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">country_population</span><span class="o">=</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span> \
  <span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="s">'-country_population'</span><span class="p">)</span>

<span class="p">[</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'China'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">309898600</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'United States'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">102537091</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'India'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">100350602</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Japan'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">65372000</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Brazil'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">38676123</span><span class="p">},</span>
  <span class="s">'...(remaining elements truncated)...'</span>
<span class="p">]</span></code></pre></figure>

<p>Here is how the last SQL query looks like:</p>

<figure class="highlight"><pre><code class="language-sql">  <span class="k">SELECT</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"population"</span><span class="p">)</span> <span class="k">AS</span> <span class="nv">"country_population"</span>
    <span class="k">FROM</span> <span class="nv">"core_city"</span> <span class="k">INNER</span> <span class="k">JOIN</span> <span class="nv">"core_country"</span> <span class="k">ON</span> <span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"country_id"</span> <span class="o">=</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"id"</span><span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="nv">"country_population"</span> <span class="k">DESC</span></code></pre></figure>

<p>Now an important thing to note here: it only makes sense adding in the <code class="highlighter-rouge">values()</code> clause, the data that can be grouped.
Every field you add to the <code class="highlighter-rouge">values()</code> clause, will be used to create the group by query.</p>

<p>Look at this queryset:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'name'</span><span class="p">,</span> <span class="s">'country__name'</span><span class="p">)</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span></code></pre></figure>

<p>The resulting SQL query would be:</p>

<figure class="highlight"><pre><code class="language-sql">  <span class="k">SELECT</span> <span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"name"</span><span class="p">,</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"population"</span><span class="p">)</span> <span class="k">AS</span> <span class="nv">"population__sum"</span>
    <span class="k">FROM</span> <span class="nv">"core_city"</span> <span class="k">INNER</span> <span class="k">JOIN</span> <span class="nv">"core_country"</span> <span class="k">ON</span> <span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"country_id"</span> <span class="o">=</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"id"</span><span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"name"</span><span class="p">,</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span></code></pre></figure>

<p>This would have no effect, because all the city names are unique, and they can’t be grouped (the database will try to
group it, but each “group” will have only 1 row/instance). We can see it simply by performing a count on each queryset:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'name'</span><span class="p">,</span> <span class="s">'country__name'</span><span class="p">)</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">84</span>

<span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'country__name'</span><span class="p">)</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">29</span></code></pre></figure>

<p>That’s what I meant when I said in the beginning of the post that, you are no longer interested in the details of each
row. When we group by country to get the sum of the population, we lost the details of the cities (at least in the
query result).</p>

<p>Sometimes it makes sense to have more than one value in the <code class="highlighter-rouge">values()</code> clause. For example if our database was composed
by City / State / Country. Then we could group by using <code class="highlighter-rouge">.values('state__name', 'country__name')</code>. This way you would
have the population by country. And you would avoid States from different countries (with the same name) to be grouped
together.</p>

<p>The values you generate on the database, using the <code class="highlighter-rouge">annotate</code> clause, can also be used to filter data. Usually in the
database we use the <code class="highlighter-rouge">HAVING</code> function, which makes it very idiomatic. You can read the query like it was plain English.
Now, in the Django side, it’s a simple <code class="highlighter-rouge">filter</code>.</p>

<p>For example, let’s say we want to see the total population by country, but only those countries where the total
population is greater than 50,000,000:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">City</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span> \
  <span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="s">'country__name'</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">country_population</span><span class="o">=</span><span class="n">Sum</span><span class="p">(</span><span class="s">'population'</span><span class="p">))</span> \
  <span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">country_population__gt</span><span class="o">=</span><span class="mi">50000000</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="s">'-country_population'</span><span class="p">)</span>

<span class="p">[</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'China'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">309898600</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'United States'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">102537091</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'India'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">100350602</span><span class="p">},</span>
  <span class="p">{</span><span class="s">'country__name'</span><span class="p">:</span> <span class="s">u'Japan'</span><span class="p">,</span> <span class="s">'country_population'</span><span class="p">:</span> <span class="mi">65372000</span><span class="p">}</span>
<span class="p">]</span></code></pre></figure>

<p>And finally the SQL query:</p>

<figure class="highlight"><pre><code class="language-sql">  <span class="k">SELECT</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"population"</span><span class="p">)</span> <span class="k">AS</span> <span class="nv">"country_population"</span>
    <span class="k">FROM</span> <span class="nv">"core_city"</span> <span class="k">INNER</span> <span class="k">JOIN</span> <span class="nv">"core_country"</span> <span class="k">ON</span> <span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"country_id"</span> <span class="o">=</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"id"</span><span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"core_country"</span><span class="p">.</span><span class="nv">"name"</span> <span class="k">HAVING</span> <span class="k">SUM</span><span class="p">(</span><span class="nv">"core_city"</span><span class="p">.</span><span class="nv">"population"</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50000000</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="nv">"country_population"</span> <span class="k">DESC</span></code></pre></figure>

<p>I hope you found this small tutorial helpful! If you have any questions, please leave a comment below!</p>
    </div>
    <div class="feedEntry">

        <a href="http://krzysztofzuraw.com/blog/2016/transcoding-aws-part-one.html" title="Transcoding with AWS- part one">
            <h2>Transcoding with AWS- part one</h2>
        </a>

        <p class="discreet">
            
                  By Krzysztof Żuraw Personal Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Dec 04, 2016</span>.
            
        </p>

        <p><strong>Nowadays moving everything to the cloud becomes more and more popular. A lot of
software companies move their technology stack to such infrastructure. One of
the biggest players in this field is Amazon Web Services - AWS. That's why I decided
decided to adapt existing code from my previous project and move transcoding
to write blog posts about that. In this series I
process to cloud.</strong></p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#overview-of-series" id="id1">Overview of series</a></li>
<li><a class="reference internal" href="https://www.djangoproject.com/rss/community/blogs/#moving-static-and-media-files-to-aws" id="id2">Moving static and media files to AWS</a></li>
</ul>
</div>
<div class="section" id="overview-of-series">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id1">Overview of series</a></h2>
<p>I decided to adapt code from my previous blog series about
<a class="reference external" href="http://krzysztofzuraw.com/blog/2016/django-celery-rabbit-part-one.html">celery and rabbit-mq</a>. I did that because code
from this django application actually transcodes mp3 files to other formats. This
series will be divided into these parts:</p>
<ul class="simple">
<li>Moving static and media files to AWS</li>
<li>Transcoding files inside AWS transcoder</li>
<li>Notifying user that transcode is complete</li>
<li>User downloads transcoded file</li>
</ul>
</div>
<div class="section" id="moving-static-and-media-files-to-aws">
<h2><a class="toc-backref" href="https://www.djangoproject.com/rss/community/blogs/#id2">Moving static and media files to AWS</a></h2>
<p>AWS transcoder operates only on files that are inside S3 bucket so first I need
to change how these files are served in django.</p>
<p>Let's say that I already had my account on AWS. Next step is to generate specific
account using <a class="reference external" href="http://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">IAM</a>.
While creating a user I want to give him access to AWS S3:</p>
<img alt="Policy for IAM user" src="https://www.djangoproject.com/images/aws1.png" />
<p>and after I download its
credentials I can create S3 container - I have chosen Ireland because with Frankfurt
I have a problem with uploading files to S3. After bucket creation, it's time to add
policy. The policy is basically JSON that tells AWS which user can access given bucket.
More information about that can be found <a class="reference external" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/intro-managing-access-s3-resources.html">here</a>.
Adding policy is quite simple from S3 management view:</p>
<img alt="Policy for S3 bucket" src="https://www.djangoproject.com/images/aws2.png" />
<p>This policy looks like this:</p>
<div class="highlight"><pre><span></span><span class="p">{</span>
      <span class="nt">&quot;Version&quot;</span><span class="p">:</span> <span class="s2">&quot;2008-10-17&quot;</span><span class="p">,</span>
      <span class="nt">&quot;Statement&quot;</span><span class="p">:</span> <span class="p">[</span>
              <span class="p">{</span>
                      <span class="nt">&quot;Sid&quot;</span><span class="p">:</span> <span class="s2">&quot;PublicReadForGetBucketObjects&quot;</span><span class="p">,</span>
                      <span class="nt">&quot;Effect&quot;</span><span class="p">:</span> <span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
                      <span class="nt">&quot;Principal&quot;</span><span class="p">:</span> <span class="p">{</span>
                              <span class="nt">&quot;AWS&quot;</span><span class="p">:</span> <span class="s2">&quot;*&quot;</span>
                      <span class="p">},</span>
                      <span class="nt">&quot;Action&quot;</span><span class="p">:</span> <span class="s2">&quot;s3:GetObject&quot;</span><span class="p">,</span>
                      <span class="nt">&quot;Resource&quot;</span><span class="p">:</span> <span class="s2">&quot;AWS_RESOURCE&quot;</span>
              <span class="p">},</span>
              <span class="p">{</span>
                      <span class="nt">&quot;Effect&quot;</span><span class="p">:</span> <span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
                      <span class="nt">&quot;Principal&quot;</span><span class="p">:</span> <span class="p">{</span>
                              <span class="nt">&quot;AWS&quot;</span><span class="p">:</span> <span class="s2">&quot;AWS_PRINCIPAL&quot;</span>
                      <span class="p">},</span>
                      <span class="nt">&quot;Action&quot;</span><span class="p">:</span> <span class="s2">&quot;s3:*&quot;</span><span class="p">,</span>
                      <span class="nt">&quot;Resource&quot;</span><span class="p">:</span> <span class="p">[</span>
                              <span class="s2">&quot;AWS_RESOURCE&quot;</span><span class="p">,</span>
                      <span class="p">]</span>
              <span class="p">}</span>
      <span class="p">]</span>
<span class="p">}</span>
</pre></div>
<p>Where AWS_PRINCIPAL is your IAM user in format of
<a class="reference external" href="http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">ARN resource</a>:
<tt class="docutils literal"><span class="pre">&quot;arn:aws:iam::AMAZON_ID:user/IAM_USER&quot;</span></tt> and AWS_RESOURCE: <tt class="docutils literal"><span class="pre">arn:aws:s3:::S3_BUCKET_NAME/*</span></tt>.</p>
<p>As I have this set up right now I can make changes in the application itself. To use S3 as
a static and media files container I used <a class="reference external" href="https://django-storages.readthedocs.io/en/latest/">django-storages</a>.
To make django-storages to work I have to add couple things in settings.py:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">environ</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">environ</span><span class="o">.</span><span class="n">Env</span><span class="p">()</span>


<span class="n">INSTALLED_APPS</span> <span class="o">=</span> <span class="p">[</span>
  <span class="c1"># other applicaitons</span>
  <span class="s1">'storages'</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">AWS_STORAGE_BUCKET_NAME</span> <span class="o">=</span> <span class="n">env</span><span class="p">(</span><span class="s1">'AWS_STORAGE_BUCKET_NAME'</span><span class="p">)</span>
<span class="n">AWS_ACCESS_KEY_ID</span> <span class="o">=</span> <span class="n">env</span><span class="p">(</span><span class="s1">'AWS_ACCESS_KEY_ID'</span><span class="p">)</span>
<span class="n">AWS_SECRET_ACCESS_KEY</span> <span class="o">=</span> <span class="n">env</span><span class="p">(</span><span class="s1">'AWS_SECRET_ACCESS_KEY'</span><span class="p">)</span>
<span class="n">AWS_S3_CUSTOM_DOMAIN</span> <span class="o">=</span> <span class="s1">'</span><span class="si">%s</span><span class="s1">.s3.amazonaws.com'</span> <span class="o">%</span> <span class="n">AWS_STORAGE_BUCKET_NAME</span>
<span class="n">AWS_HEADERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'Expires'</span><span class="p">:</span> <span class="s1">'Thu, 15 Apr 2010 20:00:00 GMT'</span><span class="p">,</span>
    <span class="s1">'Cache-Control'</span><span class="p">:</span> <span class="s1">'max-age=86400'</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">AWS_S3_HOST</span> <span class="o">=</span> <span class="s1">'s3-eu-west-1.amazonaws.com'</span>
</pre></div>
<p>I'm using here another package called <a class="reference external" href="https://github.com/joke2k/django-environ">django-environ</a>.
It allows me to get certain settings from environmental variables. I'm setting them
in my virtualenvwrapper script inside <tt class="docutils literal">$ENV_PATH/bin/postactivate</tt>:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">AWS_STORAGE_BUCKET_NAME</span><span class="o">=</span><span class="s1">'name'</span>
<span class="nb">export</span> <span class="nv">AWS_ACCESS_KEY_ID</span><span class="o">=</span><span class="s1">'key'</span>
<span class="nb">export</span> <span class="nv">AWS_SECRET_ACCESS_KEY</span><span class="o">=</span><span class="s1">'acces_id'</span>
</pre></div>
<p>The last line with <tt class="docutils literal">AWS_S3_HOST</tt> is really important here as boto - client that
django-storages use underneath to connect to AWS doesn't have default region set up.
If this is not specified I upload files with redirection which don't allow to transfer
static files or upload any large media file.</p>
<p>As I have AWS settings set up there is time to change static files settings in settings.py:</p>
<div class="highlight"><pre><span></span><span class="n">STATICFILES_LOCATION</span> <span class="o">=</span> <span class="s1">'static'</span>
<span class="n">STATIC_URL</span> <span class="o">=</span> <span class="s2">&quot;https://</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">/&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">AWS_S3_CUSTOM_DOMAIN</span><span class="p">,</span> <span class="n">STATICFILES_LOCATION</span><span class="p">)</span>
<span class="n">STATICFILES_STORAGE</span> <span class="o">=</span> <span class="s1">'audio_transcoder.storages.StaticStorage'</span>
<span class="n">STATICFILES_DIRS</span> <span class="o">=</span> <span class="p">(</span>
  <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="s1">'static'</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<p>I add custom <tt class="docutils literal">StaticStorage</tt> as I want my static files to be under static in S3 bucket:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">django.conf</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="nn">storages.backends.s3boto</span> <span class="kn">import</span> <span class="n">S3BotoStorage</span>


<span class="k">class</span> <span class="nc">StaticStorage</span><span class="p">(</span><span class="n">S3BotoStorage</span><span class="p">):</span>
  <span class="n">location</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">STATICFILES_LOCATION</span>
</pre></div>
<p>To upload my static files I simply run <tt class="docutils literal">python manage.py collectstatic</tt>. After a while
I can see that my files are in a bucket:</p>
<img alt="Static files inside S3" src="https://www.djangoproject.com/images/aws3.png" />
<p>Right now when I run my server I can see the location of my static files:</p>
<img alt="Static files loaded from S3" src="https://www.djangoproject.com/images/aws4.png" />
<p>As static files are working it's high time to use AWS for media files. Right now it's simple - in
settings I add:</p>
<div class="highlight"><pre><span></span><span class="n">MEDIAFILES_LOCATION</span> <span class="o">=</span> <span class="s1">'media'</span>
<span class="n">MEDIA_URL</span> <span class="o">=</span> <span class="s2">&quot;https://</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">/&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">AWS_S3_CUSTOM_DOMAIN</span><span class="p">,</span> <span class="n">MEDIAFILES_LOCATION</span><span class="p">)</span>
<span class="n">DEFAULT_FILE_STORAGE</span> <span class="o">=</span> <span class="s1">'audio_transcoder.storages.MediaStorage'</span>
</pre></div>
<p>with custom storage:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MediaStorage</span><span class="p">(</span><span class="n">S3BotoStorage</span><span class="p">):</span>
  <span class="n">location</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">MEDIAFILES_LOCATION</span>
</pre></div>
<p>Now when I upload my mp3 file it's sent directly to S3 bucket under media location:</p>
<img alt="Media files in S3" src="https://www.djangoproject.com/images/aws5.png" />
<p>That's all for today! In the next blog post, I will write about how to set up AWS transcoder.</p>
<p>The code that I have made so far is available on
<a class="reference external" href="https://github.com/krzysztofzuraw/blog_transcoder_aws">github</a>. Stay
tuned for next blog post from this series.</p>
<p>Special thanks to Kasia for being an editor for this post. Thank you.</p>
<p>While creating this blog post I used an excellent tutorial from
<a class="reference external" href="https://www.caktusgroup.com/blog/2014/11/10/Using-Amazon-S3-to-store-your-Django-sites-static-and-media-files/">cactus group</a>.</p>
<p>Cover image by <a class="reference external" href="http://www.flickr.com/people/25691430&#64;N04">Harald Hoyer</a> under <a class="reference external" href="http://creativecommons.org/licenses/by-sa/2.0">CC BY-SA 2.0</a>, via Wikimedia Commons</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://evennia.blogspot.com/2016/11/birthday-retrospective.html" title="Birthday retrospective">
            <h2>Birthday retrospective</h2>
        </a>

        <p class="discreet">
            
                  By Griatch's Evennia musings (MU* creation with Django+Twisted) from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Nov 30, 2016</span>.
            
        </p>

        <div class="separator" style="clear: both; text-align: center;"><a href="https://4.bp.blogspot.com/-pW3nsIxgroY/WDDFXo3z2dI/AAAAAAAAEs8/n9ehRTZrlggiEIOMGZupSVFxYa7DSGsZgCPcB/s1600/evennia_logo_festive_small.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="180" src="https://4.bp.blogspot.com/-pW3nsIxgroY/WDDFXo3z2dI/AAAAAAAAEs8/n9ehRTZrlggiEIOMGZupSVFxYa7DSGsZgCPcB/s200/evennia_logo_festive_small.png" width="200" /></a></div><span id="goog_1748990488"></span><span id="goog_1748990489"></span><b>S</b>o, recently Evennia celebrated its ten-year anniversary. That is, it was on Nov 20, 2006, Greg Taylor made the first repo commit to what would eventually become the Evennia of today. Greg has said that Evennia started out as a "weird experiment" of building a MUD/MUX using Django. The strange name he got from a cheesy NPC in the <a href="https://wiki.guildwars.com/wiki/Evennia" target="_blank">Guild Wars</a> MMORPG and Greg's <a href="https://groups.google.com/forum/#!category-topic/evennia/evennia-news/5hQTspfWd_Q" target="_blank">first post</a> to the mailing list also echoes the experimental intention of the codebase. The merger with Twisted came <a href="https://groups.google.com/forum/#!category-topic/evennia/evennia-news/CJ52R4Ws0OM" target="_blank">pretty early too</a>, replacing the early asyncore hack he used and immediately seeing a massive speedup. Evennia got attention from the MUD community - clearly a Python-based MUD system sounded attractive.<br /><br />When I first joined the project I had been looking at doing something MUD-like in Python for a good while. I had looked over the various existing Python code bases at the time and found them all to be either abandoned or very limited. I had a few week's stunt working with <a href="https://sourceforge.net/projects/pymoo/" target="_blank">pymoo</a> before asking myself why I was going through the trouble of parsing a custom script language<i> ... in Python</i> ... Why not use Python throughout? This is when I came upon Evennia. I started <a href="https://groups.google.com/forum/#!category-topic/evennia/evennia-news/yfR0GLKGhJA" target="_blank">making contributions</a> and around 2010 I <a href="https://groups.google.com/forum/#!category-topic/evennia/evennia-news/zXsA2PaWUoU" target="_blank">took over the development</a> as real life commitments forced Greg to step down.<br /><br />Over the years we have gone through a series of changes. We have gone from using SVN to Mercurial and then to using GIT. We have transited from GoogleCode to GitHub - the main problem of which was converting the wiki documentation (Evennia has <a href="https://github.com/evennia/evennia/wiki" target="_blank">extensive documentation</a>). <br /><br />For a long time we used Python's reload() function to add code to the running game. It worked ... sometimes, depending on what you changed. Eventually it turned out to be so unpredictable that we now use two processes, one to connect clients to and the other running the game, meaning we can completely restart one process without disconnecting anyone. <br /><br />Back in the day you were also expected to create your own game in a folder <span>game/</span> inside the Evennia repo itself. It made it really hard for us to update that folder without creating merge conflicts all over. Now Evennia is a proper library and the code you write is properly separated from ours.<br /><br />So in summary, many things have happened over the years, much of it documented in this blog. With 3500 commits, 28 000 lines of code (+46% comments) and some 25 people contributing in the last year, <a href="https://www.openhub.net/p/evennia" target="_blank">Openhub</a> lists us as <br /><br /><blockquote class="tr_bq">"<i>A mature, well-established codebase with a stable commit history, a large development team and very well documented source code</i>".&nbsp;</blockquote><br />It's just words compiled by an algorithm, but they still feel kinda good!<br /><br /><br />While Evennia was always meant to be used for any type of multiplayer text game, this general use have been expanded and cleaned up a lot over the years.<br /><br />This has been reflected in the width of people wanting to use it for different genres: Over time the MUSH people influenced us into adding the option to play the same character from many different clients at the same time (apparently, playing on the bus and then continuing on another device later is common for such games). Others have wanted to use Evennia for interactive fiction, for hack&amp;slash, deep roleplay, strategy, education or just for learning Python.<br /><br />Since Evennia is a framework/library and tries to not impose any particular game systems, it means there is much work to do when building a game using Evennia. The result is that there are dozens of games "in production" using Evennia (and more we probably don't know about), but few public releases yet.<br /><br />The first active "game" may have been an Evennia game/chat supporting the Russian version of 4chan...&nbsp;<span id="goog_1748990486"></span><span id="goog_1748990486">The community driven Evennia demo-game <a href="http://ainneve.evennia.com/" target="_blank">Ainneve</a></span><span id="goog_1748990486"> is also progressing, recently adding combat for testing. This is aimed at offering an example of more game-specific code people can build from (the way Diku does). There are similar projects meant for helping people create RPI (RolePlay Intensive) and MUSH-style games. </span><span id="goog_1748990487"></span>That said, the Evennia-game <a href="http://games.evennia.com/game/arx" target="_blank">Arx, After the Reckoning</a><span id="goog_1748990486"> is progressing through beta at a good clip and is showing all signs of becoming the first full-fledged released Evennia game.</span><span id="goog_1748990486">&nbsp;</span><br /><br /><br /><span id="goog_1748990486">So cheers, Evennia for turning 10. That's enough of the introspection and history. I'll get back to more technical aspects in the next post. </span>
    </div>
    <div class="feedEntry">

        <a href="https://adamj.eu/tech/2016/11/30/optimizing-construction-of-django-querysets/" title="Optimizing the construction of Django QuerySets">
            <h2>Optimizing the construction of Django QuerySets</h2>
        </a>

        <p class="discreet">
            
                  By Adam’s Tech Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Nov 29, 2016</span>.
            
        </p>

        <p><img alt="Deep construction
details" src="https://www.djangoproject.com/tech/assets/2016-11-30-construction-underground.jpg" /></p>

<p>Django’s ORM is normally fast enough as-is, but if you’ve ever profiled a high
traffic view with a fairly complicated query, you might have found that
constructing <code>QuerySet</code> can take a noticeable portion of your request time. For
example, I once found a query on the front page of the site I was working on
that took 1ms to construct and 1ms for the database to answer. With a
performance budget of 100ms, that was 1% gone on computing the exactly same
SQL.</p>

<p>Thankfully we don’t need to instantly drop down to raw SQL to optimize such
cases, as Django’s <code>QuerySet</code> API naturally lends itself to caching the
intermediate objects. Since each operation on a <code>QuerySet</code> returns a <em>new</em>
object with the change applied, they’re always lazy as to executing the
SQL, and operations can (normally) be chained in any order, you can build the
non-specific part of your <code>QuerySet</code> up as a cached object and then apply
final, specific filtering required at request time.</p>

<p>Just a note before we dive in: this should be one of the least reached for
tools in your optimization toolbox - normally it’s enough to fix the basics
such as avoiding N+1 queries with <code>select_related()</code> / <code>prefetch_related()</code>,
and adding caching of data between requests with Django’s caching framework. On
that old front page I was talking about, the reason the rest of the page fit in
98ms was because most of it came from a few cache keys, avoiding even some
template rendering.</p>

<p>As an example, let’s say we’re building an autocomplete feature on Django’s
<code>User</code> model. We might have a function that looks like this:</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">full_construction_autocomplete</span><span class="p">(</span><span class="n">typed</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="n">username_length</span><span class="o">=</span><span class="n">Length</span><span class="p">(</span><span class="s">'username'</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">order_by</span><span class="p">(</span>
        <span class="s">'username_length'</span>
    <span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
        <span class="n">username__startswith</span><span class="o">=</span><span class="n">typed</span>
    <span class="p">)</span></code></pre></figure>

<p>If we time it with IPython’s <code>%timeit</code> on <code>./manage.py shell</code>, it will time
just the construction time, since nothing is iterating the QuerySet and causing
the lazy fetching of results from the database. It comes out taking about a
quarter of a millisecond on my machine:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="o">%</span><span class="n">timeit</span> <span class="n">full_construction_autocomplete</span><span class="p">(</span><span class="s">'ad'</span><span class="p">)</span>
<span class="mi">1000</span> <span class="n">loops</span><span class="p">,</span> <span class="n">best</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">263</span> <span class="err">µ</span><span class="n">s</span> <span class="n">per</span> <span class="n">loop</span></code></pre></figure>

<p>To cache most of the construction, we can just define the non-specific part of
the query as a module-level object, and apply the <code>filter()</code> at the last step:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">cached_qs</span> <span class="o">=</span> <span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="n">username_length</span><span class="o">=</span><span class="n">Length</span><span class="p">(</span><span class="s">'username'</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">order_by</span><span class="p">(</span>
    <span class="s">'username_length'</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">cached_construction_autocomplete</span><span class="p">(</span><span class="n">typed</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cached_qs</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
        <span class="n">username__startswith</span><span class="o">=</span><span class="n">typed</span>
    <span class="p">)</span></code></pre></figure>

<p>And just like that, we’ve sped the function calls up by more than 50%:</p>

<figure class="highlight"><pre><code class="language-python"><span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="o">%</span><span class="n">timeit</span> <span class="n">cached_construction_autocomplete</span><span class="p">(</span><span class="s">'ad'</span><span class="p">)</span>
<span class="mi">10000</span> <span class="n">loops</span><span class="p">,</span> <span class="n">best</span> <span class="n">of</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">105</span> <span class="err">µ</span><span class="n">s</span> <span class="n">per</span> <span class="n">loop</span></code></pre></figure>

<p>Obviously 160 microseconds on its own is hardly going to be noticeable to your
end users, but if you find yourself looking at a complicated or frequently
called <code>QuerySet</code>, this technique might help you make your performance budget.
It’s also a simple optimization.</p>

<p>You don’t necessarily have to cache with a module-level object, for example in
<code>ModelAdmin</code> classes you could cache partially constructed <code>QuerySet</code>s on the
class itself. For example this will work as long as you don’t do per-request
modifications in <code>get_queryset</code> or <code>get_ordering</code>:</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">class</span> <span class="nc">MyModelAdmin</span><span class="p">(</span><span class="n">ModelAdmin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">get_queryset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'_queryset'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queryset</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_queryset</span><span class="p">(</span><span class="n">request</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
                <span class="n">username_length</span><span class="o">=</span><span class="n">Length</span><span class="p">(</span><span class="s">'username'</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queryset</span><span class="o">.</span><span class="n">all</span><span class="p">()</span></code></pre></figure>

<p>The <code>all()</code> here is important to make sure we hand a copy of the <code>QuerySet</code> to
the caller and avoid caching the results once for the whole class!</p>

<p>I’m sure you can come up with the right caching scheme for wherever it is you
construct your <code>QuerySet</code>s, such as your class-based views, or custom managers.</p>

<p>The Django core team are aware of the time that can be wasted on <code>QuerySet</code>
construction, and have looked at optimizing it. This would be particularly
useful for some Django internals, such as when constructing a <code>QuerySet</code>
during <code>Model.save()</code>. Anssi Kääriäinen created a patch to add an option to
<code>QuerySet</code>s to not clone themselves on operations in
<a href="https://code.djangoproject.com/ticket/20880">Ticket 20880</a>, and Josh Smeaton
opened an experimental
<a href="https://github.com/django/django/pull/7505">Pull Request</a> implementing the
same idea as a (maybe) public API. I personally think that it’s going to be
better kept as a private API for Django’s core, as there are many ways of
optimizing user code, including this strategy of caching partially constructed
<code>QuerySet</code>s :)</p>
    </div>
    <div class="feedEntry">

        <a href="https://www.caktusgroup.com/blog/2016/11/29/django-under-hood-2016-recap/" title="Django Under the Hood 2016 Recap">
            <h2>Django Under the Hood 2016 Recap</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Nov 29, 2016</span>.
            
        </p>

        <p>Caktus was a proud sponsor of Django Under the Hood (DUTH) 2016 in Amsterdam this year. Organized by Django core developers and community members, DUTH is a highly technical conference that delves deep into Django.</p>
<p>Django core developers and Caktus Technical Manager <a href="https://www.caktusgroup.com/about/karen-tracey/">Karen Tracey</a> and CEO/Co-founder <a href="https://www.caktusgroup.com/about/tobias-mcnulty/">Tobias McNulty</a> both flew to Amsterdam to spend time with fellow Djangonauts.  Since not all of us could go, we wanted to ask them what Django Under the Hood was like.</p>
<h2>Can you tell us more about Django Under the Hood?</h2>
<p><strong>Tobias</strong>: This was my first Django Under the Hood. The venue was packed. It’s an in-depth, curated talk series by invite-only speakers.  It was impeccably organized. Everything is thought through. They even have little spots where you can pick up toothbrush and toothpaste.</p>
<p><strong>Karen</strong>: I’ve been to all three. They sell out very quickly. Core developers are all invited, get tickets, and some funding depending on sponsorship. This is the only event where some costs are covered for core developers. DjangoCon EU and US have core devs going, but they attend it however they manage to get funds for it.</p>
<h2>What was your favorite part of Django Under the Hood?</h2>
<p><strong>Tobias</strong>: The talks: they’re longer and more detailed than typical conference talks; they’re curated and confined to a single track so the conference has a natural rhythm to it. I really liked the talks, but also being there with the core team. Just being able to meet these people you see on IRC and mailing list, there’s a big value to that. I was able to put people in context. I’d met quite a few of the core team before but not all.</p>
<p><strong>Karen</strong>:  I don’t have much time to contribute to Django because of heavy involvement in cat rescue locally and a full time job, but this is a great opportunity to have at least a day to do Django stuff at the sprint and to see a lot of people I don’t otherwise have a chance to see.</p>
<h2>All the talk videos are now online. Which talk do you recommend we watch first?</h2>
<p><strong>Karen</strong>: Depends on what you’re interested in. I really enjoyed the <a href="https://youtu.be/lx5WQjXLlq8?list=PLQdy7QUATciZ4V3g3iCTnG5fvkZkuNGyg">Instagram one</a>. As someone who contributed to the Django framework, to see it used and scaled to the size of Instagram 500 million plus users is interesting.</p>
<p><strong>Tobias</strong>: There were humorous insights, like the Justin Bieber effect. Originally they’d shared their database by user ID, so everybody on the ops team had memorized his user ID to be prepared in case he posted anything. At that scale, maximizing the number of requests they can serve from a single server really matters.</p>
<p><strong>Karen</strong>: All the monitoring was interesting too.</p>
<p><strong>Tobias</strong>: I liked Ana Balica’s <a href="https://youtu.be/EHyKzPQFXzo?list=PLQdy7QUATciZ4V3g3iCTnG5fvkZkuNGyg">testing talk</a>. It included a history of testing in Django, which was educational to me. Django didn’t start with a framework for testing your applications. It was added as a ticket in the low thousands. She also had practical advice on how to treat your test suite as part of the application, like splitting out functional tests and unit tests. She had good strategies to make your unit tests as fast as possible so you can run them as often as needed. </p>
<h2>What was your favorite tip or lesson?</h2>
<p><strong>Tobias</strong>: Jennifer Akullian gave a keynote on mental health that had a diagram of how to talk about feelings in a team. You try to dig into what that means. She talked about trying to destigmatize mental health in tech. I think that’s an important topic we should be discussing more.</p>
<p><strong>Karen</strong>: I learned things in each of the talks. I have a hard time picking out one tip that sticks with me. I’d like to look into what Ana Balica said about mutation testing and learn more about it. </p>
<h2>What are some trends you’re seeing in Django?</h2>
<p><strong>Karen</strong>: The core developers met for a half-day meeting the first day of the conference. We talked about what’s going on with DJango, what’s happened in the past year, what’s the future of Django. The theme was “Django is boring.”</p>
<p><strong>Tobias</strong>: “Django is boring” because it is no longer unknown. It’s an established, common framework now used by big organizations like NASA, Instagram, Pinterest, US Senate, etc. At the start, it was a little known bootstrappy cutting edge web framework. The reasons why we hooked up with Django nine years ago at Caktus, like security and business efficacy, all of those arguments are ever so much stronger today. That can make it seem boring for developers but it’s a good thing for business.</p>
<p><strong>Karen</strong>: It’s been around for awhile. Eleven years. A lot of the common challenges in Django have been solved. Not that there aren’t cutting edge web problems. But should you solve some problems elsewhere? For example, in third party, reusable apps like channels, REST framework.</p>
<p><strong>Tobias</strong>: There was also recognition that Django is so much more than the software. It’s  the community and all the packages around it. That’s what make Dango great. </p>
<h2>Where do you see Django going in the future?</h2>
<p><strong>Karen</strong>: I hate those sorts of  questions. I don’t know how to answer that. It’s been fun to see the Django community grow and I expect to see continued growth.</p>
<p><strong>Tobias</strong>: That’s not my favorite question either. But Django has a role in fostering and continuing to grow the community it has. Django can set an example for open source communities on how to operate and fund themselves in sustainable ways. Django is experimenting with funding right now. How do we make open source projects like this sustainable without relying on people with full-time jobs volunteering their nights and weekends? This is definitely not a “solved problem,” and I look forward to seeing the progress Django and other open source communities make in the coming years.</p>
<h2>Thank you to Tobias and Karen for sharing their thoughts.</h2>
    </div>
    <div class="feedEntry">

        <a href="http://davidfozo.com/blog/introduction-to-django-models/" title="Introduction to Django Models">
            <h2>Introduction to Django Models</h2>
        </a>

        <p class="discreet">
            
                  By David Fozo's Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Nov 29, 2016</span>.
            
        </p>

        <p style="margin-bottom: 0in; line-height: 100%;">In this part of the tutorial, I will show you some basic model definition by creating a simple blog. As discussed earlier, database tables are translated from the models.py files.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">If you haven't followed along with earlier tutorials, you can do the setup <a href="http://www.davidfozo.com/blog/django-tutorial-setup/" target="_blank">here</a>. Choose branch exercise4.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">As usual we start by creating a new branch:</p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>git checkout -b blog</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Activate virtualenv, if you haven't already:</p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>source ../virtualenv/bin/activate</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">A is an application by itself, so we create one inside Django with the following command.</p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>python3 manage.py startapp blog</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">You should see these directories and files in your source dir:</p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>blog/</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>main/</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>manage.py</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>MyTutorial/</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>requirements.txt</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">In order for django to discover the new application, you need to include it in the installed apps in settings.py</p>
<p style="margin-bottom: 0in; line-height: 100%;">***MyTutorial/settings.py***</p>
<p style="margin-bottom: 0in; line-height: 100%;">...</p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>INSTALLED_APPS = [</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'main',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'blog',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.admin',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.auth',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.contenttypes',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.sessions',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.messages',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>    'django.contrib.staticfiles',</code></p>
<p style="margin-bottom: 0in; line-height: 100%;"><code>]</code></p>
<p style="margin-bottom: 0in; line-height: 100%;">…</p>
<p style="margin-bottom: 0in; line-height: 100%;"></p>
<p style="margin-bottom: 0in; line-height: 100%;">As usual we write some tests first. If you have a look at the other test file main/tests.py you can see, that we have some very similar goal here. It might be tempting to import those tests and tweak it a little, but that wouldn't be right. As for Unit Tests, it needs to be completely independent from each other. So it is not a problem, if they look too much alike.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">***blog/tests.py***</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.core.urlresolvers import resolve</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.test import TestCase</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.http import HttpRequest</p>
<p style="margin-bottom: 0in; line-height: 100%;">from blog.models import BlogPost</p>
<p style="margin-bottom: 0in; line-height: 100%;">from blog.views import view_post</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;"># Create your tests here.</p>
<p style="margin-bottom: 0in; line-height: 100%;">class BlogPostTest(TestCase):</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">    def setUp(self):</p>
<p style="margin-bottom: 0in; line-height: 100%;">        self.title = "Blog Post Test"</p>
<p style="margin-bottom: 0in; line-height: 100%;">        self.slug = "blog-post-test"</p>
<p style="margin-bottom: 0in; line-height: 100%;">        self.body = "This is a test."</p>
<p style="margin-bottom: 0in; line-height: 100%;">        self.date = "2016-11-26"</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">        BlogPost.objects.create(</p>
<p style="margin-bottom: 0in; line-height: 100%;">            title=self.title,</p>
<p style="margin-bottom: 0in; line-height: 100%;">            slug=self.slug,</p>
<p style="margin-bottom: 0in; line-height: 100%;">            body=self.body,</p>
<p style="margin-bottom: 0in; line-height: 100%;">            date=self.date)</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">    def test_blogpost_resolves_to_slug(self):</p>
<p style="margin-bottom: 0in; line-height: 100%;">        blogpost = resolve('/blog/' + self.slug + '/')</p>
<p style="margin-bottom: 0in; line-height: 100%;">        self.assertEqual(blogpost.func,view_post)</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">    def test_blogpost_displays_article(self):</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">         request = HttpRequest()</p>
<p style="margin-bottom: 0in; line-height: 100%;">         response = view_post(request,self.slug)</p>
<p style="margin-bottom: 0in; line-height: 100%;">         self.assertTrue(response.content.startswith(b'&lt;!doctype html&gt;'))</p>
<p style="margin-bottom: 0in; line-height: 100%;">         for i in [self.title,self.body]:</p>
<p style="margin-bottom: 0in; line-height: 100%;">             self.assertIn(i,response.content.decode())</p>
<p style="margin-bottom: 0in; line-height: 100%;"></p>
<p style="margin-bottom: 0in; line-height: 100%;">    def tearDown(self):</p>
<p style="margin-bottom: 0in; line-height: 100%;">        BlogPost.objects.all().filter(title=self.title).delete()</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%; text-align: justify;">So what did we do here? We created a new test class, which tests our blog application. In the setUp function, we create some title, body, slug variables, which we can refer to later. We also a create BlogPost object. In the first test we check if our custom url will trigger the right view function. I think the second tests title speaks for itself. We call the view_post function, which we will create in a moment, with our custom slug (the blog post identifier as in the URL). Then check if the response contains our chosen title, and body.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">If you run the tests now:</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py test</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">You should have two failures:</p>
<p style="margin-bottom: 0in; line-height: 100%;">FF.......</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">So let's create the model classes first, because that's the most interesting.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">***blog/models.py***</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.db import models</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.core.urlresolvers import reverse</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.template.defaultfilters import slugify</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;"># Create your models here.</p>
<p style="margin-bottom: 0in; line-height: 100%;">class BlogPost(models.Model):</p>
<p style="margin-bottom: 0in; line-height: 100%;">    title = models.CharField(max_length=255)</p>
<p style="margin-bottom: 0in; line-height: 100%;">    slug = models.SlugField(max_length=255)</p>
<p style="margin-bottom: 0in; line-height: 100%;">    body = models.TextField()</p>
<p style="margin-bottom: 0in; line-height: 100%;">    date = models.DateField(auto_now_add=True)</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">    def save(self, *args, **kwargs):</p>
<p style="margin-bottom: 0in; line-height: 100%;">        if not self.id:</p>
<p style="margin-bottom: 0in; line-height: 100%;">            self.slug = slugify(self.title)</p>
<p style="margin-bottom: 0in; line-height: 100%;">        super(BlogPost, self).save(*args, **kwargs)</p>
<p style="margin-bottom: 0in; line-height: 100%;"></p>
<p style="margin-bottom: 0in; line-height: 100%;">    def get_absolute_url(self):</p>
<p style="margin-bottom: 0in; line-height: 100%;">        return reverse('blog.views.view_post', args=[str(self.slug)])</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%; text-align: justify;">What is happening here? So our database tables are model classes in Django. The fields are variables. So you declare a variable, and that will be the title of the database column/field. Then, you choose the appropriate field type. One if the method is saving your title as a slug (url) if it's a new post (no id yet), the other method let's you reference this post as an url.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Now, let's connect these models to the templates, by the views functions.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">***blog/views.py***</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.shortcuts import render_to_response, get_object_or_404</p>
<p style="margin-bottom: 0in; line-height: 100%;">from blog.models import BlogPost</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;"># Create your views here.</p>
<p style="margin-bottom: 0in; line-height: 100%;">def view_post(request, slug):</p>
<p style="margin-bottom: 0in; line-height: 100%;">    post = get_object_or_404(BlogPost, slug=slug)</p>
<p style="margin-bottom: 0in; line-height: 100%;">    return render_to_response("blogpost.html", {'post' : post,})</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Okay, so our view_post function takes in the slug and fetches the corresponding BlogPost model object. Then it renders the blogpost.html template, where the post variables refer to our BlogPost object.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Let's add our BlogPost slug to the urls:</p>
<p style="margin-bottom: 0in; line-height: 100%;">***MyTutorial/urls.py***</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.conf.urls import url</p>
<p style="margin-bottom: 0in; line-height: 100%;">from django.contrib import admin</p>
<p style="margin-bottom: 0in; line-height: 100%;">from main.views import home, form, subscribed, thanks</p>
<p style="margin-bottom: 0in; line-height: 100%;">from blog.views import view_post</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">urlpatterns = [</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^admin/', admin.site.urls),</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^form/',form),</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^thanks/',thanks),</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^subscribed/',subscribed),</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^$', home),</p>
<p style="margin-bottom: 0in; line-height: 100%;">    url(r'^blog/(?P&lt;slug&gt;[-\w\d\_]+)/$', view_post, name='view_post'),</p>
<p style="margin-bottom: 0in; line-height: 100%;">]</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">So now you can reference your Post as /blog/my-blog-post-title.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Let's create some basic template. See, how it all comes full circle!</p>
<p style="margin-bottom: 0in; line-height: 100%;">***blog/blogpost.html***</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;!doctype html&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;html&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;head&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">    &lt;title&gt;{{ post.title }}&lt;/title&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;/head&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;body&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">    &lt;h1&gt;{{ post.title }}&lt;/h1&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">    &lt;p&gt;{{ post.body }}&lt;/p&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">    &lt;br&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">    &lt;p&gt;created at {{ post.date }}&lt;/p&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;/body&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;">&lt;/html&gt;</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">If you run the tests, you will still have no luck. Even though, every piece of code is in place. You need to update the database to reflect the changes.</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py makemigrations</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py migrate</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Now, if want to make a blog post, it's not so convenient:</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py shell</p>
<p style="margin-bottom: 0in; line-height: 100%;">&gt;&gt;&gt;from blog.models import BlogPost</p>
<p style="margin-bottom: 0in; line-height: 100%;">&gt;&gt;&gt;BlogPost.objects.create(title=”My Title”,slug=”my-title”,body=”Hello World”,date=”2016-11-29”)</p>
<p style="margin-bottom: 0in; line-height: 100%;">&gt;&gt;&gt;exit()</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">So you are able to see it, if you start up your development server:</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py runserver</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Write to the url line in the browser: <a href="http://localhost/blog/my-title/">http://localhost/blog/my-title/</a> . Should see this:</p>
<p style="margin-bottom: 0in; line-height: 100%;">### Screenshot ###</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Run the tests:</p>
<p style="margin-bottom: 0in; line-height: 100%;">python3 manage.py test</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">It should all pass.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Let's commit our changes and merge into the master branch.</p>
<p style="margin-bottom: 0in; line-height: 100%;">git status</p>
<p style="margin-bottom: 0in; line-height: 100%;">git add .</p>
<p style="margin-bottom: 0in; line-height: 100%;">git commit -m “Added blog application, able to create basic blog posts”</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Change you branch back to master:</p>
<p style="margin-bottom: 0in; line-height: 100%;">git checkout master</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Merge the blog branch back to master and then delete the branch not needed.</p>
<p style="margin-bottom: 0in; line-height: 100%;">git merge blog</p>
<p style="margin-bottom: 0in; line-height: 100%;">git branch -d blog</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">So you learned how to create some basic database model in Django. It is not really user friendly yet, but soon you will see how to be the master of your Django universe.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Stay tuned for the next lesson, where I will show you, how to handle your models with grace in the Django Admin.</p>
<p style="margin-bottom: 0in; line-height: 100%;"> </p>
<p style="margin-bottom: 0in; line-height: 100%;">Until next time.</p>
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/im_gonna_regret_this" title="I'm Gonna Regret This">
            <h2>I'm Gonna Regret This</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Jun 14, 2016</span>.
            
        </p>

        A plea for liberals to fight for individual rights.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/is_open_source_consulting_dead" title="Is Open Source Consulting Dead?">
            <h2>Is Open Source Consulting Dead?</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Sep 10, 2013</span>.
            
        </p>

        Has Elvis left the building?  Will we be able to sustain ourselves as open source consultants?
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/consulting_and_patent_indemnification" title="Consulting and Patent Indemification">
            <h2>Consulting and Patent Indemification</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Aug 09, 2013</span>.
            
        </p>

        Article about consulting and patent indemnification
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/python_advent_2012" title="Python Advent Calendar 2012 Topic">
            <h2>Python Advent Calendar 2012 Topic</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Dec 24, 2012</span>.
            
        </p>

        An entry for the 2012 Japanese advent calendar at http://connpass.com/event/1439/
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/why_i_like_zodb" title="Why I Like ZODB">
            <h2>Why I Like ZODB</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">May 15, 2012</span>.
            
        </p>

        Why I like ZODB better than other persistence systems for writing real-world web applications.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/python_2_vs_python_3_str_iter" title="A str. __iter__ Gotcha in Cross-Compatible Py2/Py3 Code">
            <h2>A str. __iter__ Gotcha in Cross-Compatible Py2/Py3 Code</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Mar 03, 2012</span>.
            
        </p>

        A bug caused by a minor incompatibility can remain latent for long periods of time in a cross-compatible Python 2 / Python 3 codebase.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/in_praise_of_complaining" title="In Praise of Complaining">
            <h2>In Praise of Complaining</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Jan 01, 2012</span>.
            
        </p>

        In praise of complaining, even when the complaints are absurd.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/2012_python_meme" title="2012 Python Meme">
            <h2>2012 Python Meme</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Dec 24, 2011</span>.
            
        </p>

        My "Python meme" replies.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/in_defense_of_zope_libraries" title="In Defense of Zope Libraries">
            <h2>In Defense of Zope Libraries</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Dec 19, 2011</span>.
            
        </p>

        A much too long defense of Pyramid's use of Zope libraries.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/ploneconf_2011_pyramid_sprint" title="Plone Conference 2011 Pyramid Sprint">
            <h2>Plone Conference 2011 Pyramid Sprint</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Nov 10, 2011</span>.
            
        </p>

        An update about the happenings at the recent 2011 Plone Conference Pyramid sprint.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/oss_jobsification" title="Jobs-Ification of Software Development">
            <h2>Jobs-Ification of Software Development</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Oct 17, 2011</span>.
            
        </p>

        Try not to Jobs-ify the task of software development.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/webob_py3" title="WebOb Now on Python 3">
            <h2>WebOb Now on Python 3</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Oct 15, 2011</span>.
            
        </p>

        Report about porting to Python 3.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/oss_sarcasm" title="Open Source Project Maintainer Sarcastic Response Cheat Sheet">
            <h2>Open Source Project Maintainer Sarcastic Response Cheat Sheet</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Jun 12, 2011</span>.
            
        </p>

        Need a sarcastic response to a support interaction as an open source project maintainer?  Look no further!
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/minicon0_wrapup" title="Pylons Miniconference #0 Wrapup">
            <h2>Pylons Miniconference #0 Wrapup</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">May 04, 2011</span>.
            
        </p>

        Last week, I visited the lovely Bay Area to attend the 0th Pylons
Miniconference in San Francisco.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/pylons_project_minicon" title="Pylons Project Meetup / Minicon">
            <h2>Pylons Project Meetup / Minicon</h2>
        </a>

        <p class="discreet">
            
                  By chrism from .
            
            
            
                Published on <span name="publication_time">Apr 14, 2011</span>.
            
        </p>

        In the SF Bay Area on the 28th, 29th, and 30th of this month (April), 3 separate Pylons Project events.
    </div>

    

    <div class="visualClear"><!-- --></div>

    <div class="documentActions">
        

        

    </div>


                        </div>
                    

                    
                </div>
            

            <div id="viewlet-below-content">

<div id="portlets-below" class="row">
     
         
             <div class="cell BelowPortletManager2 width-1:2 position-0">


<div id="portletwrapper-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572320a636f6e746578740a2f506c6f6e652f636f7665720a6c61746573742d706c6f6e652d706f737473" class="portletWrapper kssattr-portlethash-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572320a636f6e746578740a2f506c6f6e652f636f7665720a6c61746573742d706c6f6e652d706f737473"><dl class="portlet portletfeedmixer">

    <dt class="portletHeader">
        <span class="portletTopLeft"></span>
        <span>Latest Plone Posts</span>
        <span class="portletTopRight"></span>
    </dt>

    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/-fsaEox55SA/Python-Meeting-Duesseldorf-2017-01-18" title="Python Meeting Düsseldorf - 2017-01-18">
                Python Meeting Düsseldorf - 2017-01-18
                <span class="portletItemDetails">Jan 16, 2017</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/5y-e41MiETE/how-to-monitor-your-plone-servers-with-sentry" title="How to monitor your Plone servers with Sentry">
                How to monitor your Plone servers with Sentry
                <span class="portletItemDetails">Dec 30, 2016</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/4FhKZqlg7gw/quills-blogging-add-on-for-plone-gets-some-attention" title="Quills blogging add-on for Plone gets some attention">
                Quills blogging add-on for Plone gets some attention
                <span class="portletItemDetails">Dec 27, 2016</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/Gwnva8Vfm90/how-to-enable-online-reading-of-taylor-francis-journals" title="How to enable online reading of Taylor &amp; Francis journals from your Plone site">
                How to enable online reading of Taylor & Francis journals from your Plone site
                <span class="portletItemDetails">Dec 27, 2016</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/7Pj2NjSUPZw/plone-site-performance-threads-or.html" title="Plone performance: threads or instances?">
                Plone performance: threads or instances?
                <span class="portletItemDetails">Dec 23, 2016</span>
            </a>
        </dd>
    
    
    <dd class="portletFooter">
      <a href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager2/latest-plone-posts/full_feed" class="tile">More&hellip;</a>
        <span class="portletBottomLeft"></span>
        <span class="portletBottomRight"></span>
    </dd>

</dl>
</div>

</div> 

         
         
             <div class="cell BelowPortletManager3 width-1:2 position-1:2">


<div id="portletwrapper-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572330a636f6e746578740a2f506c6f6e652f636f7665720a6f70656e2d736f757263652d706f737473" class="portletWrapper kssattr-portlethash-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572330a636f6e746578740a2f506c6f6e652f636f7665720a6f70656e2d736f757263652d706f737473"><dl class="portlet portletfeedmixer">

    <dt class="portletHeader">
        <span class="portletTopLeft"></span>
        <span>Open Source Posts</span>
        <span class="portletTopRight"></span>
    </dt>

    
        <dd class="portletItem odd">

            <a href="https://postgr.es/p/3IA" title="Magnus Hagander: Another couple of steps on my backup crusade">
                Magnus Hagander: Another couple of steps on my backup crusade
                <span class="portletItemDetails">Jan 16, 2017</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="https://postgr.es/p/3Iz" title="Kaarel Moppel: Two simple Postgres tips to kick-start year 2017">
                Kaarel Moppel: Two simple Postgres tips to kick-start year 2017
                <span class="portletItemDetails">Jan 16, 2017</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="https://postgr.es/p/3Iy" title="Michael Paquier: Postgres 10 highlight - Reload of SSL parameters">
                Michael Paquier: Postgres 10 highlight - Reload of SSL parameters
                <span class="portletItemDetails">Jan 15, 2017</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://krzysztofzuraw.com/blog/2017/transcoding-aws-part-four.html" title="Transcoding with AWS- part four">
                Transcoding with AWS- part four
                <span class="portletItemDetails">Jan 15, 2017</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="https://postgr.es/p/3Ix" title="Shaun M. Thomas: PG Phriday: Why Postgres">
                Shaun M. Thomas: PG Phriday: Why Postgres
                <span class="portletItemDetails">Jan 13, 2017</span>
            </a>
        </dd>
    
    
    <dd class="portletFooter">
      <a href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed" class="tile">More&hellip;</a>
        <span class="portletBottomLeft"></span>
        <span class="portletBottomRight"></span>
    </dd>

</dl>
</div>

</div> 

         
     
</div>


</div>
        </div>

        
        

        
        
    </div>


    <div class="row">
        <div id="portlets-footer" class="row">
     
     
</div>



<div class="row">
    <div class="cell width-full position-0">
        <div id="portal-footer">
          <a id="license-img" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">
            <img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" />
          </a>
          <p>
            This site and its content is licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative
              Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>, 
              2011&mdash;2017
          </p>
          <div class="visualClear"><!-- clear floats --></div>
        </div>

    </div>
</div>
<div id="portal-colophon">

<div class="colophonWrapper">
<ul>
  <li>
    <a href="http://plone.org" title="This site was built using the Plone Open Source CMS/WCM.">
      Powered by Plone &amp; Python</a>
  </li>
</ul>
</div>
</div>

<ul id="portal-siteactions">

    <li id="siteaction-sitemap"><a href="http://crisewing.com/sitemap" accesskey="3" title="Site Map">Site Map</a></li>
    <li id="siteaction-accessibility"><a href="http://crisewing.com/accessibility-info" accesskey="0" title="Accessibility">Accessibility</a></li>
    <li id="siteaction-contact"><a href="http://crisewing.com/about/contact" accesskey="9" title="Contact">Contact</a></li>
</ul>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22486368-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
        <div id="kss-spinner">
            <img alt="" src="http://crisewing.com/spinner.gif" />
        </div>
    </div>

</div>
</body>
</html>



